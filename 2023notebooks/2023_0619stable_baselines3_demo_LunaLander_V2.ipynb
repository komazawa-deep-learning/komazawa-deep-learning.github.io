{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOEFP/Iz9WBhowMAiZAVuN0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2023notebooks/2023_0619stable_baselines3_demo_LunaLander_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "date: 2023_0619\n",
        "author: 浅川伸一\n",
        "---\n",
        "\n",
        "# Demo for `Lunalander-v2` from stable-baselines3\n",
        "\n",
        "source from [https://araffin.github.io/post/sb3/](https://araffin.github.io/post/sb3/)\n",
        "\n",
        "<center>\n",
        "<div>\n",
        "<video controls src=\"https://youtu.be/M1_qCqvW-u4\" muted=\"false\">\n",
        "</video>\n",
        "</center>\n"
      ],
      "metadata": {
        "id": "MCWBUoJgqfz7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vW_7SwBl8_I"
      },
      "outputs": [],
      "source": [
        "from IPython import get_ipython\n",
        "isColab =  'google.colab' in str(get_ipython())\n",
        "if isColab:\n",
        "    !pip install jupyter-black"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for autoformatting\n",
        "%load_ext jupyter_black"
      ],
      "metadata": {
        "id": "1JSKMJiTl-hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if isColab:\n",
        "    !apt-get install ffmpeg freeglut3-dev xvfb  # For visualization\n",
        "    !pip install \"stable-baselines3[extra]>=2.0.0a4\" --upgrade\n",
        "    !pip install swig --upgrade\n",
        "    !pip install 'gymnasium[box2d]' --upgrade"
      ],
      "metadata": {
        "id": "yItryBuUmA68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "I125iMj7mEZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# source form <https://araffin.github.io/post/sb3/>\n",
        "# import gym\n",
        "\n",
        "from stable_baselines3 import PPO  # Proximal Policy Optimization\n",
        "from stable_baselines3 import A2C  # Asynchronous Advantage Actor Critic (A3C)\n",
        "from stable_baselines3 import DDPG  # Deep Deterministic Policy Gradient\n",
        "from stable_baselines3 import DQN  # Deep Q Network\n",
        "from stable_baselines3 import SAC  # Soft Actor Critic\n",
        "\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback\n",
        "\n",
        "# 途中経過 `checkpoint` を 5000 ステップ毎に保存\n",
        "checkpoint_callback = CheckpointCallback(\n",
        "    save_freq=5000, save_path=\"./logs/\", name_prefix=\"rl_model\"\n",
        ")\n",
        "\n",
        "# モデルを定期的に評価，最適モデルと評価を保存\n",
        "# モニターラッパーを使用して，エピソードの統計情報を報告\n",
        "eval_env = Monitor(gym.make(\"LunarLander-v3\"))\n",
        "\n",
        "# 評価のために決定論的な行動を行う\n",
        "eval_callback = EvalCallback(\n",
        "    eval_env,\n",
        "    best_model_save_path=\"./logs/\",\n",
        "    log_path=\"./logs/\",\n",
        "    eval_freq=2000,\n",
        "    deterministic=True,\n",
        "    render=False,\n",
        ")\n",
        "\n",
        "# 動作主 (エージェント) を訓練\n",
        "model = A2C(\"MlpPolicy\", \"LunarLander-v3\", verbose=1)\n",
        "model.learn(total_timesteps=20000, callback=[checkpoint_callback, eval_callback])\n",
        "\n",
        "# Retrieve and reset the environment\n",
        "env = model.get_env()\n",
        "obs = env.reset()\n",
        "\n",
        "# Query the agent (stochastic action here)\n",
        "action, _ = model.predict(obs, deterministic=False)"
      ],
      "metadata": {
        "id": "Ycq5uSLxml0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 動画撮影の準備 <!-- ### Prepare video recording -->"
      ],
      "metadata": {
        "id": "PuQ0j75MpHB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# フェイク画面のセットアップ，そうしないとレンダリングに失敗する\n",
        "import os\n",
        "\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ[\"DISPLAY\"] = \":1\""
      ],
      "metadata": {
        "id": "v5_33ibLmmxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "from pathlib import Path\n",
        "\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "\n",
        "def show_videos(video_path=\"\", prefix=\"\"):\n",
        "    \"\"\"\n",
        "    https://github.com/eleurent/highway-env より援用\n",
        "\n",
        "    :param video_path: (str) 動画が格納されているフォルダのパス\n",
        "    :param prefix: (str) この接頭辞のついた動画のみを表示する\n",
        "    \"\"\"\n",
        "    html = []\n",
        "    for mp4 in Path(video_path).glob(\"{}*.mp4\".format(prefix)):\n",
        "        video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "        html.append(\n",
        "            \"\"\"<video alt=\"{}\" autoplay\n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                </video>\"\"\".format(\n",
        "                mp4, video_b64.decode(\"ascii\")\n",
        "            )\n",
        "        )\n",
        "    ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
      ],
      "metadata": {
        "id": "5dyG3VChpJBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
        "\n",
        "\n",
        "def record_video(env_id, model, video_length=500, prefix=\"\", video_folder=\"videos/\"):\n",
        "    \"\"\"\n",
        "    :param env_id: (str)\n",
        "    :param model: (RL model)\n",
        "    :param video_length: (int)\n",
        "    :param prefix: (str)\n",
        "    :param video_folder: (str)\n",
        "    \"\"\"\n",
        "    eval_env = DummyVecEnv([lambda: gym.make(env_id, render_mode=\"rgb_array\")])\n",
        "    # Start the video at step=0 and record 500 steps\n",
        "    eval_env = VecVideoRecorder(\n",
        "        eval_env,\n",
        "        video_folder=video_folder,\n",
        "        record_video_trigger=lambda step: step == 0,\n",
        "        video_length=video_length,\n",
        "        name_prefix=prefix,\n",
        "    )\n",
        "\n",
        "    obs = eval_env.reset()\n",
        "    for _ in range(video_length):\n",
        "        action, _ = model.predict(obs)\n",
        "        obs, _, _, _ = eval_env.step(action)\n",
        "\n",
        "    # Close the video recorder\n",
        "    eval_env.close()"
      ],
      "metadata": {
        "id": "VNuNt-fvpLLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "record_video(\"LunarLander-v3\", model, video_length=500, prefix=\"LunarLander-v3\")"
      ],
      "metadata": {
        "id": "gzVaiVO2pN-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_videos(video_path=\"videos\", prefix=\"LunarLander-v3\")"
      ],
      "metadata": {
        "id": "CMEirPUQpWFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NvYYRG53p2t_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 別のゲームタイトルやモデルを試す"
      ],
      "metadata": {
        "id": "gkOX8QlA_e2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "game_id = 'Breakout'  # 'CartPole-v2', 'LunarLander-v2', 'Tennis'\n",
        "game_id = 'Tennis'\n",
        "#game_id = 'Boxing'\n",
        "#game_id = 'Gopher'\n",
        "\n",
        "# 途中経過 `checkpoint` を 5000 ステップ毎に保存\n",
        "checkpoint_callback = CheckpointCallback(\n",
        "    save_freq=5000, save_path=\"./logs/\", name_prefix=\"rl_model\")\n",
        "\n",
        "# モデルを定期的に評価，最適モデルと評価を保存\n",
        "# モニターラッパーを使用して，エピソードの統計情報を報告\n",
        "eval_env = Monitor(gym.make(game_id))\n",
        "\n",
        "# 評価のために決定論的な行動を行う\n",
        "eval_callback = EvalCallback(\n",
        "    eval_env,\n",
        "    best_model_save_path=\"./logs/\",\n",
        "    log_path=\"./logs/\",\n",
        "    eval_freq=2000,\n",
        "    deterministic=True,\n",
        "    render=False)\n",
        "\n",
        "# 動作主 (エージェント) を訓練\n",
        "# PPO, A2C, DDPG, DQN, SAC\n",
        "model = PPO(\"MlpPolicy\", game_id, verbose=1)\n",
        "model.learn(total_timesteps=20000, callback=[checkpoint_callback, eval_callback])\n",
        "\n",
        "# Retrieve and reset the environment\n",
        "env = model.get_env()\n",
        "obs = env.reset()\n",
        "\n",
        "# Query the agent (stochastic action here)\n",
        "action, _ = model.predict(obs, deterministic=False)"
      ],
      "metadata": {
        "id": "V79lzmdX8WxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "record_video(game_id, model, video_length=500, prefix=game_id)\n",
        "show_videos(video_path=\"videos\", prefix=game_id)"
      ],
      "metadata": {
        "id": "UIFfffhy9Wl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# さらに別のゲームタイトルやモデルを試す"
      ],
      "metadata": {
        "id": "RIYpAk5Y_nQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "game_id = 'Breakout'  # 'CartPole-v2', 'LunarLander-v2', 'Tennis'\n",
        "game_id = 'Tennis'\n",
        "#game_id = 'Boxing'\n",
        "#game_id = 'Gopher'\n",
        "\n",
        "# 途中経過 `checkpoint` を 5000 ステップ毎に保存\n",
        "checkpoint_callback = CheckpointCallback(\n",
        "    save_freq=5000, save_path=\"./logs/\", name_prefix=\"rl_model\")\n",
        "\n",
        "# モデルを定期的に評価，最適モデルと評価を保存\n",
        "# モニターラッパーを使用して，エピソードの統計情報を報告\n",
        "eval_env = Monitor(gym.make(game_id))\n",
        "\n",
        "# 評価のために決定論的な行動を行う\n",
        "eval_callback = EvalCallback(\n",
        "    eval_env,\n",
        "    best_model_save_path=\"./logs/\",\n",
        "    log_path=\"./logs/\",\n",
        "    eval_freq=2000,\n",
        "    deterministic=True,\n",
        "    render=False)\n",
        "\n",
        "# 動作主 (エージェント) を訓練\n",
        "# PPO, A2C, DDPG, DQN, SAC\n",
        "model = PPO(\"MlpPolicy\", game_id, verbose=1)\n",
        "model.learn(total_timesteps=20000, callback=[checkpoint_callback, eval_callback])\n",
        "\n",
        "# Retrieve and reset the environment\n",
        "env = model.get_env()\n",
        "obs = env.reset()\n",
        "\n",
        "# Query the agent (stochastic action here)\n",
        "action, _ = model.predict(obs, deterministic=False)\n"
      ],
      "metadata": {
        "id": "cdRS-0ZE-B2U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}