{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2023notebooks/2023_1123Stroop_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96ca70b8-9927-4d31-89e5-f4ee93851bb2",
      "metadata": {
        "id": "96ca70b8-9927-4d31-89e5-f4ee93851bb2"
      },
      "source": [
        "# Stroop effect\n",
        "\n",
        "# 文献\n",
        "\n",
        "* J. Ridley Stroop (1935) [STUDIES OF INTERFERENCE IN SERIAL VERBAL REACTIONS](https://psychclassics.yorku.ca/Stroop/), Journal of Experimental Psychology, 18, 643-662.\n",
        "\n",
        "<center>\n",
        "<div style=\"width:88%;font-color:teal;\">\n",
        "\n",
        "語の名前と異なる色で印刷された色名語音読 (RCNd) 条件 (100 刺激，単位:秒) と黒インクで印字された色名語音読条件 (RCNb)<br/>\n",
        "**RCNd** 印刷色が文字と不一致の場合の色名文字音読条件，\n",
        "**RCNb** 黒インクで印字された色名文字音読条件，\n",
        "**No. Ss** 被験者数，**s** 標準偏差，**D** 差分，**D/PEd** 差分を確率誤差で除した値<br/>\n",
        "Stroop (1935) Table 1.\n",
        "</div>\n",
        "<img src=\"https://raw.githubusercontent.com/ShinAsakawa/ShinAsakawa.github.io/master/assets/1935Stroop_tab1.jpg\" style=\"width:77%\">\n",
        "<!-- <img src=\"1935Stroop_tab1.jpg\" width=\"77%\">-->\n",
        "<div style=\"width:88%;font-color:teal;\">\n",
        "\n",
        "正方形 ■ の色名呼称条件と，他の色で印刷された語の色名音読条件<br/>\n",
        "**NCWd**: 色名呼称時に文字が色と異なる条件，**NC** 色名呼称条件.\n",
        "Stroop (1935) Table 3.    \n",
        "</div>    \n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/ShinAsakawa/ShinAsakawa.github.io/master/assets/1935Stroop_tab3.jpg\" style=\"width:77%\">\n",
        "<!-- <img src=\"1935Stroop_tab3.jpg\" width=\"77%\"> -->\n",
        "</center>\n",
        "\n",
        "* **NC**: 色名呼称 Naming Colors.\n",
        "* **NCWd**: 色名呼称時に文字が色と異なる場合 Naming the Colors of the Print of Words Where the Color of the Print and the Word are Different.\n",
        "* **RCNb** 黒で書かれた色名を読む Reading Color Names Printed in Black Ink.\n",
        "* **RCNd** 色名を読むが，印刷色と単語名が不一致 Reading Color Names Where the Color of the Print and the Word are Different.\n",
        "* **D** 差分 Difference.\n",
        "* **D/P Ed** 差分を確率誤差で除した値 Difference divided by the probable error of the difference.\n",
        "* **M & F** 男性と女性 Males and Females.\n",
        "* **P Ed**: 差分の確率誤差 Probable error of the difference.\n",
        "* **s**: 標準偏差 Sigma or standard deviation.\n",
        "* **s / m**:  Standard deviation divided by the mean.\n",
        "\n",
        "\n",
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/ShinAsakawa/ShinAsakawa.github.io/master/assets/2003Roelofs_stroop_fig9.jpg\" style=\"width:44%\">\n",
        "<!-- <img src=\"2003Roelofs_stroop_fig9.jpg\" width=\"44%\"><br/> -->\n",
        "<div style=\"width:77%;background-color:lavendar;\">\n",
        "\n",
        "Stroop 課題における，単語計画と実行制御。\n",
        "ヒトの左半球の側面図 (上) と 中央 (下)。\n",
        "単語計画系は，色知覚 (cp)，概念同定 (ci)，レンマ検索 (lr)，単語携帯符号化 (wfe)，構音処理 (art) を\n",
        "介して色名呼称へと至る。\n",
        "単語形態知覚 (wfp) は，語彙と形態と並列的に至る。\n",
        "単語音読は，最小限 wfp, wfe, art を含む。\n",
        "実行系は前帯状回にあり，目標と入力制御に関与する。\n",
        "<!-- Figure 9. Word planning and executive control in the Stroop task.\n",
        "Lateral view (top panel) and medial view (bottom panel) of the left hemisphere of the human brain.\n",
        "\n",
        "The word-planning system achieves color naming through color perception (cp), conceptual identific\n",
        "ation (ci), lemma retrieval (lr), word-form encoding (wfe), and articulatory processing (art);\n",
        "word-form perception (wfp) activates lemmas and word forms in parallel.\n",
        "Word reading minimally involves wfp, wfe, and art.\n",
        "The executive system centered on the anterior cingulate achieves goal and input control. -->\n",
        "出典: Roelofs (2003) __Goal-Referenced Selection of Verbal Action: Modeling Attentional Control in the Stroop Task__, Psychological Review, 2003, Vol. 110, No. 1, 88–125.\n",
        "</div>\n",
        "</center>    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08eabe4a-ebac-4d5c-97f2-f33578180cb9",
      "metadata": {
        "id": "08eabe4a-ebac-4d5c-97f2-f33578180cb9"
      },
      "source": [
        "# 0 下準備"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc1a11c9-fdf7-420d-bdd0-72bf5c4eb10d",
      "metadata": {
        "id": "fc1a11c9-fdf7-420d-bdd0-72bf5c4eb10d"
      },
      "source": [
        "## 0.1 ライブラリの輸入"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc1982d5-b8ec-4d17-83f7-cabacc3e907a",
      "metadata": {
        "tags": [],
        "id": "bc1982d5-b8ec-4d17-83f7-cabacc3e907a"
      },
      "outputs": [],
      "source": [
        "%config InlineBackend.figure_format = 'retina'\n",
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "import IPython\n",
        "isColab = 'google.colab' in str(IPython.get_ipython())\n",
        "\n",
        "if isColab:\n",
        "    !pip install --upgrade termcolor==1.1\n",
        "from termcolor import colored\n",
        "\n",
        "try:\n",
        "    import japanize_matplotlib\n",
        "except ImportError:\n",
        "    !pip install japanize_matplotlib\n",
        "    import japanize_matplotlib\n",
        "\n",
        "try:\n",
        "    import bit\n",
        "except ImportError:\n",
        "    !pip install ipynbname --upgrade\n",
        "    !git clone https://github.com/ShinAsakawa/bit.git\n",
        "    import bit\n",
        "\n",
        "import os\n",
        "HOME = os.environ['HOME']\n",
        "\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88a88a51-740c-4b6d-8aa2-46a49ef6400f",
      "metadata": {
        "id": "88a88a51-740c-4b6d-8aa2-46a49ef6400f"
      },
      "source": [
        "## 0.1 乱数系列発生器の種を設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b07c9ae-77ec-485e-ad0e-5da075c036e2",
      "metadata": {
        "tags": [],
        "id": "2b07c9ae-77ec-485e-ad0e-5da075c036e2"
      },
      "outputs": [],
      "source": [
        "# 乱数のシードを設定\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "\n",
        "seed=42\n",
        "torch.manual_seed(seed=seed)\n",
        "np.random.seed(seed=seed)\n",
        "random.seed(seed)\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "964697f0-0fc6-4746-a5aa-b37a01c102c6",
      "metadata": {
        "id": "964697f0-0fc6-4746-a5aa-b37a01c102c6"
      },
      "source": [
        "# 1 データセットの定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ae93b24-0768-4d97-b42b-54703cb93db1",
      "metadata": {
        "tags": [],
        "id": "6ae93b24-0768-4d97-b42b-54703cb93db1"
      },
      "outputs": [],
      "source": [
        "from bit import get_text_img\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "from glob import  glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from torchvision.transforms import v2\n",
        "\n",
        "\n",
        "class stroop_Dataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 dataset_name:str='train'):\n",
        "\n",
        "        super().__init__()\n",
        "        self.dataset_name = 'train' if dataset_name == 'train' else 'val'\n",
        "\n",
        "        self.width, self.height = 224, 224\n",
        "        self.bgcolor = [255,255,255]\n",
        "\n",
        "        # 色刺激情報\n",
        "        self.colors = ['black', 'red', 'green', 'blue', 'yellow']\n",
        "\n",
        "        # 文字刺激情報，上の色刺激情報と一対一対応\n",
        "        self.words  = ['黒', '赤', '緑', '青', '黄','■']\n",
        "\n",
        "        # 認識の一般性を確保するために複数の文字サイズを用いる\n",
        "        self.font_sizes=[42, 56, 70, 84, 98, 112]\n",
        "\n",
        "        # 認識の一般性を確保するために複数の文字フォントを用いる\n",
        "        # 無料で公開されている Noto フォントを用いる。\n",
        "        # 下のループを実行することで 14 種類のフォントが登録される\n",
        "        # NotoSerif は明朝体，NotoSans はゴチック体と考えれば良い\n",
        "        # これら両書体について，各々 7 種類の太さが定義されている\n",
        "        fonts = []\n",
        "        for font_size in self.font_sizes:\n",
        "            _fonts = bit.get_notojp_fonts(fontsize=font_size, verbose=False)\n",
        "            for _fontname, _font in _fonts.items():\n",
        "                font_name = str(f'{font_size:03d}')+_fontname\n",
        "\n",
        "                if dataset_name == 'train':\n",
        "                    fonts.append((font_name, _font))\n",
        "                elif 'Regular' in _fontname:\n",
        "                    fonts.append((font_name, _font))\n",
        "\n",
        "        self.fonts = fonts\n",
        "\n",
        "        # 上記の，文字 X 色 X サイズ X フォント で条件を作成\n",
        "        # 文字呼称条件と色名呼称条件とが Stroop 効果である。\n",
        "        # 理論上，サイズ同定条件，フォント識別問題でも同様の実験が成り立つが今回は採用せず\n",
        "        cond = []\n",
        "        for font in fonts:\n",
        "            size = int(font[0][:3])\n",
        "            for color in self.colors:\n",
        "                for word in self.words:\n",
        "                    # 条件は (色，文字，フォントサイズ，フォント書体) の 4 連 tuple\n",
        "                    cond.append((color, word, size, font))\n",
        "        self.cond = cond\n",
        "\n",
        "        self.affine = v2.RandomAffine(degrees=(-5, 5), translate=(0.1, 0.1), fill=list(np.array(self.bgcolor)/255))\n",
        "        #self.affine = v2.RandomAffine(degrees=(-5, 5), translate=(0.05, 0.05))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.colors) * len(self.words) * len(self.fonts)\n",
        "        #return len(self.cond)\n",
        "\n",
        "    def __getitem__(self, idx:int):\n",
        "\n",
        "        color_ = self.cond[idx][0]\n",
        "        word_  = self.cond[idx][1]\n",
        "        size_  = self.cond[idx][2]\n",
        "        font_name  = self.cond[idx][3][0]\n",
        "        font_  = self.cond[idx][3][1]\n",
        "\n",
        "        color_idx = self.colors.index(color_)\n",
        "        word_idx  = self.words.index(word_)\n",
        "        size_idx  = self.font_sizes.index(size_)\n",
        "\n",
        "        # 条件に従った画像を 1 枚生成\n",
        "        img, draw_canvas, bbox = get_text_img(\n",
        "            text=word_, color=color_, draw_bbox=False, font=font_)\n",
        "\n",
        "        # 画像を torch.Tensor に変換しないと，DataLoader でハンドリングできない。\n",
        "        # このため一旦 torch.tensor に変換している\n",
        "        _img = torch.tensor(\n",
        "            (np.array(img)/255).clip(0,1).transpose(2,0,1),\n",
        "            device=device,\n",
        "            dtype=torch.float32,\n",
        "        )\n",
        "\n",
        "        if self.dataset_name == 'train':\n",
        "            _img = self.affine(_img)\n",
        "\n",
        "        return _img, {'color':self.colors.index(color_),\n",
        "                     'word':self.words.index(word_),\n",
        "                     'font_size':size_, 'font_name':font_name}\n",
        "\n",
        "stroop_ds = stroop_Dataset()\n",
        "stroop_val_ds = stroop_Dataset(dataset_name='val')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "853f79f2-cae6-4581-b047-3503199dbcda",
      "metadata": {
        "id": "853f79f2-cae6-4581-b047-3503199dbcda"
      },
      "source": [
        "## 1.1 定義したデータセットの視覚化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86f02e07-26df-4488-89d0-fe4620c1b072",
      "metadata": {
        "tags": [],
        "id": "86f02e07-26df-4488-89d0-fe4620c1b072"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(6, 6, figsize=(14, 10))\n",
        "i, j = 0, 0\n",
        "j_max = 6\n",
        "\n",
        "ds = stroop_ds # or stroop_val_ds\n",
        "#ds = stroop_val_ds\n",
        "Ns = np.random.permutation(ds.__len__())\n",
        "for idx in Ns[:36]:\n",
        "#for idx in range(30):\n",
        "    img, y = ds.__getitem__(idx)\n",
        "    _img = img.detach().squeeze(0).cpu().numpy().transpose(1,2,0) # * 255\n",
        "    print(idx,y)\n",
        "    ax[i,j].imshow(_img)\n",
        "    ax[i,j].set_xticks([])\n",
        "    ax[i,j].set_yticks([])\n",
        "    j += 1\n",
        "    if j == j_max:\n",
        "        i+=1; j=0\n",
        "\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a72a303-fe73-4505-8b03-1d099b692c2f",
      "metadata": {
        "id": "5a72a303-fe73-4505-8b03-1d099b692c2f"
      },
      "source": [
        "## 1.2 訓練用，検証用データへの分割とデータローダ用意"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "614b0a9d-7333-496a-91db-d4d0159cddc8",
      "metadata": {
        "tags": [],
        "id": "614b0a9d-7333-496a-91db-d4d0159cddc8"
      },
      "outputs": [],
      "source": [
        "train_ds = stroop_ds\n",
        "val_ds = stroop_val_ds\n",
        "\n",
        "# 並列計算のために collation 関数を定義\n",
        "def _collate_fn(batch):\n",
        "    inps, tgts = list(zip(*batch))\n",
        "    inps = list(inps)\n",
        "    tgts = list(tgts)\n",
        "    return inps, tgts\n",
        "\n",
        "# 訓練データセット用データローダ\n",
        "train_dl = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=_collate_fn\n",
        ")\n",
        "\n",
        "# 検証データセット用データローダ\n",
        "val_dl = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=_collate_fn\n",
        ")\n",
        "\n",
        "# 後に使用するために，データローダに名前を加えておく\n",
        "train_dl.name = 'train'\n",
        "val_dl.name = 'val'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86b1b20b-dae6-4305-a03f-125ef6a6ac81",
      "metadata": {
        "id": "86b1b20b-dae6-4305-a03f-125ef6a6ac81"
      },
      "source": [
        "## 1.3 公開されている訓練済一般画像認識 (ImageNet) モデルの読み込み，最終層の付け替え"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "cnn_col = torchvision.models.mobilenet_v3_small(weights=\"DEFAULT\")\n",
        "#cnn_col = torchvision.models.resnet50(weights=\"DEFAULT\")\n",
        "cnn_col.eval()"
      ],
      "metadata": {
        "id": "eTJRwachbUG6"
      },
      "id": "eTJRwachbUG6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a12f2a6-73c6-42ac-b489-b3d3743bf8d6",
      "metadata": {
        "tags": [],
        "id": "7a12f2a6-73c6-42ac-b489-b3d3743bf8d6"
      },
      "outputs": [],
      "source": [
        "# 各モデルを定義し，訓練済み結合係数をダウンロード\n",
        "import copy\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "\n",
        "#cnn_col = models.resnet50(weights=\"DEFAULT\")\n",
        "#cnn_wrd = models.resnet50(weights=\"DEFAULT\")\n",
        "#cnn_col = models.resnet18(weights=\"DEFAULT\")\n",
        "#cnn_wrd = models.resnet18(weights=\"DEFAULT\")\n",
        "cnn_col = models.efficientnet_v2_s(weights=\"DEFAULT\").to(device)\n",
        "cnn_wrd = models.efficientnet_v2_s(weights=\"DEFAULT\").to(device)\n",
        "# cnn_col = torchvision.models.mobilenet_v3_small(weight=\"DEFAULT\")\n",
        "# cnn_wrd = torchvision.models.mobilenet_v3_small(weight=\"DEFAULT\")\n",
        "\n",
        "# parameters_col = {name:param for name, param in cnn_col.named_parameters()}\n",
        "# modules_col = {name:param for name, param in cnn_col.named_modules()}\n",
        "# parameters_wrd = {name:param for name, param in cnn_wrd.named_parameters()}\n",
        "# modules_wrd = {name:param for name, param in cnn_wrd.named_modules()}\n",
        "\n",
        "# cnn model の最終層入れ替え\n",
        "#cnn_col.fc = torch.nn.Linear(in_features=2048, out_features=len(stroop_ds.colors)) # resnet50\n",
        "#cnn_wrd.fc = torch.nn.Linear(in_features=2048, out_features=len(stroop_ds.words))\n",
        "# cnn_col.classifier[-1] = torch.nn.Linear(in_features=1024, out_features=len(stroop_ds.colors)) # mobilenet v3 small\n",
        "# cnn_wrd.classifier[-1] = torch.nn.Linear(in_features=1024, out_features=len(stroop_ds.words))\n",
        "cnn_col.classifier[-1] = torch.nn.Linear(in_features=1280, out_features=len(stroop_ds.colors)).to(device) # efficientnet v2\n",
        "cnn_wrd.classifier[-1] = torch.nn.Linear(in_features=1280, out_features=len(stroop_ds.words)).to(device)\n",
        "\n",
        "# 転移学習で学習させるパラメータを `params_to_update` に格納\n",
        "params_to_update_wrd = []\n",
        "params_to_update_col = []\n",
        "\n",
        "# 学習させるパラメータ名\n",
        "update_param_names_wrd = [\"classifier.1.weight\", \"classifier.1.bias\"]\n",
        "update_param_names_col = [\"classifier.1.weight\", \"classifier.1.bias\"]\n",
        "# update_param_names_wrd = [\"classifier.3.weight\", \"classifier.3.bias\"]\n",
        "# update_param_names_col = [\"classifier.3.weight\", \"classifier.3.bias\"]\n",
        "\n",
        "# 学習させるパラメータ以外は勾配計算をなくし、変化しないように設定\n",
        "# cnn_col\n",
        "for name, param in cnn_col.named_parameters():\n",
        "    if name in update_param_names_col:\n",
        "        param.requires_grad = True\n",
        "        params_to_update_col.append(param)\n",
        "        print(name)\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "\n",
        "for name, param in cnn_col.state_dict().items():\n",
        "    if name in update_param_names_col:\n",
        "        param.requires_grad = True\n",
        "        params_to_update_col.append(param)\n",
        "        print(name)\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "\n",
        "\n",
        "# cnn_wrd\n",
        "for name, param in cnn_wrd.named_parameters():\n",
        "    if name in update_param_names_wrd:\n",
        "        param.requires_grad = True\n",
        "        #params_to_update_wrd.append((name, param))\n",
        "        params_to_update_wrd.append(param)\n",
        "        print(name)\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "\n",
        "for name, param in cnn_wrd.state_dict().items():\n",
        "    if name in update_param_names_wrd:\n",
        "        param.requires_grad = True\n",
        "        #params_to_update_wrd.append((name,param))\n",
        "        params_to_update_wrd.append(param)\n",
        "        print(name)\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "\n",
        "# params_to_updateの中身を確認\n",
        "#print(params_to_update_col)\n",
        "#print(params_to_update_wrd)\n",
        "# for param in params_to_update_wrd:\n",
        "#     print(param[0], type(param[1]))\n",
        "#print(f'id(cnn_wrd):{id(cnn_wrd)}, id(cnn_col):{id(cnn_col)}')\n",
        "\n",
        "# 確認作業\n",
        "for (name1, param1), (name2, param2) in zip(cnn_wrd.named_parameters(), cnn_wrd.named_parameters()):\n",
        "    if param1.requires_grad == True or param2.requires_grad == True:\n",
        "        print(name1, name2)\n",
        "        #print(name1, param1.requires_grad, name2, param2.requires_grad)\n",
        "\n",
        "print(cnn_col.classifier)\n",
        "params_to_update_col"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5636c0c8-950a-4f81-9963-cffbcfac1e59",
      "metadata": {
        "id": "5636c0c8-950a-4f81-9963-cffbcfac1e59"
      },
      "source": [
        "## 1.4 訓練関数の定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd304b66-f87b-442b-8594-454ab2486ed7",
      "metadata": {
        "tags": [],
        "id": "dd304b66-f87b-442b-8594-454ab2486ed7"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "col_optimizer = torch.optim.Adam(params=params_to_update_col, lr=0.001)\n",
        "\n",
        "# モデルを学習させる関数\n",
        "def train_model(\n",
        "    model:torchvision.models=cnn_col,\n",
        "    target:str='color',  # ['color', 'word']\n",
        "    train_dl:torch.utils.data.dataloader=train_dl,\n",
        "    val_dl:torch.utils.data.dataloader=val_dl,\n",
        "    criterion:torch.nn.modules=criterion,\n",
        "    optimizer:torch.optim=col_optimizer,\n",
        "    epochs:int=5,\n",
        "    losses:dict=None,\n",
        "    accs:list=None):\n",
        "\n",
        "    if losses == None:\n",
        "        losses = {'train':[], 'val':[]}\n",
        "    if accs == None:\n",
        "        accs = {'train':[],'val':[]}\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        print(f'エポック {epoch+1:02d}/{epochs:02d}', end=\" \")\n",
        "        for phase in [train_dl, val_dl]:\n",
        "            if phase.name == 'train':\n",
        "                model.train()  # モデルを訓練モードに\n",
        "            else:\n",
        "                model.eval()   # モデルを検証モードに\n",
        "\n",
        "            epoch_loss = 0.     # epoch ごとの損失和\n",
        "            epoch_corrects = 0  # epoch ごとの正解数\n",
        "\n",
        "            # 未学習時の検証性能を確かめるため epoch=0 時の訓練は省略\n",
        "            if (epoch == 0) and (phase.name == 'train'):\n",
        "                continue\n",
        "\n",
        "            # データローダからミニバッチを取り出すループ\n",
        "            for inputs, labels in phase:\n",
        "                inputs = torch.tensor(np.array([inp.detach().cpu().numpy() for inp in inputs])).float().to(device)\n",
        "                labels = torch.LongTensor([label[target] for label in labels]).to(device)\n",
        "\n",
        "                optimizer.zero_grad() # optimizerを初期化\n",
        "                # 順伝搬（forward）計算\n",
        "                with torch.set_grad_enabled(phase.name =='train'):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)  # 損失を計算\n",
        "                    _, preds = torch.max(outputs, 1)   # ラベルを予測\n",
        "\n",
        "                    # 訓練時はバックプロパゲーション\n",
        "                    if phase.name == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                    epoch_loss += loss.item() * inputs.size(0)\n",
        "                    # 正解数の合計を更新\n",
        "                    epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # epoch ごとの loss と正解率を表示\n",
        "            N = train_ds.__len__() if phase.name == 'train' else val_ds.__len__()\n",
        "            epoch_loss = epoch_loss / N\n",
        "            epoch_acc = epoch_corrects.double() / N\n",
        "\n",
        "            losses[phase.name].append(epoch_loss)\n",
        "            accs[phase.name].append(epoch_acc.detach().cpu().numpy())  #[0])\n",
        "\n",
        "            print(f'{phase.name:5s}',\n",
        "                  f'損失: {epoch_loss:.4f}',\n",
        "                  f'精度: {epoch_acc:.3f}', end=\" \")\n",
        "        print()\n",
        "    return losses, accs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d782bcff-812b-4fe9-813b-f8b5fa0254bd",
      "metadata": {
        "id": "d782bcff-812b-4fe9-813b-f8b5fa0254bd"
      },
      "source": [
        "## 1.5 検証データセットを用いた評価関数の定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7995945d-c038-404c-9143-2e63774e5d57",
      "metadata": {
        "tags": [],
        "id": "7995945d-c038-404c-9143-2e63774e5d57"
      },
      "outputs": [],
      "source": [
        "def _eval(\n",
        "    model:torchvision.models=cnn_col,\n",
        "    target:str='color',  # ['color', 'word']\n",
        "    ds:torch.utils.data.dataset=val_ds,\n",
        "    isDisplay:bool=False):\n",
        "\n",
        "    model.eval()\n",
        "    n_corrects = 0\n",
        "    Outs = []\n",
        "    for idx in tqdm(range(ds.__len__())):\n",
        "        img, label = val_ds.__getitem__(idx)\n",
        "        out = model(img.unsqueeze(0))\n",
        "        _, pred = torch.max(out, 1)   # ラベルを予測\n",
        "        _pred = pred.detach().cpu().numpy()[0]\n",
        "        _tch = label[target]\n",
        "        tch_col, tch_wrd = label['color'], label['word']\n",
        "        isOK = _pred == _tch\n",
        "        if isOK:\n",
        "            n_corrects += 1\n",
        "        if not isOK:\n",
        "            if target == 'color':\n",
        "                _pred_ = stroop_ds.colors[_pred]\n",
        "            else:\n",
        "                _pred_ = stroop_ds.words[_pred]\n",
        "            Outs.append({'idx':idx, '正否':isOK, '出力':_pred_, '刺激色':stroop_ds.colors[tch_col], '刺激字':stroop_ds.words[tch_wrd]})\n",
        "            if isDisplay:\n",
        "                plt.figure(figsize=(3,3))\n",
        "                plt.title(f'idx:{idx}, 予測:{_pred_}, 色:{stroop_ds.colors[tch_col]}, 文字:{stroop_ds.words[tch_wrd]}')\n",
        "                plt.imshow(img.detach().cpu().numpy().transpose(1,2,0))\n",
        "                plt.show()\n",
        "\n",
        "    print(f'正解率: {(n_corrects / val_ds.__len__()) * 100:.3f} %')\n",
        "    #print(stroop_ds.words)\n",
        "    return Outs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ff526a7-a06f-42bc-b8b9-79ad759b5fd5",
      "metadata": {
        "id": "9ff526a7-a06f-42bc-b8b9-79ad759b5fd5"
      },
      "source": [
        "# 2 訓練の実施"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31c861cb-d412-4afe-b18f-226f4810d406",
      "metadata": {
        "tags": [],
        "id": "31c861cb-d412-4afe-b18f-226f4810d406"
      },
      "outputs": [],
      "source": [
        "#%%time\n",
        "print('# 色名呼称課題')\n",
        "_optimizer = torch.optim.Adam(params=params_to_update_col, lr=0.001)\n",
        "#_optimizer = torch.optim.Adam(params=[cnn_col.classifier[1].bias, cnn_col.classifier[1].weight], lr=0.001)\n",
        "#col_optimizer = torch.optim.Adam(params=params_to_update_col, lr=0.001)\n",
        "losses_col = {'train':[], 'val':[]}\n",
        "accs_col = {'train':[],'val':[]}\n",
        "losses_col, accs_col = train_model(\n",
        "    model=cnn_col,\n",
        "    #model=cnn_col,\n",
        "    target='color',\n",
        "    optimizer=_optimizer,\n",
        "    losses=losses_col,\n",
        "    accs=accs_col,\n",
        "    epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e121a996-785f-4008-9485-9a9150f405d2",
      "metadata": {
        "tags": [],
        "id": "e121a996-785f-4008-9485-9a9150f405d2"
      },
      "outputs": [],
      "source": [
        "_eval(target='color', model=cnn_col, isDisplay=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9f65555-5e51-4e3a-916d-2d7c4337b0b7",
      "metadata": {
        "tags": [],
        "id": "e9f65555-5e51-4e3a-916d-2d7c4337b0b7"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "print('# 文字音読課題')\n",
        "_optimizer = torch.optim.Adam(params=params_to_update_wrd, lr=0.0001)\n",
        "#_optimizer = torch.optim.Adam(params=params_to_update_wrd, lr=0.001)\n",
        "_losses = {'train':[], 'val':[]}\n",
        "_accs = {'train':[],'val':[]}\n",
        "losses_col, accs_col = train_model(\n",
        "    model=cnn_wrd,\n",
        "    target='word',\n",
        "    optimizer=_optimizer,\n",
        "    losses=_losses,\n",
        "    accs=_accs,\n",
        "    epochs=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fc0510b-1417-44cf-a800-e20e499669c2",
      "metadata": {
        "tags": [],
        "id": "6fc0510b-1417-44cf-a800-e20e499669c2"
      },
      "outputs": [],
      "source": [
        "_eval(target='word', model=cnn_wrd, isDisplay=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a983a00d-a8c1-475d-bb7c-385835c33614",
      "metadata": {
        "tags": [],
        "id": "a983a00d-a8c1-475d-bb7c-385835c33614"
      },
      "outputs": [],
      "source": [
        "_eval(target='color', model=cnn_col, isDisplay=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb39894f-ada9-4a97-b454-920614fe0110",
      "metadata": {
        "tags": [],
        "id": "bb39894f-ada9-4a97-b454-920614fe0110"
      },
      "outputs": [],
      "source": [
        "print(losses_col)  # 色名呼称条件の損失値の推移\n",
        "#print(losses_wrd)  # 文字音読条件の損失値の推移\n",
        "plt.plot(losses_col['train'],c='red', label='訓練データ')\n",
        "plt.plot(losses_col['val'],c='blue', label='検証データ')\n",
        "plt.title('色名呼称課題 損失値の変化')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "745ba619-f1ec-446a-bb45-2360192eff61",
      "metadata": {
        "tags": [],
        "id": "745ba619-f1ec-446a-bb45-2360192eff61"
      },
      "outputs": [],
      "source": [
        "plt.title('文字音読課題 損失値の変化')\n",
        "plt.plot(losses_wrd['train'], label='訓練データ', c='red')\n",
        "plt.plot(losses_wrd['val'], label='検証データ', c='blue')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3d0ad50-1422-48d8-84a3-2bce58c3853e",
      "metadata": {
        "tags": [],
        "id": "f3d0ad50-1422-48d8-84a3-2bce58c3853e"
      },
      "outputs": [],
      "source": [
        "outputs_col = _eval(target='color', model=cnn_col, isDisplay=True)\n",
        "outputs_wrd = _eval(target='word', model=cnn_wrd, isDisplay=True)\n",
        "print(outputs_wrd)\n",
        "print(stroop_ds.words)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7366f614-8769-4d36-b371-041b5fc070a0",
      "metadata": {
        "tags": [],
        "id": "7366f614-8769-4d36-b371-041b5fc070a0"
      },
      "source": [
        "## 2.4 保存"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c65b4c39-68ef-47e5-bd01-c63c67abe66b",
      "metadata": {
        "tags": [],
        "id": "c65b4c39-68ef-47e5-bd01-c63c67abe66b"
      },
      "outputs": [],
      "source": [
        "# 全体を保存して，model2 に再読み込み\n",
        "_fname = '2023_1114stroop_col_resnet50_full.pt'\n",
        "torch.save(cnn_col.state_dict(), _fname)\n",
        "model2 = models.resnet50(weights=\"DEFAULT\")\n",
        "model2.fc = torch.nn.Linear(in_features=2048, out_features=len(stroop_ds.colors))\n",
        "model2.load_state_dict(torch.load(_fname))\n",
        "model2.eval()\n",
        "_ = _eval(target='color', model=model2)\n",
        "\n",
        "_fname = '2023_1114stroop_wrd_resnet50_full.pt'\n",
        "torch.save(cnn_wrd.state_dict(), _fname)\n",
        "model2 = models.resnet50(weights=\"DEFAULT\")\n",
        "model2.fc = torch.nn.Linear(in_features=2048, out_features=len(stroop_ds.words))\n",
        "model2.load_state_dict(torch.load(_fname))\n",
        "model2.eval()\n",
        "_ = _eval(target='word', model=model2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7306b915-68f3-4216-95bb-ea4de93d3d72",
      "metadata": {
        "tags": [],
        "id": "7306b915-68f3-4216-95bb-ea4de93d3d72"
      },
      "outputs": [],
      "source": [
        "for (param0), (param1) in zip(cnn_col.parameters(), cnn_wrd.parameters()):\n",
        "#for (name0, param0), (name1, param1) in zip(cnn_col.named_parameters(), cnn_wrd.named_parameters()):\n",
        "    if not 'fc' in name0:\n",
        "        print(name0, (param0.data == param1.data).sum().detach().numpy() == param0.detach().numpy().size)\n",
        "    else:\n",
        "        print(name0, param0, param1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58824787-54a0-4a87-a195-7bf603ba49df",
      "metadata": {
        "tags": [],
        "id": "58824787-54a0-4a87-a195-7bf603ba49df"
      },
      "outputs": [],
      "source": [
        "# fc だけを保存して，model2 に再読み込み\n",
        "# _fname = '2023_1114stroop_col.pt'\n",
        "# torch.save(cnn_col.fc.state_dict(), _fname)\n",
        "# model2 = models.resnet50(weights=\"DEFAULT\")\n",
        "# model2.fc = torch.nn.Linear(in_features=2048, out_features=len(stroop_ds.colors))\n",
        "# model2.fc.load_state_dict(torch.load(_fname))\n",
        "# model2.eval()\n",
        "# _ = _eval(target='color', model=model2)\n",
        "\n",
        "_fname = '2023_1114stroop_wrd.pt'\n",
        "torch.save(cnn_wrd.fc.state_dict(), _fname)\n",
        "model2 = models.resnet50(weights=\"DEFAULT\")\n",
        "model2.fc = torch.nn.Linear(in_features=2048, out_features=len(stroop_ds.words))\n",
        "model2.fc.load_state_dict(torch.load(_fname))\n",
        "model2.eval()\n",
        "_ = _eval(target='word', model=model2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80f76e71-6a8b-40c2-8b56-3af6c2a074d3",
      "metadata": {
        "tags": [],
        "id": "80f76e71-6a8b-40c2-8b56-3af6c2a074d3"
      },
      "outputs": [],
      "source": [
        "_dic = torch.load(wrd_pt_fname)\n",
        "print(_dic)\n",
        "print(cnn_wrd.fc.state_dict())\n",
        "print(model2.fc.state_dict())\n",
        "model2.eval()\n",
        "_ = _eval(target='word', model=model2)\n",
        "cnn_wrd.eval()\n",
        "_ = _eval(target='word', model=cnn_wrd)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbf8fffd-baea-4823-91ae-ec06ec3cb108",
      "metadata": {
        "tags": [],
        "id": "fbf8fffd-baea-4823-91ae-ec06ec3cb108"
      },
      "outputs": [],
      "source": [
        "model3 = models.resnet50(weights=\"DEFAULT\")\n",
        "model3.fc = torch.nn.Linear(in_features=2048, out_features=len(stroop_ds.colors))\n",
        "\n",
        "#hoge_fname = '2023_1114hoge.pt'\n",
        "#torch.save(cnn_col.state_dict(), hoge_fname)\n",
        "model3.load_state_dict(torch.load(hoge_fname))\n",
        "#model3.eval()\n",
        "\n",
        "# torch.save(cnn_col.fc.state_dict(), hoge_fname)\n",
        "# model3.fc.load_state_dict(torch.load(hoge_fname))\n",
        "_ = _eval(target='color', model=cnn_col, isDisplay=False)\n",
        "_ = _eval(target='color', model=model3, isDisplay=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "776947b4-89dd-487c-bae2-e3dcc417d3a3",
      "metadata": {
        "tags": [],
        "id": "776947b4-89dd-487c-bae2-e3dcc417d3a3"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(checkpoint_path, model): # , optimizer):\n",
        "    state = {'state_dict': model.state_dict(),\n",
        "             #'optimizer' : optimizer.state_dict()\n",
        "            }\n",
        "    torch.save(state, checkpoint_path)\n",
        "    #print('model saved to %s' % checkpoint_path)\n",
        "\n",
        "def load_checkpoint(checkpoint_path, model): # , optimizer):\n",
        "    state = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(state['state_dict'])\n",
        "    #optimizer.load_state_dict(state['optimizer'])\n",
        "    #print('model loaded from %s' % checkpoint_path)\n",
        "\n",
        "\n",
        "\n",
        "model3 = models.resnet18(weights=\"DEFAULT\")\n",
        "model3.fc = torch.nn.Linear(in_features=512, out_features=len(stroop_ds.colors))\n",
        "\n",
        "save_checkpoint('2023_1113stroop_col.pt', cnn_col)\n",
        "#model3.load_state_dict(torch.load(hoge_fname))\n",
        "load_checkpoint('2023_1113stroop_col.pt', model3)\n",
        "_ = _eval(target='color', model=cnn_col, isDisplay=False)\n",
        "_ = _eval(target='color', model=model3, isDisplay=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c79e478c-6b65-4313-8afa-d4725dd3f0c3",
      "metadata": {
        "tags": [],
        "id": "c79e478c-6b65-4313-8afa-d4725dd3f0c3"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "class stroop_model(torch.nn.Module): # vision.models.resnet): # .Resnet):\n",
        "    def __init__(self,\n",
        "                 stroop_ds:torch.utils.data.dataset=stroop_ds)-> None:\n",
        "        super().__init__()\n",
        "\n",
        "        # get the pretrained ResNet18 network\n",
        "        self.cnn = models.resnet18(weights=\"DEFAULT\")\n",
        "\n",
        "        for name, param in model.cnn.named_parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        self.condition = 'color' # ['color', 'word']\n",
        "        self.cond_layer = torch.nn.Embedding(num_embeddings=2, embedding_dim=2)\n",
        "        self.cond_vec = self.set_condition(cond='color')\n",
        "\n",
        "        self.col_layer = torch.nn.Linear(in_features=512, out_features=len(stroop_ds.colors))\n",
        "        self.wrd_layer = torch.nn.Linear(in_features=512, out_features=len(stroop_ds.words))\n",
        "        self.out_layer = torch.nn.Linear(\n",
        "            in_features=len(stroop_ds.colors)+len(stroop_ds.words)+2, # 最後の 2 は条件ベクトル\n",
        "            out_features=len(stroop_ds.colors))\n",
        "\n",
        "    def set_condition(self, cond:str='color')-> None:\n",
        "        if cond == 'color':\n",
        "            self.cond_vec = self.cond_layer(torch.LongTensor([0]))\n",
        "        elif cond == 'word':\n",
        "            self.cond_vec = self.cond_layer(torch.LongTensor([1]))\n",
        "\n",
        "    def forward(self,\n",
        "                x:torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        size = x.size(0)\n",
        "        cond_vecs = self.cond_vec.repeat(size,1)\n",
        "\n",
        "        x = self.cnn.conv1(x)\n",
        "        x = self.cnn.bn1(x)\n",
        "        x = self.cnn.relu(x)\n",
        "        x = self.cnn.maxpool(x)\n",
        "\n",
        "        x = self.cnn.layer1(x)\n",
        "        x = self.cnn.layer2(x)\n",
        "        x = self.cnn.layer3(x)\n",
        "        x = self.cnn.layer4(x)\n",
        "\n",
        "        x = self.cnn.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        _col = self.col_layer(x)\n",
        "        _wrd = self.wrd_layer(x)\n",
        "\n",
        "        #x = self.out_layer(torch.cat((_col, _wrd, cond_vecs),dim=1))\n",
        "        x = self.cnn.fc(x)\n",
        "\n",
        "        return x"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}