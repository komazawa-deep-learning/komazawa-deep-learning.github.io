---
title: "第28回 2025年度開講 駒澤大学 人工知能"
author: "浅川 伸一"
layout: home
---

<div align="right">
<a href='mailto:educ0233@komazawa-u.ac.jp'>Shin Aasakawa</a>, all rights reserved.<br>
Date: 16/Jan/2026<br/>
Appache 2.0 license<br/>
</div>

<link href="/css/asamarkdown.css" rel="stylesheet">

* [課題提出用フォルダ](https://drive.google.com/drive/u/3/folders/1bO6HKr-B7-X7lZZHLZoMvFZMMABCKXrB){:target="_blank"}
* [課題提出用ファイル <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2025notebooks/2026_0116NB0000.ipynb)


# 本日のお品書き

* 総復習

# キーワード

## 前期
* 機械学習 ML:Machine Learning
* 人工知能 AI:Artificial Intelligence
* ニューラルネットワーク NN: Neural Networks
* ダートマス会議
* 深層学習 DL: Deep Learning
* 分類 Classification
* 回帰 Regression
* ロジスティック回帰 Logistic Regression
* サポートベクターマシン Support Vector Machines
* 教師あり学習 Supervised Learning
* 教師なし学習 Unsupervised Learning
* 次元圧縮 Demensionality Reductions
* 入力信号 Input Signals
* 出力信号 Output Signals
* 訓練データ，検査データ，検証データ Training dataset, Test dataset, Validation dataset
* 過学習 over-learning
* 精度 accuracy，適合度 precision，再現率 recall，F1 値 F1 value
* 主成分分析 PCA: Pricipal Component Analysis
* パーセプトロン Perceptrons
* ニューロン Neurons
* マッカロック・ピッツの形式ニューロン McCallogh and Pitts's Forma Neurons
* ソフトマックス関数 Softmax functions
* 誤差逆伝播(バックプロパゲーション)法 The Back-Propagation method
* 誤差関数, 損失関数，目的関数: Error, Loss, Objective functions
* 活性化関数 Activation functions
* 整流線型化関数 ReLU ReCtified Linear Unit
* シグモイド関数 The Sigmoid function
* 勾配降下法 Gradient Descent method
* ブラインド ハイカー アナロジー Blind Hiker's analogy
* 学習率 Learning Ratio
* 最適化 Optimization
* 勾配消失問題 Gradient vanishing Problems
* 勾配爆発問題 Gradient explosion Problems
* 信用割当問題 Credit Assignment Problems
* ネオコグニトロン Neocognitrons
* 畳み込みニューラルネットワーク CNN: Convolutional Neural Networks
* LeNet
* 交差エントロピー Cross Entropy
* 敵対生成ネットワーク Generative Adversarial Networks
* 拡散モデル Diffusion Models
* 基盤モデル Fundation Models
* 変分自己符号化器モデル VAE: Variational Auto-Encoders
* 変分下限 ELBO: Evidence Lower BOund
* ソーカル事件

## 後期

* 言語モデル LM: Language Models
* 系列予測 Serial predictions
* フーリエ変換 Fourier Transform
* 時系列分析 Time Series Analysis
* AR (Auto-Regresion), ARMA (Auto-Regression with Moving Average), ARIMA (Auto-Regression Integrated with Moving Average)
* カルマンフィルタ Kalman Filters
* SRN 単純再帰型ニューラルネットワーク Simple Recurrent Neural Networks
* LSTM 長-短期記憶 Long Short-Term Memory
* word2vec
* Transformer
* BERT
* 位置符号化器 Position Encoders
* GPT: Generative Pre-trained Transformer
* 埋め込みベクトル Embeddings (vectors)
* マルチヘッド注意 Multihead Attentions
* マスク化言語モデル Masked Language Models
* RAG: Retrieval Augmented Generations 検索拡張生成 
* プロンプトエンジニアリング Prompt Engineering
* 強化学習 RL:Reinforcement Learning
    * 動作主 Agent
    * 状態 State
    * 報酬 Reward
    * 価値 Value
    * 方針 Policy
    * 割引率 discount ratio
    * Q 関数 （行動価値関数）
    * SARSA
    * TD 学習
    * マルコフ決定過程 Markov Decision Processes
    * ベルマン方程式 Bellman's Equation
    * 信用割当問題 Credit Assignment Problems
    * エピソード（軌跡，ロールアウト），Episodes, Trajectories, Rollouts
    * 優位(アドバンテージ)関数，
    * 経験再生 Experience Replay
    * セルフプレイ Self Plays
    * DQN: Deep Q Networks
    * RLHF: 人間のフィードバックによる強化学習 Reinforcemnet Learning with Human Feedbacks
    * Agent57
* 世界モデル World models
* 視覚言語行動モデル VLA (Vision-Language-Action) models

# 本日の課題

1. 上記のキーワードのうち任意の ３ つを選び，chatGPT, Groq, Gemini などの AI に入力して，それぞれのキーワードの関連を出力させよ。その出力を記せ。
2. 1 で出力された文章に対して，異議や改善点を指摘し，AI による再出力を記せ。
3. 上記 3 つのキーワードと自分の関心のある心理学現象，あるいは心理学テーマとの関連から，研究計画を AI に立案させ，その回答を記せ。
4. 上の研究計画に対して，AI に批判，改善点，深堀り，などを指示し，AI からの回答を記せ。

<!-- 
# キーワード

* 機械学習 ML (Machine Learning): 人工知能の一分野。データを用いて予測，分類を行う手法の総称
* 人工知能 AI (Artificial Intelligence): 機械に知的振る舞いをさせる工学の一分野
* ニューラルネットワーク NN (Neural Networks) 生物の神経細胞の振る舞いをコンピュータ上で模倣することを目指す学問分野
* ダートマス会議：人工知能という言葉が初めて用いられた会議。AI の出発点とされる。それまでは，サイバネティクスと呼ばれていた
* 深層学習 DL(Deep Learning): ニューラルネットワークのうち，多層にしたモデル，とりわけ ３ 層以上のモデルを指す。
* 回帰 (Regression): データを予測する際に，予測すべき数が連続量である数理モデル
* 分類 (Classification): データを予測する際に，予測すべき数が離散量である数理モデル。
* ロジスティック回帰 (Logistic Regression): 連続量を離散量，典型的には 0 と 1 とに分け，それぞれの確率を計算する手法
* サポートベクターマシン Support Vector Machines
* 教師あり学習 Supervised Learning
* 教師なし学習 Unsupervised Learning
* 次元圧縮 Demensionality Reductions
* 入力信号 Input Signals
* 出力信号 Output Signals
* 訓練データ，検査データ，検証データ Training dataset, Test dataset, Validation dataset
* 過学習 over-learning
* 精度 accuracy，適合度 precision，再現率 recall，F1 値 F1 value
* 主成分分析 PCA: Pricipal Component Analysis
* パーセプトロン Perceptrons
* ニューロン Neurons
* マッカロック・ピッツの形式ニューロン McCallogh and Pitts's Forma Neurons
* ソフトマックス関数 Softmax functions
* 誤差逆伝播(バックプロパゲーション)法 The Back-Propagation method
* 誤差関数, 損失関数，目的関数: Error, Loss, Objective functions
* 活性化関数 Activation functions
* 整流線型化関数 ReLU ReCtified Linear Unit
* シグモイド関数 The Sigmoid function
* 勾配降下法 Gradient Descent method
* ブラインド ハイカー アナロジー Blind Hiker's analogy
* 学習率 Learning Ratio
* 最適化 Optimization
* 勾配消失問題 Gradient vanishing Problems
* 勾配爆発問題 Gradient explosion Problems
* 信用割当問題 Credit Assignment Problems
* ネオコグニトロン Neocognitrons
* 畳み込みニューラルネットワーク CNN: Convolutional Neural Networks
* LeNet
* 交差エントロピー Cross Entropy
* 敵対生成ネットワーク Generative Adversarial Networks
* 拡散モデル Diffusion Models
* 基盤モデル Fundation Models
* 変分自己符号化器モデル VAE: Variational Auto-Encoders
* 変分下限 ELBO: Evidence Lower BOund
* ソーカル事件

## 後期

* 言語モデル LM: Language Models
* 系列予測 Serial predictions
* フーリエ変換 Fourier Transform
* 時系列分析 Time Series Analysis
* AR (Auto-Regresion), ARMA (Auto-Regression with Moving Average), ARIMA (Auto-Regression Integrated with Moving Average)
* カルマンフィルタ Kalman Filters
* SRN 単純再帰型ニューラルネットワーク Simple Recurrent Neural Networks
* LSTM 長-短期記憶 Long Short-Term Memory
* word2vec
* Transformer
* BERT
* 位置符号化器 Position Encoders
* GPT: Generative Pre-trained Transformer
* 埋め込みベクトル Embeddings (vectors)
* マルチヘッド注意 Multihead Attentions
* マスク化言語モデル Masked Language Models
* RAG: Retrieval Augmented Generations 検索拡張生成 
* プロンプトエンジニアリング Prompt Engineering
* 強化学習 RL:Reinforcement Learning
    * 動作主 Agent
    * 状態 State
    * 報酬 Reward
    * 価値 Value
    * 方針 Policy
    * 割引率 discount ratio
    * Q 関数 （行動価値関数）
    * SARSA
    * TD 学習
    * マルコフ決定過程 Markov Decision Processes
    * ベルマン方程式 Bellman's Equation
    * 信用割当問題 Credit Assignment Problems
    * エピソード（軌跡，ロールアウト），Episodes, Trajectories, Rollouts
    * 優位(アドバンテージ)関数，
    * 経験再生 Experience Replay
    * セルフプレイ Self Plays
    * DQN: Deep Q Networks
    * RLHF: 人間のフィードバックによる強化学習 Reinforcemnet Learning with Human Feedbacks
    * Agent57
* 世界モデル World models
* 視覚言語行動モデル VLA (Vision-Language-Action) models
 -->
