---
title: 2025 年度開講 駒澤大学 人工知能 I および II
author: 浅川 伸一
layout: home
---
<link href="/css/asamarkdown.css" rel="stylesheet">
<div align='right'>
<a href='mailto:educ0233@komazawa-u.ac.jp'>Shin Aasakawa</a>, all rights reserved.<br>
Date: 23/May/2025<br/>
Appache 2.0 license<br/><br/>
</div>

* [課題提出用フォルダ<img src="/2025assets/Google_Drive_icon_2020.svg" style="width:02%">](https://drive.google.com/drive/u/3/folders/1Tem07Aan1iGXDJu7NKbZhY0siTXWHNs7){:target="_blank"}

<!-- PCA 固有値問題の話と Rigdge 回帰の話, 正則化
Andrew Ng の coursera 
Fisherface，Eigenふぁせ -->

* 来週は休講

# 実習

* [オリベッティ顔データベースを用いた機械学習実習 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2025notebooks/2025_0425olivetti_face_detection.ipynb){:target="_blank"}
* [OpenCV顔検出と認識実習 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2025notebooks/2025_0428opencv_face_detect_recognizer.ipynb){:target="_blank"}
* [課題提出用フォルダ](https://drive.google.com/drive/u/5/folders/1mf-_cGgNSJvpEBykEb1l5BMBBGPrhYke){:target="_blank"}


## オンライン教材

* [AI For Everyone （すべての人のためのAIリテラシー講座）](https://www.coursera.org/learn/ai-for-everyone-ja){:target="_blank"}
    * 聴講モードで｢続ける｣を選択すれば無料で受講できる。
    第１週　イントロダクション•7分，機械学習•6分，データとは？•11分，AI にまつわる専門用語•9分，AI企業にするには？•7分，機械学習でできること、できないこと•7分，機械学習でできること、できないこと - 実例•8分，非技術者でも分かるディープラーニング概要（パート1）•7分，非技術者でも分かるディープラーニング概要（パート2）•3分 までの受講すること。
    * 視聴不要なモジュール：冒頭とモジュールは視聴不要。具体的には，このコースのはじめに•1分，DXとは？•5分，DXにおけるAI／DLの重要性•8分，このコースを学ぶ皆さんへ•0分。


# 回帰 (regression) と分類 (classification)

出力 (予測すべき値) が連続値の場合を回帰と呼ぶ。
一方，出力が離散値の場合を分類と呼ぶ。

例えば，気温や時刻を予測する場合は連続値を予測することになるので回帰である。
一方，人物を予測するのであれば分類となる。

唯一の例外は，ロジスティック回帰 (logisitic regression) である。
ロジスティック回帰の場合，分類に用いられる確率を与える量が問題となる。
あるカテゴリに分類される確率を 0 から 1 の間の確率として予測することになる。

したがってロジスティック回帰とは，教師信号で与えられる値に近づけるように関数 $f$ を訓練することとなる。
この場合，教師信号が $1$ であれば，そのクラス (あるいはカテゴリ) に属することを意味し，逆に教師信号が $0$ であれば，そのクラスに属さないことを学習することとなる。

顔認識を例に取れば，男女を識別するのであれば, 男である確率と女である確率を予測することとなる。
スマートフォンにおける顔認証では，スマートフォンに登録された人物であるか否かを識別することとなる。
この場合，登録済の人物の顔画像であれば 1 そうでなければ 0 を出力すると考えても良い。

この場合，2 $\times$ 2 の表を考えることができる。
以下の表を参照せよ。

|      |真の値 1| 真の値 0 |
|-----:|:-----:|:-------:|
| 予測 1 | 正解  | 虚報 false alarm | 
|     0 | ミス  | correct rejection |

どのような入力値に対しても 1 と答えることにすれば, 正解は増えるが,虚報も増えてしまう。
反対にどのような入力データに対しても 0 と答えることにすれば, correct rejection は増えるがミスも増える。

性能の良い判別器では，正解と correct rejection が多く,ミスと虚報が少ないことが望まれる。

<center>
<img src="/2025assets/04-02classification_2norm.svg" style="width:33%"><br/>
</center>

|   | 本当は正しい  | 本当は誤り |
|:---|:-----|:---|
|:正しいと判断:| ヒット (TP) ピンク|  虚報 (FP) 青| 縦線の左側
|:誤りと判断:| ミス (FN) 赤| 正しい棄却 (TN) 水色| 縦線の右側
|            |  赤＋ピンクの分布 | 青＋水色の分布  | 


<center>

<img src="/2025assets/04-02classification_2norm.svg" style="width:33%"><br/>
</center>

- 適合率 (precision): $\displaystyle\frac{\text{ヒット(ピンク)}}{\text{ヒット(ピンク)}+\text{虚報(青)}}$ 
- 再現率 (recall): $\displaystyle\frac{\text{ヒット(ピンク)}}{\text{ヒット(ピンク)}+\text{ミス(赤)}}$ 
- 正解率 (accuracy): $\displaystyle\frac{\text{ヒット(ピンク)}+\text{正しい棄却(水色)}}{\text{ヒット(ピンク)}+\text{虚報(青)}+\text{ミス(赤)}+\text{正しい棄却(水色)}}$
- F 値: 適合率と再現率の調和平均 $\displaystyle\frac{2}{\text{正確度}^{-1}+\text{再現率}^{-1}}=2\cdot\frac{\text{正確度}\cdot\text{再現率}}{\text{正確度}+\text{再現率}}$


多値分類の場合，例えば 40 名の人物画像を考える。

ロジット比 (確率比) とは，事象 x の起こる確率と x が起こらない確率との比 $\displaystyle\frac{P(x)}{P(\neg x)}=\frac{P(x)}{1-P(x)}$ のことを言う。
ロジット比の対数を x と置くと，$\displaystyle \log\left(\frac{P(x)}{1−P(x)}\right)=x $ となる。
この式を変形して $\displaystyle P(x)=\frac{1}{1+e^{-x}}$ となる。

この値は，任意の実数 $x\in[-\infty,\infty]\equiv\mathbb{R}$ に対して 0 から 1 の間の値を与える関数となる。


### 訓練データ (training dataset)，テストデータ (test dataset)，検証データ (validation dataset)

* 機械学習では，心理統計で用いられるような 仮説検定を行うこともありますが，むしろ，行わない場合も多いです。
* 理由としては，仮説検定を行うことによりも，モデルの性能を向上させることに主眼があるからという意味合いであろうと考えられます。
* ですが，考え方は母集団統計量の推定と同じような発想をします。すなわち，まだ見ぬ未知のデータに対して精度が良いモデルが優れているモデルと判断されます。
* 訓練データを使ってモデルを作成し，作成したモデルの評価をテストデータを使って評価します。
* このとき，テストデータは訓練には使いません。未知のデータに対しての精度でモデルの性能の優劣を競います。従って，モデルの精度の良いモデルが良いモデルであり，かつ，良いモデルとは，未知のデータに対してより精度が高く動作するモデルとなります。
* この点については，母集団の統計量の優劣を考える心理統計とは異なります。
* 真の母集団という，ありもしない曖昧 (かも知れない) 仮想集団について斟酌するよりも，実際のデータについて精度の優劣でモデルの性能を競うという意味では，実務的な発想と言えるでしょう。
* 機械学習におけるモデルの精度向上を目指したパラメータチューニングのことを **学習** と呼びます。

### 過学習

* モデルのパラメータを学習するときに，同じデータを用いて性能を検証することは，方法論的に間違っていると言えます。
* すでに見たことのある敵をたおせても，真の勇者とは言えません。何度でも生き返ることができる RPG とは違います。
* 見たことのあるデータ （遭遇した経験のあるモンスター）は倒せるでしょう。ですが，それでは 勇者 ではなく チキン です。
* 経験済のデータについては，完璧なスコアを示すことができるでしょう。ですが，まだ見ぬデータに対して有用な予測をすることはできません。
* このような状況を 過学習 (over-learning) あるいは オーバーフィッティング (over-fitting) といいます。
* これを避けるために、（教師あり）機械学習を行う際には，利用可能なデータの一部を テストデータセット `X_test`, `y_test` として用意しておくのが一般的です。
* 一般に k-hold out 法などと呼ばれる手法は，訓練データセットを ｋ 個に分割します。
その上で，k 個に分割した 1 つのデータ群を除いた k-1 群の訓練データを用いてモデルの学習を行います。学習の都度，残しておいたデータを用いて性能を評価します。
* この方法により，最終評価に用いるテストデータを使うこと無くチューニングを行います。
* **なぜ全データを用いないで，データを分割するのか？**
  * 未知の母集団を仮定しないで，モデルの優劣を正当に評価するための方法であるとみなすことができます。

### 回帰と分類

* 機械学習で頻用される手法の分類に **回帰** と **分類** があります。
* 予測すべきデータが連続量の場合は，回帰
* 予測すべきデータが離散量の場合は，分類 と呼ばれます。
* 身長や体重，あるいは，明日の東京都における COVID-19 の感染者数を予測するのであれば 回帰 です。
* 一方，手書き数字認識は，予測すべきデータが 10 分類された各クラスですので 分類 と呼ばれます。
* $\mathbf{y} = \mathbf{Xw} +\mathbf{b}$ などは 線形回帰 と呼ばれます。これは中学校以来の 直線を表す 1 次方程式 $y=ax+b$ と同じ形をしています。
* $y$ を予測すべき量，$x$ を与えられたデータと考えます。
* 傾き slope:$a$ と 切片 intercept:$b$ とを推定する問題が 回帰 です。
* 中学校までの数学の知識では，2 点 $(x_1, y_1)$, $(x_2, y_2)$ が与えられたとき，$a$ と $b$ とは計算して求めることが可能でした。
* では，N 個のデータ $(x_1,y_1),\cdots,(x_n,y_n)$ が与えられたとき，切片 と 傾き とはどう定めたら良いのでしょうか？

#### モデルの精度を測る指標: 精度 (accuracy)，適合度 (precision)，再現率 (recall)，F1 値 (F1 value)

* モデルの精度とは，何か。精度とは，正しく予測できることです。分類課題の場合，
* 正しい予測と誤った予測とには，詳細な検討が必要になりる。
* ここでは，精度 とは，英語で accuracy である。
* 混乱する用語に適合度 precision がある。

* **精度 precision**: 正事例であると予測された事例のうち，正しく評価された事例の割合ある事例が陽性であると分類器が判定した際に，その陽性と判断された事例中の正しい割合。
<!-- This computes the proportion of instances predicted as positives that were correctly evaluated (it measures how right our classifier is when it says that an instance is positive). -->
* **適合度 precision**:
* **再現率 recall**: 分類器がどれだけ正しく正事例を判定できたか<!--This counts the proportion of positive instances that were correctly evaluated (measuring how right our classifier is when faced with a positive instance).-->
* **F1 値 F1-score**: 精度 (precision) と 再現率 (recall) との調和平均<!--This is the harmonic mean of precision and recall, and tries to combine both in a single number-->


| | 真の値 (+) | 真の値 (-) |
|:---|:---|:---|
|予測 (+) | True Positive (ヒット Hit) | False Positive (虚報 False alarm) |
|予測 (-) | False Negative (ミス Miss) | True Negative (正しい棄却 Correct rejection) |


<!-- | | 予測: + | 予測: - |
|---|----|----|
|真の値: + | True Positive (ヒット Hit)| False  Negative (ミス Miss) |
|真の値: - | False Positive (虚報 False alarm)| True Negative (正しい棄却 Correect rejection) | -->


* **問題: 分類問題の精度の指標の一つでもある混同行列の中で正しい組み合わせのものを選べ。ここでは小数第3位以下は切り捨てている。**

| | 真の値 (正 +) | 真の値 (負 -) |
|:---|:---:|:---:|
|分類器の予測 (+) | 13 | 1 |
|分類器の予測 (-) | 2  | 14 |

<!-- | | 予測: + | 予測: - |
|:---|:---:|:---:|
|真の値: + | 13 | 2 |
|真の値: - | 1  | 14 | -->



<!-- <div class="figcenter">
<img src="/assets/cm.svg" style="width:33%;"><br/>
</div> -->

ただし，A は正解率, B は適合率, C は再現率, D は F 値とする。

1. A:$0.866$, B:$0.896$, C:$0.928$, D:$0.900$
2. A:$0.928$, B:$0.900$, C:$0.896$, D:$0.866$
3. A:$0.896$, B:$0.866$, C:$0.900$, D:$0.928$
4. A:$0.900$, B:$0.928$, C:$0.866$, D:$0.896$

<!--
### 解説:
正解は 4

1. 精度 accuracy (13+14)/(13+2+1+14) = 0.900
2. 適合度 precision 13/(13+1) = 0.9286
3. 再現率 recall 13/(13+2) = 0.867
4. F1 (2 * precision * recall)/(precision + recall)

 -->


## 教師あり学習と教師なし学習

* 予測すべき数値に正解が与えられている場合，**教師あり学習 supervised learning** と呼びます。
* 一方，予測すべきデータが与えられていない場合を **教師なし学習 unsupervised learning** と呼びます。
* 手書き数字認識では，正解となるデータが与えられているので，教師あり学習となります。
* 一方で，正解データが与えられていない場合に，入力データを分類したりする場合を 教師なし学習と 呼びます。

以下はすぐに知る必要がない知識です

### 重回帰

中学校以来の直線の方程式 $y = ax + b$ を一般化します。
データ行列を $\mathbf{X}$，予測すべき値を $\mathbf{y}$ とし，推定すべきパラーメータを $\mathbf{W}$ で表します。
重回帰 multiple regression は次式で表されます:

$$
\mathbf{y}=\mathbf{Xw} +\mathbf{b}
$$
ここで $\mathbf{b}$ はバイアス項，中学数学で言えば切片にあたります。

### 主成分分析

データ $\mathbf{X}$ の次元圧縮 dimensionality reduction の方法です。
$\mathbf{X}$ を 係数行列 $\mathbf{w}$ によって変換したデータを $\mathbf{y}$ とします。
$\mathbf{y}$ の分散を最大化する方法として，次のような目的関数を最大化することを考えます:

$$
\mathbf{w}^\top\mathbf{X}^\top\mathbf{Xw} - \lambda\left(\mathbf{w}^\top\mathbf{w}-1\right)
$$

ここで $\lambda$ はラグランジェ (Lagrange) の未定定数 (Lagrange's multiplier) と呼ばれる。
すなわち，主成分分析とは，目的関数である $\mathbf{w}^\top\mathbf{w}$ を最小化する代わりに，制約付き最小化問題を解くことに相当する。
目的とする関数を最小化する代わりに，新たな目的関数を設定して，その新しい目的関数を最小化することで，制約付き最初化を実現する方法である。

この方法を一般化して **変分法** variational methods と呼ぶ。

また，上式を解くことは，$\left|\mathbf{X}-\lambda\mathbf{I}\right|=0$ なる固有方程式を解くことになる。
すなわち，主成分分析とは，データ行列の固有値問題を解くことと同義である。

固有値問題，および 変分法，変分問題は，古くは，オイラーやニュートンによって始められた。
すなわち，惑星の運行を記述する運動方程式の解法として考案されました。
この方法を洗練させたのが，ラグランジェ で解析力学として定式化した。



### 勾配降下法

重回帰では解析解が存在しました。一方，非線形問題は一般に解析解が存在しません。
その際に，目的関数を繰り返しによって求める方法があります。
**勾配降下法** gradient descent methods はその一つです。
任意の点 $x$ における関数 $f(x)$ の微分が定義されていれば，求める関数の最小値は次式:

$$
\Delta\theta = \eta\frac{\partial f}{\partial\theta}
$$

を逐次計算することで求めることができると仮定します。
ここで $\theta$  はモデルのパラメータ，$f$ は目的関数，$\eta$ は学習率，$\partial$ は **偏微分** partial differential を表します。



<!--
Authors:    J.A. Anderson, A. Pellionisz, E. Rosenfeld (eds.)
Title:      Neurocomputing 2: Directions for Research
Reference:  MIT Press, Cambridge (1990), Massachusetts

### ANNs are some kind of non-linear statistics for amateurs
-->

<!--
## 次の語の示すサイトを訪れ，それぞれどのようなサイトかを調べよ。
いずれも現在のエコシステムとしての役割を果たしている。

1. arXiv: <font color="white">論文置き場</font>
2. Colab:
3. Github: <font color="white">プログラムのソースコード置き場</font>
4. Stack Oerflow: <font color="white">掲示板，ノウハウ集</font>
5. Reddit: <font color="white">掲示板，ただしビッグネーム本人が降臨することがある</font>
-->

<!--
# AI を学ぶ人間のための心構え
- 無知蒙昧から来るブラックボックス的な恐怖を払拭するよう務める(現時点での技術的な裏付けに基づく啓蒙活動)
- 現在の技術から予測できる近未来の展望を語ることを忌避しない(謙遜は美徳ではない)

<center>
<img src="https://blogs-images.forbes.com/markhughes/files/2016/01/Terminator-2-1200x873.jpg" style="width:32%">
<img src="http://zatugaku1128.com/wp-content/uploads/2016/09/%E3%83%89%E3%83%A9%E3%81%88%E3%82%82%E3%82%93.png" style="width:20%"></br>
</center>

未来はどっち？ **It will depend on you.**

# クイズ
* 次の語の組み合わせのうち不適切なものを指摘せよ

1. IBM - Watson - Joapady
2. DeepMind - AlphaGo - 囲碁
3. Google 翻訳 - ペッパー
4. Uber - 自動運転
-->


## ニューラルネットワーク

ニューラルネットワーク (神経回路網 neural networks) とは，神経細胞 (ニューロン) の結合 (ネットワーク) のことです。

クイズのようなダジャレのような話ですが，ANN, BNN, CNN, DNN という省略形で呼ばれています。

* ANN: 人工ニューラルネットワーク
* BNN: 生物学的ニューラルネットワーク
* CNN: 畳み込みニューラルネットワーク。アメリカ合衆国のケーブルテレビの名称でもある。
* DNN: ディープニューラルネットワーク

広義には ニューロンを基本計算単位とした情報処理モデルであると言えます。
**計算** という言葉は，算術演算を意味しません。脳の働き，さまざまな心の作用はすべて 計算である との立場です。
すなわち，我々の知的活動，心的状態は，ニューロンを基本構成単位とする ネットワーク働きとして説明されるという、心，あるいは 脳を理解するためのパラダイム一般をニューラルネットワーク，
あるいは，心 （精神） の計算理論と呼びます。

現在までのところ，ニューラルネットワーク研究では，脳の血流 （とその異常，障害），神経伝達物質の代謝 (とその異常，障害) ，と言った側面にまで
及んでいるわけではありません。

神経細胞は，人間を含む動物が持っていますが，人工ニューラルネットワーク (ANN) では，コンピュータ上で，ニューロンの働きを模倣することにより，複雑な課題を解くことを目指し，
場合によっては，人間以上の性能を示すまでになっています。

ANN は 生物学的ニューラルネットワーク (BNN) にヒントを得て作成されました。
ですが，現在の ANN は BNN に比べて極端な単純化を行った並列情報処理モデルです。

たとえば，スパイキングモデルは計算機科学の分野では重要な位置を占めています。
スパイキングモデルでは 樹状突起による計算や 各ニューロン内の他のプロセス (Gallistel&King2011) あるいは，異なるタイプのニューロンからの関与を考慮しているとは言えません。

通常 ANN では ニューロンの空間構造は プログラミング可能な形で抽象化されています。
ニューロンのスパイク出力はスパイク率のような実数としてモデル化されています。
<!--このレートは、静的な非線形性を介して入力される活性化の加重和としてモデル化されます。-->
このように単純化されているにもかかわらず，ニューラルネットワークは脳の情報処理を理解するための最も重要な方法の 1 つとなっています。

実際のニューロンの活動を調べる 神経科学 と 人間の 知的活動を 材料とする 認知科学 との橋渡しをする 理論モデルとして 中心的な役割を果たすことになると予想します。


* [認知計算論的神経科学 Kriegeskorte and Douglas (2018)](../2018Kriegeskorte_ja.pdf){:target="_blank"} 
* [認知神経科学のためのディープラーニング Storrs and Nikolaus Kriegeskorte (2019)](../2019Storrs_ja.pdf){:target="_blank"} 
* [視覚系のモデルとしての畳み込みニューラルネットワーク: 過去，現在，そして未来 Lindsay (2020)](../2020Lindsay_ja.pdf){:target="_blank"}


### 訓練データ (training dataset)，テストデータ (test dataset)，検証データ (validation dataset)

* 機械学習では，心理統計で用いられるような 仮説検定を行うこともありますが，むしろ，行わない場合も多いです。
* 理由としては，仮説検定を行うことによりも，モデルの性能を向上させることに主眼があるからという意味合いであろうと考えられます。
* ですが，考え方は母集団統計量の推定と同じような発想をします。すなわち，まだ見ぬ未知のデータに対して精度が良いモデルが優れているモデルと判断されます。
* 訓練データを使ってモデルを作成し，作成したモデルの評価をテストデータを使って評価します。
* このとき，テストデータは訓練には使いません。未知のデータに対しての精度でモデルの性能の優劣を競います。従って，モデルの精度の良いモデルが良いモデルであり，かつ，良いモデルとは，未知のデータに対してより精度が高く動作するモデルとなります。
* この点については，母集団の統計量の優劣を考える心理統計とは異なります。
* 真の母集団という，ありもしない曖昧 (かも知れない) 仮想集団について斟酌するよりも，実際のデータについて精度の優劣でモデルの性能を競うという意味では，実務的な発想と言えるでしょう。
* 機械学習におけるモデルの精度向上を目指したパラメータチューニングのことを **学習** と呼びます。

### 過学習

* モデルのパラメータを学習するときに，同じデータを用いて性能を検証することは，方法論的に間違っていると言えます。
* すでに見たことのある敵をたおせても，真の勇者とは言えません。何度でも生き返ることができる RPG とは違います。
* 見たことのあるデータ （遭遇した経験のあるモンスター）は倒せるでしょう。ですが，それでは 勇者 ではなく チキン です。
* 経験済のデータについては，完璧なスコアを示すことができるでしょう。ですが，まだ見ぬデータに対して有用な予測をすることはできません。
* このような状況を 過学習 (over-learning) あるいは オーバーフィッティング (over-fitting) といいます。
* これを避けるために、（教師あり）機械学習を行う際には，利用可能なデータの一部を テストデータセット `X_test`, `y_test` として用意しておくのが一般的です。
* 一般に k-hold out 法などと呼ばれる手法は，訓練データセットを ｋ 個に分割します。
その上で，k 個に分割した 1 つのデータ群を除いた k-1 群の訓練データを用いてモデルの学習を行います。学習の都度，残しておいたデータを用いて性能を評価します。
* この方法により，最終評価に用いるテストデータを使うこと無くチューニングを行います。
* **なぜ全データを用いないで，データを分割するのか？**
  * 未知の母集団を仮定しないで，モデルの優劣を正当に評価するための方法であるとみなすことができます。

### 回帰と分類

* 機械学習で頻用される手法の分類に **回帰** と **分類** があります。
* 予測すべきデータが連続量の場合は，回帰
* 予測すべきデータが離散量の場合は，分類 と呼ばれます。
* 身長や体重，あるいは，明日の東京都における COVID-19 の感染者数を予測するのであれば 回帰 です。
* 一方，手書き数字認識は，予測すべきデータが 10 分類された各クラスですので 分類 と呼ばれます。
* $\mathbf{y} = \mathbf{Xw} +\mathbf{b}$ などは 線形回帰 と呼ばれます。これは中学校以来の 直線を表す 1 次方程式 $y=ax+b$ と同じ形をしています。
* $y$ を予測すべき量，$x$ を与えられたデータと考えます。
* 傾き slope:$a$ と 切片 intercept:$b$ とを推定する問題が 回帰 です。
* 中学校までの数学の知識では，2 点 $(x_1, y_1)$, $(x_2, y_2)$ が与えられたとき，$a$ と $b$ とは計算して求めることが可能でした。
* では，N 個のデータ $(x_1,y_1),\cdots,(x_n,y_n)$ が与えられたとき，切片 と 傾き とはどう定めたら良いのでしょうか？

#### モデルの精度を測る指標: 精度 (accuracy)，適合度 (precision)，再現率 (recall)，F1 値 (F1 value)

* モデルの精度とは，何か。精度とは，正しく予測できることです。分類課題の場合，
* 正しい予測と誤った予測とには，詳細な検討が必要になりる。
* ここでは，精度 とは，英語で accuracy である。
* 混乱する用語に適合度 precision がある。

* **精度 precision**: 正事例であると予測された事例のうち，正しく評価された事例の割合ある事例が陽性であると分類器が判定した際に，その陽性と判断された事例中の正しい割合。
<!-- This computes the proportion of instances predicted as positives that were correctly evaluated (it measures how right our classifier is when it says that an instance is positive). -->
* **適合度 precision**:
* **再現率 recall**: 分類器がどれだけ正しく正事例を判定できたか<!--This counts the proportion of positive instances that were correctly evaluated (measuring how right our classifier is when faced with a positive instance).-->
* **F1 値 F1-score**: 精度 (precision) と 再現率 (recall) との調和平均<!--This is the harmonic mean of precision and recall, and tries to combine both in a single number-->


| | 真の値 (+) | 真の値 (-) |
|:---|:---|:---|
|予測 (+) | True Positive (ヒット Hit) | False Positive (虚報 False alarm) |
|予測 (-) | False Negative (ミス Miss) | True Negative (正しい棄却 Correct rejection) |


<!-- | | 予測: + | 予測: - |
|---|----|----|
|真の値: + | True Positive (ヒット Hit)| False  Negative (ミス Miss) |
|真の値: - | False Positive (虚報 False alarm)| True Negative (正しい棄却 Correect rejection) | -->


* **問題: 分類問題の精度の指標の一つでもある混同行列の中で正しい組み合わせのものを選べ。ここでは小数第3位以下は切り捨てている。**

| | 真の値 (正 +) | 真の値 (負 -) |
|:---|:---:|:---:|
|分類器の予測 (+) | 13 | 1 |
|分類器の予測 (-) | 2  | 14 |

<!-- | | 予測: + | 予測: - |
|:---|:---:|:---:|
|真の値: + | 13 | 2 |
|真の値: - | 1  | 14 | -->



<!-- <div class="figcenter">
<img src="/assets/cm.svg" style="width:33%;"><br/>
</div> -->

ただし，A は正解率, B は適合率, C は再現率, D は F 値とする。

1. A:$0.866$, B:$0.896$, C:$0.928$, D:$0.900$
2. A:$0.928$, B:$0.900$, C:$0.896$, D:$0.866$
3. A:$0.896$, B:$0.866$, C:$0.900$, D:$0.928$
4. A:$0.900$, B:$0.928$, C:$0.866$, D:$0.896$

<!--
### 解説:
正解は 4

1. 精度 accuracy (13+14)/(13+2+1+14) = 0.900
2. 適合度 precision 13/(13+1) = 0.9286
3. 再現率 recall 13/(13+2) = 0.867
4. F1 (2 * precision * recall)/(precision + recall)
-->

