---
title: 第10回 2025 年度開講 駒澤大学 人工知能 I および II
author: 浅川 伸一
layout: home
---
<link href="/css/asamarkdown.css" rel="stylesheet">

<div align="center">
<font size="+2" color="navy"><strong>2025 年度開講 駒澤大学 人工知能 I および II</strong></font><br/><br/>
</div>

<div align='right'>
<a href='mailto:educ0233@komazawa-u.ac.jp'>Shin Aasakawa</a>, all rights reserved.<br/>
Date: 27/Jun/2025<br/>
Appache 2.0 license<br/>
</div>


* [課題提出用フォルダ <img src="/2025assets/Google_Drive_icon_2020.svg" style="width:02%">](https://drive.google.com/drive/u/3/folders/1YDJrFFIblRruY6co-MVHrSkq__AmaRdd){:target="_blank"}


# 第 10 回 ニューラルネットワーク(3)

## キーワード

<!-- SGD, Adam, Adagrad, Adadelta はやらないのか。-->

* 正則化，正規化，標準化
* 勾配消失問題 (gradient vanishing problem)，勾配爆発問題 (gradient explosion problem)
* 信用割当問題
* ネオコグニトロン
* 畳み込みニューラルネットワーク (CNN)

## デモ

- [グーグルによるニューラルネットワークの遊び場 (プレイグランド)](https://project-ccap.github.io/tensorflow-playground/){:target="_blank"}
* [ニューラルネットワークで遊んでみよう](https://komazawa-deep-learning.github.io/tensorflow-playground/){:target="_blank"}

<!-- * [ニューラルネットワークで遊んでみよう](https://komazawa-deep-learning.github.io/tensorflow-playground/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.98055&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false){:target="_blank"} -->


### 実習ファイル

- [LeNet PyTorch <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2021_0528LeNet_pytorch.ipynb){:target="_blank"}
* [畳み込みニューラルネットワークの事前訓練済モデルによる中間表現の可視化 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2022notebooks/2022_1024CNN_layer_visualization.ipynb){:target="_blank"}
* [ニューラルネットワークモデルの定義 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2022notebooks/2022_1028komazawa_neural_networks_primer.ipynb){:target="_blank"}
* [画像認識 PyTorch の基礎編 AlexNet <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0515komazawa_step_by_step_CNN_Pytorch.ipynb){:target="_blank"}
* [ステップ・バイ・ステップで画像認識の基礎 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0515komazawa_step_by_step_CNN_Pytorch.ipynb){:target="_blank"}

## 1. 生理学的知見 ヒューベルとウィーゼルによる視覚野の生理学研究

<div class="figure figcenter">
<!-- <div class="figure figcenter" style="width:66%"> -->

<img src="/assets/1968Hubel_Wiesel_1.svg" style="width:66%">
<div class="figcaption">
Hubel と Wiesel (1959, 1962, 1968) の実験の模式図
</div>

<img src="/assets/1968Hubel_Wiesel_2.svg" style="width:74%"><br/>
<div class="figcaption">
Hubel と Wiesel の実験結果 (Hubel&Wiesel, 1968 の Fig.2.7 をトレーシングしたもの
</div>
</div>

## 2. ブレイクモア と クーパー (Blackmore&Cooper1970) によるネコの新生児による初期視覚経験

<center>
<iframe width="450" height="300" src="https://www.youtube.com/embed/QzkMo45pcUo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<!--<iframe width="845" height="676" src="https://www.youtube.com/embed/QzkMo45pcUo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>--><br/>
<div class="figcaption">
source: `https://youtu.be/QzkMo45pcUo`
</div>
</center>

<div class="figure figcenter">
<img src='/assets/1970BlackmoreCooper_Fig1.svg' style='width:39%'>
<img src='/assets/1970BlackmoreCooper_Fig2.svg' style='width:49%'>
<div class="figcaption">
Blackmore&Cooper (1970) Fig.1, Fig. 2
</div></div>

<center>
<iframe width="450" height="300" src="https://www.youtube.com/embed/RSNofraG8ZE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<br/>
<div class="figcaption">
source: `https://youtu.be/RSNofraG8ZE`
</div>
</center>


## 3. 福島のネオコグニトロン (Fukushima, 1980)

* S 細胞と C 細胞との繰り返し。最初の多層（深層）化された物体認識モデルととらえることが可能
    - S 細胞：生理学の単純細胞 simple cells に対応。受容野 receptive fields の概念を実現。特徴抽出，特徴検出。<br/>
    - C 細胞：複雑細胞 complex cells に対応。広い受容野。位置，回転，拡大縮小の差異を吸収<br>

<div class="figure figcenter">
<img src="/assets/Neocognitron.jpeg" width="55%">
<img src="/assets/Fukushima.jpeg" style="width:24%"><br>
<div class="figcaption">

ネオコグニトロンの模式図
</div></div>

## 4. リーゼンフーバー と ポッジオ (Riesenhuber&Poggio1999) による最大値プーリングのモデル。

<div class="figure figcenter">
<img src="/assets/1999Riesenhuber_Poggio_fig2.svg" style="width:49%">
<div class="figcaption" style="width:99%">
モデルのスケッチ。
単純細胞から作られた複雑細胞の古典的なモデルを拡張したもので，線形演算 (福島の表記法では `S` ユニット，テンプレート・マッチング 図中の実線) と非線形演算 (`C`プーリングユニット，最大値 MAX 演算を行う 図中破線) を持つ層の階層で構成。
細胞入力の最大値を選択，その値を用いてセルを駆動する非線形の MAX 演算は複雑細胞に対して，線形入力の合計とは異なりモデルの特性の鍵となる概念である。
この 2 種類の操作は 異なる位置にチューニングされた求心性結合をプールすることでパターン特異性と並進不変性を，また異なるスケールにチューニングされた求心性結合をプールすることで、スケール不変性をもたらした (図示せず)。
Riesenhuber&Poggio1999 Fig. 2.
</div></div>


<div class="figure figcenter">
<img src="/assets/1999Riesenhuber_Poggio_fig3a.svg" style="width:44%">
<img src="/assets/1999Riesenhuber_Poggio_fig3b.svg" style="width:44%"><br/>
<div class="figcaption" style="width:99%">

<!-- MAX 機構 高度に非線形な形状調整の特性。
「最適」特徴を決定するために考案された「単純化手順」を用いて得られた下側頭葉細胞の応答（選好刺激に対する反応が等しくなるように正規化された反応)。
実験では，もともと細胞は「水のボトル」の画像 (一番左の物体) に非常に強い反応を示した。
その後，刺激を単色の輪郭に単純化したところ，細胞の発火が増加し，さらに，楕円を支える棒からなるパドルのような物体に変化した。
この物体が強い反応を引き起こすのに対し，棒や楕円だけではほとんど反応しなかった。
Riesenhuber&Poggio1999, Fig 3A.
</div></div>
<img src="/assets/1999Riesenhuber_Poggio_fig3b.svg" style="width:66%"><br/>
<div class="figcaption" style="width:99%"> -->

実験とモデルの比較。
白棒はの実験用ニューロンの反応を示す。
黒と灰色の棒は 選好刺激の 幹-楕円 の基部の遷移に合わせてチューニングしたモデル細胞の反応を示している。
モデル細胞は 直上図に示したモデルを簡略化したもの。
受容野の各位置に 2 種類の S1 特徴があり，それぞれが遷移領域の左側または右側にチューンしていて，その出力が C1 ユニットに入力され MAX 関数 (黒棒) または SUM 関数 (灰色棒) を用いてプールされている。
モデル細胞は 実験ニューロンの 選好刺激が受容野内にあるときに反応が最大になるよう，C1 ユニットに接続されていた。

図 3. MAX 機構の高度に非線形な形状チューニング特性。
(a) `最適` 特徴を決定するために考案された `単純化手続`(26) を用いて得られた，実験的に観察された IT 細胞の応答 (好ましい刺激に対する応答が 1 に等しくなるように正規化された応答)。
実験では，細胞はもともと「水瓶」 (一番左の物体) の画像にかなり強く反応した。
その後，刺激は単色の輪郭に「単純化」され，細胞の発火が増加し，さらに楕円を支える棒からなるパドルのような物体に変化した。
この物体は強い反応を引き起こしたが，棒や楕円だけではほとんど全く反応を起こさなかった (図は許可を得て使用)。
(b) 実験とモデルの比較。
白棒は (a) の実験ニューロンの反応。
黒棒と灰色棒は，優先刺激の幹-楕円底遷移に同調させたモデルニューロンの反応を示す。
このモデルニューロンは，図 2 に示したモデルの単純化された版の最上部にあり，受容野の各位置に 2 種類の S1 特徴のみが存在し，それぞれが遷移領域の左側または右側に同調し，MAX 関数 (黒棒グラフ) または SUM 関数 (灰色棒グラフ) のいずれかを用いてそれらをプールする C1 ユニットに供給される。
モデルニューロンは，実験ニューロンの好ましい刺激がその受容野にあるときに，その反応が最大になるように，これらの C1 ユニットに接続された。
<!-- Fig. 3. Highly nonlinear shape-tuning properties of the MAX mechanism.
(a) Experimentally observed responses of IT cells obtained using a `simplification procedure`(26) designed to determine `optimal` features (responses normalized so that the response to the preferred stimulus is equal to 1).
In that experiment, the cell originally responded quite strongly to the image of a `water bottle` (leftmost object).
The stimulus was then `simplified` to its monochromatic outline, which increased the cell’s firing, and further, to a paddle-like object consisting of a bar supporting an ellipse.
Whereas this object evoked a strong response, the bar or the ellipse alone produced almost no response at all (figure used by permission).
(b) Comparison of experiment and model.
White bars show the responses of the experimental neuron from (a).
Black and gray bars show the response of a model neuron tuned to the stem-ellipsoidal base transition of the preferred stimulus.
The model neuron is at the top of a simplified version of the model shown in Fig. 2, where there were only two types of S1 features at each position in the receptive field, each tuned to the left or right side of the transition region, which fed into C1 units that pooled them using either a MAX function (black bars) or a SUM function (gray bars).
The model neuron was connected to these C1 units so that its response was maximal when the experimental neuron’s preferred stimulus was in its receptive field. -->
</div></div>

<!-- MAX 機構に対する追加的な間接的支持は，IT 細胞の好ましい特徴，つまり細胞を駆動するための刺激成分を決定するために，「単純化手順」(26 )または「複雑性減少」(27) を用いた研究から得られている。
これらの研究では一般的に，IT 細胞の高度に非線形な同調を発見している (図 3a)。
このような同調は MAX 応答関数 (図 3b 黒棒) と一致する。
線形モデル (図 3b 灰色棒) では，入力画像のわずかな変化に対す るこの強い応答の変化を再現できないことに注意されたい。
Additional indirect support for a MAX mechanism comes from studies using a `simplification procedure`(26) or `complexity reduction`(27) to determine the preferred features of IT cells, that is, the stimulus components that are responsible for driving the cell.
These studies commonly find a highly nonlinear tuning of IT cells (Fig. 3a).
Such tuning is compatible with the MAX response function (Fig. 3b, black bars).
Note that a linear model (Fig. 3b, gray bars) could not reproduce this strong change in response for small changes in the input image. -->

<!-- * [デモ](/conv-demo/index.html){:target="_blank"} -->
<!--
<center>
<iframe src="/conv-demo/index.html" width="140%" height="640px;" style="border:none;"></iframe>

</center> -->

## 5. LeNet5 (LeCun, 1998)
- **LeNet**. Yann LeCun (現 Facebook AI 研究所所長)による CNN 実装。
[LeNet](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf){:target="_blank"} 手書き数字認識

<div class="figure figcenter">
<img src="/assets/1998LeNet5.png" width="84%">
<div class="figcaption">

LeNet5 の論文より改変
</div></div>

- 畳込層とプーリング層（発表当初はサブサンプリング）との繰り返し
  - 畳込とプーリングは<font color="green">局所結合</font>
- MNIST を用いた１０種類の手書き文字認識
- 最終２層は全結合層をつなげて最終層１０ニューロン，最終層の各ニューロンの出力がそれぞれの数字（０から９までの１０種）に対応する


<table style="width:100%; table-layout:fixed;">
  <tr>
    <td><img width="94%" src="/assets/dmoulin_gif/no_padding_no_strides.gif"></td>
    <td><img width="94%" src="/assets/dmoulin_gif/arbitrary_padding_no_strides.gif"></td>
    <td><img width="94%" src="/assets/dmoulin_gif/same_padding_no_strides.gif"></td>
    <td><img width="94%" src="/assets/dmoulin_gif/full_padding_no_strides.gif"></td>
  </tr>
  <tr>
    <td>パディング=0，ストライド=1</td>
    <td>パディング=2，ストライド=1</td>
    <td>パディング=1，ストライド=1</td>
    <td>パディング=2，ストライド=1</td>
  </tr>
  <tr>
    <td><img width="94%" src="/assets/dmoulin_gif/no_padding_strides.gif"></td>
    <td><img width="94%" src="/assets/dmoulin_gif/padding_strides.gif"></td>
    <!-- <td><img width="88%" src="/assets/dmoulin_gif/padding_strides_odd.gif"></td> -->
    <td></td>
  </tr>
  <tr>
    <td>パディング=0，ストライド=1</td>
    <td>パディング=1，ストライド=2</td>
    <!-- <td>パディング=1，ストライド=2</td> -->
    <td></td>
  </tr>
</table>

<!--
<div class="figure figcenter" style="width:100%">
<img src="/assets/dmoulin_gif/full_padding_no_strides.gif" style="width:33%">
<img src="/assets/dmoulin_gif/same_padding_no_strides_transposed.gif" style="width:33%">
<div class="figcaption" style="width:99%">

左:入力層 5x5青，出力層緑，カーネルサイズ3x3, フルパディング，ストライド=1.<br/>
右:入力層 5x5青，出力層緑，カーネルサイズ3x3, フルパディング，ストライド=1. トランスポーズド畳み込み
</div> -->

<div class="figure figcenter">
<img src="/assets/dmoulin_gif/numerical_max_pooling.gif" style="width:33%">
<img src="/assets/dmoulin_gif/numerical_average_pooling.gif" style="width:33%">
<div class="figcaption" style="width:6666%">

左: 最大値プーリング。
右: 平均値プーリング。Dmoulin and Visin (2020) より
</div></div>

<!--
<img src="/assets/dmoulin_gif/padding_strides.gif" style="width:30">
<img src="/assets/dmoulin_gif/padding_strides_odd.gif" style="width:30%">
<img src="/assets/dmoulin_gif/padding_strides_odd_transposed.gif" style="width:30%">
<div class="figcaption" style="width:99%">

左: パディング付きストライド，
中: パディング付きストライドodd
右: パディング付きストライド転置
padding_strides, 中:padding_strides_odd, 右:padding_stride_transposed
</div>
<img src="/assets/dmoulin_gif/same_padding_no_strides.gif" style="width:33%">
<img src="/assets/dmoulin_gif/same_padding_no_strides_transposed.gif" style="width:33%">
<div class="figcaption">

右:same_padding_no_strides, 左: same_padding_no_strides_transposed
</div>
<img src="/assets/dmoulin_gif/arbitrary_padding_no_strides.gif" style="width:33%">
<img src="/assets/dmoulin_gif/arbitrary_padding_no_strides_transposed.gif" style="width:33%">
<div class="figcaption">
右:arbitrary padding no strides, 左: artibtrary padding no stride transposed
</div></div> -->


## 参考

* [ベイズ学習](/2023cogpsy/2023_1124bayes){:target="_blank"}
* [最適化](/2023cogpsy/2023_1124optimizations){:target="_blank"}

1. [ディープラーニング概説, 2015, LeCun, Bengio, Hinton, Nature](https://komazawa-deep-learning.github.io/2021/2015LeCun_Bengio_Hinton_NatureDeepReview.pdf){:target="_blank"}
1. [ゴール駆動型深層学習モデルを用いた感覚皮質の理解 Yamins(2016) Nature](https://project-ccap.github.io/2016YaminsDiCarlo_Using_goal-driven_deep_learning_models_to_understand_sensory_cortex.pdf){:target="_blank"}
1. [ディープラーニングレビュー Storrs ら, 2019, Neural Network Models and Deep Learning, 2019](https://komazawa-deep-learning.github.io/2021/2019Storrs_Golan_Kriegeskorte_Neural_network_models_and_deep_learning.pdf){:target="_blank"}
1. [深層学習と脳の情報処理レビュー Kriegestorte, 2015, Deep Neural Networks: A New Framework for Modeling Biological Vision and Brain Information Processing](2015Kriegeskorte_Deep_Neural_Networks-A_New_Framework_for_Modeling_Biological_Vision_and_Brain_Information_Processing.pdf){:target="_blank"}
1. [生物の視覚と脳の情報処理をモデル化する新しい枠組み Kriegeskorte, Deep Neural Networks: A New Framework for Modeling Biological Vision and Brain Information Processing, 2015](https://project-ccap.github.io/2015Kriegeskorte_Deep_Neural_Networks-A_New_Framework_for_Modeling_Biological_Vision_and_Brain_Information_Processing.pdf){:target="_blank"}
1. [計算論的認知神経科学 Kriegeskorte and Douglas, 2018, Cognitive computational neuroscience](https://project-ccap.github.io/2018Kriegeskorte_Douglas_Cognitive_Computational_Neuroscience.pdf){:target="_blank"}
1. [視覚系の畳み込みニューラルネットワークモデル，過去現在未来 Lindsay, 2020, Convolutional Neural Networks as a Model of the Visual System: Past, Present, and Future](https://project-ccap.github.io/2020Lindsay_Convolutional_Neural_Networks_as_a_Model_of_the_Visual_System_Past_Present_and_Future.pdf){:target="_blank"}


## 標準正則化理論 (Poggio1985)


1. [計算論的視覚と正則化理論 Poggio, Torre, Koch, 1985](https://komazawa-deep-learning.github.io/2021cogpsy/1985Poggio_Computational_Vision_and_Regularization_Theory.pdf){:target="_blank"}
1. [皮質における物体認識の階層モデル Riesenhuber and Poggio (1999) Nature](https://komazawa-deep-learning.github.io/2021cogpsy/1999Riesenhuber_Poggio_Hierarchical_models_of_object_recognition_in_cortex.pdf){:target="_blank"}


## 力学的エネルギー = 運動エネルギー + 位置エネルギー(ポテンシャル)

$$
E = K + U\\
E = \frac{1}{2}mv^2 + mgh
$$

- 統計物理学: 巨視的な物体，すなわち莫大な数の個別的な粒子，原子や分子，からなる物体のふるまいやっ性質を支配している特別な型の法則性を研究する学問分野

- [熱力学第一法則 エネルギー保存則](https://ja.wikipedia.org/wiki/%E3%82%A8%E3%83%8D%E3%83%AB%E3%82%AE%E3%83%BC%E4%BF%9D%E5%AD%98%E3%81%AE%E6%B3%95%E5%89%87)
- [熱力学第二法則 エントロピーは増大する](https://ja.wikipedia.org/wiki/%E7%86%B1%E5%8A%9B%E5%AD%A6%E7%AC%AC%E4%BA%8C%E6%B3%95%E5%89%87)


## 用語の整理

<!-- - [初めての画像認識 <img src="https://raw.githubusercontent.com/komazawa-deep-learning/komazawa-deep-learning.github.io/4c5e1c665109926508b3fa505914b60b7237bf62/assets/colab_icon.svg">](https://github.com/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0515komazawa_ResNet50_demo.ipynb){:target="_blank"}-->

<!-- - [機械学習の超簡単デモ <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2021_0507_3mnists_demo.ipynb){:target="_blank"} -->

### 訓練データ，テストデータ，検証データ
* 機械学習では，心理統計で用いられるような 仮説検定を行うこともありますが，むしろ，行わない場合も多いです。
* 理由としては，仮説検定を行うことによりも，モデルの性能を向上させることに主眼があるからという意味合いであろうと考えられます。
* ですが，考え方は母集団統計量の推定と同じような発想をします。すなわち，まだ見ぬ未知のデータに対して精度が良いモデルが優れているモデルと判断されます。
* 訓練データを使ってモデルを作成し，作成したモデルの評価をテストデータを使って評価します。
* このとき，テストデータは訓練には使いません。未知のデータに対しての精度でモデルの性能の優劣を競います。従って，モデルの精度の良いモデルが良いモデルであり，かつ，良いモデルとは，未知のデータに対してより精度が高く動作するモデルとなります。
* この点については，母集団の統計量の優劣を考える心理統計とは異なります。
* 真の母集団という，ありもしない曖昧 (かも知れない) 仮想集団について斟酌するよりも，実際のデータについて精度の優劣でモデルの性能を競うという意味では，実務的な発想と言えるでしょう。
* 機械学習におけるモデルの精度向上を目指したパラメータチューニングのことを **学習** と呼びます。

### 過学習

* モデルのパラメータを学習するときに，同じデータを用いて性能を検証することは，方法論的に間違っていると言えます。
* すでに見たことのある敵をたおせても，真の勇者とは言えません。何度でも生き返ることができる RPG とは違います。
* 見たことのあるデータ （遭遇した経験のあるモンスター）は倒せるでしょう。ですが，それでは 勇者 ではなく チキン です。
* 経験済のデータについては，完璧なスコアを示すことができるでしょう。ですが，まだ見ぬデータに対して有用な予測をすることはできません。
* このような状況を 過学習 (over-learning) あるいは オーバーフィッティング (over-fitting) といいます。
* これを避けるために、（教師あり）機械学習を行う際には，利用可能なデータの一部を テストデータセット `X_test`, `y_test` として用意しておくのが一般的です。
* 一般に k-hold out 法などと呼ばれる手法は，訓練データセットを ｋ 個に分割します。その上で，k 個に分割した 1 つのデータ群を除いた k-1 群の訓練データを用いてモデルの学習を行います。学習の都度，残しておいたデータを用いて性能を評価します。
* この方法により，最終評価に用いるテストデータを使うこと無くチューニングを行います。
* **なぜ全データを用いないで，データを分割するのか？**
  * 未知の母集団を仮定しないで，モデルの優劣を正当に評価するための方法であるとみなすことができます。

### ロジスティック回帰

ロジスティック回帰とは 回帰の名前がついていますが，分類 問題を解くための手法です。
ある事象が生起する確率を $p$ とすれば，生起市内確率は $(1-p)$ と表せます。この確率比のことを **ロジット比** と呼びます。
ロジット比の対数が次式に従うことを仮定するのが，ロジスティック回帰です。

$$
\log\left(\frac{p}{1-p}\right) = e^{x}
$$

上式を解けば，

$$
p(x) = \frac{1}{1+e^{-x}}
$$

この式を **シグモイド関数** sigmoid function と呼びます。

<!-- #### 伏線回収

初回の授業で，COVID-19 の感染者数の変動を記述するモデルを紹介しました。
Kermack McKendrick モデルのポイントは 時刻 $t$ における感染者の増加率 $dp/dt$ は その時の感染者の比率と非感染者の比率 の積に比例する
と仮定することでした。 -->

上式を微分すると，次式を得ます:
$$
\frac{dp}{dt} = \beta p(t)\left(1-p(t)\right)
$$

上式を高等学校数学風味に書き換えると次式のようになります。

$$
y' = \beta y(1-y)
$$

ここでは $p$ を $y$ と書き換えました。
また微分を表す記号を プライム (') にしました。
この式は，高校学校 2 年生の知識で解くことができます。

あまり深入りする必要はありません。
ですが，$y$ を微分した右辺に，$x$ が入っていないことに注意です。

### 勾配降下法

重回帰では解析解が存在しました。一方，非線形問題は一般に解析解が存在しません。
その際に，目的関数を繰り返しによって求める方法があります。
**勾配降下法** gradient descent methods はその一つです。
任意の点 $x$ における関数 $f(x)$ の微分が定義されていれば，求める関数の最小値は次式:

$$
\Delta\theta = \eta\frac{\partial f}{\partial\theta}
$$

を逐次計算することで求めることができると仮定します。
ここで $\theta$  はモデルのパラメータ，$f$ は目的関数，$\eta$ は学習率，$\partial$ は **偏微分** partial differential を表します。


<!--
Authors:    J.A. Anderson, A. Pellionisz, E. Rosenfeld (eds.)
Title:      Neurocomputing 2: Directions for Research
Reference:  MIT Press, Cambridge (1990), Massachusetts

### ANNs are some kind of non-linear statistics for amateurs
-->

<!--
## 次の語の示すサイトを訪れ，それぞれどのようなサイトかを調べよ。
いずれも現在のエコシステムとしての役割を果たしている。

1. arXiv: <font color="white">論文置き場</font>
2. Colab:
3. Github: <font color="white">プログラムのソースコード置き場</font>
4. Stack Oerflow: <font color="white">掲示板，ノウハウ集</font>
5. Reddit: <font color="white">掲示板，ただしビッグネーム本人が降臨することがある</font>
-->

<!--
# AI を学ぶ人間のための心構え
- 無知蒙昧から来るブラックボックス的な恐怖を払拭するよう務める(現時点での技術的な裏付けに基づく啓蒙活動)
- 現在の技術から予測できる近未来の展望を語ることを忌避しない(謙遜は美徳ではない)

<center>
<img src="https://blogs-images.forbes.com/markhughes/files/2016/01/Terminator-2-1200x873.jpg" style="width:32%">
<img src="http://zatugaku1128.com/wp-content/uploads/2016/09/%E3%83%89%E3%83%A9%E3%81%88%E3%82%82%E3%82%93.png" style="width:20%"></br>
</center>

未来はどっち？ **It will depend on you.**

# クイズ
* 次の語の組み合わせのうち不適切なものを指摘せよ

1. IBM - Watson - Joapady
2. DeepMind - AlphaGo - 囲碁
3. Google 翻訳 - ペッパー
4. Uber - 自動運転
-->

<!--
## 文献

- [労働新聞平成31年2月25日号 知識を拡張する道具 人類の歴史の延長線上に](/2019laborNews.pdf){:target="_blank"}
- [イラストで学ぶ 人工知能概論](https://www.amazon.co.jp/gp/product/4061538233/) (KS情報科学専門書) ([谷口](http://ai.tanichu.com/), 2014)
-->
<!--https://www.amazon.co.jp/gp/product/4061538233/ -->

<!--
- [Cognitive computational neuroscience](https://www.nature.com/articles/s41593-018-0210-5){target="_blank"}
-->
<!--- [Cognitive computational neuroscience](https://arxiv.org/abs/1807.11819)-->

<!--
## 小説，戯曲の中に現れた AI

- マリー・ウォルストンクラフト・シェリー　Mary Wallstoncraft Shelley，
  - フランケンシュタイン Frankenstein, or The Modern Prometheus
  - [https://www.aozora.gr.jp/cards/001176/files/44904_35865.html](https://www.aozora.gr.jp/cards/001176/files/44904_35865.html){target="_blank"}
- カレル・チャペック　Karel Capek,
  - ＲＵＲ ―ロッサム世界ロボット製作所 R.U.R. (Rossum's Universal Robots)
  - [https://www.aozora.gr.jp/cards/001236/files/46345_23174.html](https://www.aozora.gr.jp/cards/001236/files/46345_23174.html){target="_blank"}
- アイザック・アシモフ Issac Asimov,
  - われはロボット I, Robot
  - [https://www.amazon.co.jp/dp/4150105359](https://www.amazon.co.jp/dp/4150105359){target="_blank"}
- アーサー・クラーク Arthur C. Clarke,
  - 2001年宇宙の旅 2001: a Space Odyssey
  - [https://www.amazon.co.jp/dp/415011000X](https://www.amazon.co.jp/dp/415011000X){target="_blank"}

## 映画 AI
  - Matrix, Star Wars, Surrogate, ...

## TV anime
  - 鉄腕アトム，がんばれロボコン, ..., ガンダム，エヴァ，

# クイズ
* 小説，戯曲，に現れたロボット，人工知能を年代順に並べよ
1. アーサー・クラーク 2001 年宇宙の旅
2. アイザック・アシモフ われはロボット
3. カレル・チャペック ロボット
4. マリー・シェリー フランケンシュタイン
-->

## 勾配降下法 Gradient descent methods

<center>
<img src="https://miro.medium.com/max/814/1*kmmjFBP5vRkKOM1SP4URpA.png" style="width:33%"><br/>

出典: [The Complete Beginner’s Guide to Deep Learning: Artificial Neural Networks](https://towardsdatascience.com/simply-deep-learning-an-effortless-introduction-45591a1c4abb)
</center>


### 損失，誤差，目的，および，コスト関数

- コスト関数 cost function
- 損失関数 loss function
- 誤差関数 error function
- 目的関数 objective function

$$
p(\mathbf{y}\vert \mathbf{x};\mathbf{\theta})
$$

**最小二乗誤差**（下式）, あるいは**負の対数尤度** negative log likelifood ($-\log(x)$) など

$$
J(\mathbf{\theta})=\frac{1}{2}\mathbb{E}_{\mathbf{x,y}\sim\hat{p}_{data}}
\left\|\mathbf{y}-f(\mathbf{x};\mathbf{\theta})\right\|^2+\mbox{const.}
$$


### 交差エントロピー損失関数
ニューラルネットワークや機械学習において，予測すべき値が2値化された量，たとえば真偽値真であれば $1$ をとり，偽
であれば $0$ であったり，確率である場合には，最小化すべき目標関数(正則化項を含めて損失関数でもよい)は平均二乗
誤差 Mean Square Errors ではなく **交差エントロピー cross-entropy 損失**，あるいは交差エントロピー誤差と呼ぶ関
数が用いられる。

自乗誤差に比べて交差エントロピーを用いると学習が高速化される。
<!-- 理由は以下で説明する-->
文献的にはニューラルネットワークに交差エントロピーが導入されたのは Hinton(1989) など

交差エントロピーは次式で表される:

$$
\mathcal{L}=-t\log(y)-(1-t)\log(1-y),
$$<!-- {#eq:def-cross-entropy}-->

ここで $t$ は教師信号すなわち $1$ または $0$ をとり，$y$ はニューラルネットワークから出力された予測値。

上式は （確率とみなせる）出力 $y$ が $t$ 回起こった と解釈できる $y^t$ このときの $t$ の値はは $0$ か $1$ しか取らないので，
上式右辺は，もし $t$ が 1 であれば右辺第一項を計算し，$t$ が $0$ であれば 右辺第2項を計算することになる。

右辺第一項と右辺第二項とを別曲線として描いた下図。

<center>
<img src="/assets/cross-entropy.svg" style="width:39%"><br/>
<!--      https://raw.githubusercontent.com/komazawa-deep-learning/komazawa-deep-learning.github.io/e69ca10d8b2a4e9f34943fc302e5eafc7dbd934d/assets/cross-entropy.svg-->
交差エントロピーのグラフ
</center>

ここで対数 $\log$ の底は $e$ や $2$ が用いられる。

## エントロピー
エントロピーには熱力学エントロピーと情報論的エントロピーと $2$ 種類存在するがどちらも同じ形式をしている。情報
論的には平均エントロピー $H$ を以下のように定義する

$$
H[X]=-\sum_i X_i\log(X_i)
$$

上式 は 平均情報量 [@Shannon1948] とも呼ばれる。連続変量の場合には総和記号 $\sum$ が積分記号 $\int$ となって
$$
H[x]=-\int x\log(x)\;dx
$$

<center>
<img src="/assets/shannon-entropy.svg" style="width:29%"><br/>
シャノンのエントロピー
</center>

### まとめ

- コスト関数，損失関数，誤差関数，目的関数，はほぼ同じような意味で用いられる
- 代表的なコスト関数として，最小自乗誤差，交差エントロピー誤差，などがある
- 出力が確率で与えられるような問題，たとえば，分類問題などでは交差エントロピー誤差関数が用いられる



## 一般化とオーバーフィッティング，アンダーフィッティング
<!--Generalization, Overfitting and Under-fitting-->

- データへの当てはまりが良いことが良いモデルではない
- 未知のデータに対してどれほど当てはまるのかがモデルの性能を決める
<!--
* 訓練データ training data 実際に学習に用いたデータ
* テストデータ test data 未知のデータ，訓練時には使用していないデータ
-->
* オーバーフィッティング 訓練データへの過剰適合
* アンダーフィッティング 訓練データを十分に学習できない場合
<!--
* データ数(*小*) アンダーフィットする可能性**大**
-->

<center>
<img src="/assets/04_07underOverFittings.svg" style="width:59%"><br/>
</center>

- [多項回帰による過剰適合，デモ <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/notebooks/2020Sight_Visit_polynomilal_fittings_demo.ipynb)

<!-- It's not a good idea to test a machine learning model on a dataset which we used to train it, since it won't g ive any indication of how well our model performs on unseen data.
The ability to perform well on unseen data is called generalization, and is the desirable characteristic we want in a model.
When a model performs well on training data (the data on which the algorithm was trained) but does not perform well on test data (new or unseen data), we say that it has overfit the training data or that the model is overfitting.
This happens because the model learns the noise present in the training data as if it was a reliable  pattern.
Conversely, when a model does not perform well on training data (i.e. it fails to capture patterns present in the training data) as well as unseen data then it is said to be under-fitting.
That is, the model is unable to
 capture patterns present in the training data.
A smaller dataset can significantly increase the chance of overfitting.
This is because it is much tougher to separate reliable patterns from noise when the dataset is small.[1]
Examples of overfitting and under-fitting-->

$y = w_0 + w_1 x$,

$y = w_0 + w_1 x_1 + w_2 x_2$,

$y = w_0 + w_1 x_1 +\cdots + x_nx_n$


<!--
Suppose we have the following dataset (red points in the figure), where we have only one input variable x and one output variable y.

If we fit y = w0 + w1x to the above dataset, we get the straight line fit as shown above.
Note that this is not a good fit since it is quite far from many data points.
This is an example of under-fitting.

Now, if we add another feature x2 and fit y = w0 + w1x1 + w2x2 then we'll get a curve fit as shown above.
(Side note: This is still a linear model.
x2 is a feature, i.e. input.
The weights are w's and they are interacting linearly with the features x and x2.
The curve we are fitting is a quadratic curve).
As you can see, this is slightly better since it passes much closer to the data points above.

If we keep adding more features we'll get a curve that is more and more complex and that passes through more and more data points.
Above figure shows an example.
This is an example of overfitting.
In this case, we are performing polynomial fitting y = w0 + w1x1 + w2x2 + ... + wdxd.
Even though the fitted curve passes through almost all points, it won't perform well on unseen data. -->

### オーバーフィッティングの回避
<!-- Strategies to Avoid Overfitting

One way to avoid overfitting it to collect more data.
However, that is not always feasible.
Below are some other strategies to overcome the problem of overfitting - regularization and cross-validation. -->

### 正則化 Regularization

モデルの複雑さを調整する

<!--
In regularization, we combat overfitting by controlling the model's complexity, i.e. by introducing an additio
nal term in our cost function in-order to penalize large weights. This biases our model to be simpler, where s
impler is weights of smaller magnitude (or even zero). We want to make the weights smaller, because complex mo
dels and overfitting are characterized by large weights. Recall the mean-squared error cost function,
J(w)=1nn∑i=1(y(xi)−yit)2
-->

### L2 正則化 リッジ回帰
<!--Regularization or Ridge Regression-->

$$
\text{目的関数} = \text{誤差} + \lambda \left|w\right|^2
$$

<!--
In L2 regularization, a commonly used regularization technique, we add a penalty proportional to the squared m
agnitude of each weight. Our new cost function with L2 regularization is as follows:-
J(w)=1nn∑i=1(y(xi)−yit)2+λ||w2||
where, the first term is the same as in regular linear regression (without any regularization), and the second
 term is the regularization term. λ is a hyper-parameter that we choose and decides the regularization strengh. Larger values of λ imply more regularization, i.e. smaller values for the model parameters. ||w2|| is w12  w22 + ... wd2.
-->
- L2 正則化はパラメータの絶対値が大きくなると罰則項 pernalty term として作用

<!--
L2 regularization penalizes the larger weights more (since the penalty is proportional to the weight squared).
 For example, reducing w = 10 to w = 9 has a larger effect on the penalty term (102-92) than reducing w = 3 to
 w = 2 (32-22).
-->

### L1 正則化 Lasso 回帰 <!--Regularization or Lasso Regression-->

$$
\text{目的関数} = \text{誤差} + \lambda\left|w\right|
$$

<!--
In L1 regularization, we the penalty term is λ ||w||. That is, our cost function is:
J(w)=1nn∑i=1(y(xi)−yit)2+λ||w||
-->
<!--
An interesting property of L1 regularization is that model's parameters become sparse during optimization, i.e
. it promotes a larger number of parameters w to be zero. This is because smaller weights are equally penalize
d as larger weights, whereas in L2 regularizations, larger weights are being penalized much more. This sparse
property is often quite useful. For example, it might help us identify which features are more important for m
aking predictions, or it might help us reduce the size of a model (the zero values don't need to be stored).
Ordinary least square (which we saw earlier in linear regression) with L2 regularization is known as Ridge Reg
ression and with L1 regularization it is known as Lasso Regression.
Cross Validation and Validation Datasets
-->

### 正則化項

- 簡潔さ原理 simplicity principle L1
- 滑らかさ原理 smoothness principle L2
- 疎性原理 sparseness principle L0

<center>
<img src="/assets/Regularization.svg" style="width:44%"><br/>
</center>

#### 正則化項の影響

<center>
<img src="/assets/2001Hastie_p84.png" style="width:33%">
<img src="/assets/2001Hastie_p89.png" style="width:33%"><br/>
<img src="/assets/2001Hastie_p91.png" style="width:49%"><br/>
</center>
Hastie (2001) より

### まとめ

- アンダーフィッテイングとオーバーフィッティング
- データ数に比べて，推定すべきパラメータが多過ぎ = オーバーフィッティング
- データ数に比べて，推定すべきパラメータが少な過ぎ = アンダーフィッティング
- 正則化 L1, L2, L0, エラスティック
- 正則化項の大きさ $\lambda$ はハイパーパラメータと呼ぶ


## 交差妥当性 cross validation

<!-- is a method for finding the best hyper-parameters of a model.
For example, in gradient descent, we need to choose a stopping criteria.
The simplest stopping criteria is to check whether our accuracy is improving on the training dataset.
However, this is prone to overfitting since the model might be capturing noise present in the training data as reliable patterns. -->

## ホールド・アウト法 Holdout method

データを訓練データと検証データに分割
<!-- We can overcome this problem by not using the entire training data while training a model.
Instead we will hold out some data (validation dataset) and we'll train only on remaining data.
For example, we can split our training dataset into 70/30 and use 70% data for training and 30% data for validation.
In the above example of gradient descent, now we train our algorithm on the training data, but check whether or not our model is getting better on the validation dataset.
This is known as the holdout method and it is one of the simplest cross validation methods.
We can also use the validation data for other types of experimentation. Such as if we want to run multiple experiments where we choose different features to use to train our machine learning model. -->

- k ホールド法 K-fold Cross Validation

データを k 個に分割して, k-1 データで訓練，残りの 1 で検証
<!-- In K-fold cross validation, the dataset is divided into k separate parts. We repeat training process k times.
Each time, one part is used as validation data, and the rest is used for training a model.
Then we average the error to evaluate a model. Note that k-fold cross validation increases the computational requirements for training our model by a factor of k.
-->

<!-- The main advantages of k-fold cross validation are that
1. It is more robust to over-fitting than the holdout method when performing large number of experiments.
2. It is better to use when the dataset size is small. This is because when performing k-fold cross-validation, we can use a much smaller validation split (say 10% instead of 30%) since we are testing the model on various subsamples of the data being in the 10%.
Leave-one-out cross validation is a special instance of k-fold cross validation in which k is equal to the number of data points in the dataset.
Each time, we hold out a single data point and train a model on rest of the data.
We use the single data point to test our model. Then we calculate the average error to evaluate a model. -->


- 初期停止 early stopping

オーバーフィッティングを避ける方法の一つ: 学習打ち切り基準

<center>
<img src="/assets/04_07earlyStopping.svg" style="width:33%"><br/>
</center>



## SGD


<center>
<img src='/assets/2014Imgur_Saddle_point.gif' style='width:33%'>
<img src='/assets/2014Imgur_Beales_function.gif' style='width:33%'>
<img src='/assets/2014Imgur_Long_Valley.gif' style='width:33%'>
</center>


```python
import IPython
isColab = 'google.colab' in str(IPython.get_ipython())
if isColab:
    !pip install japanize_matplotlib

import numpy as np
import matplotlib.pyplot as plt
import japanize_matplotlib
%config InlineBackend.figure_format = 'retina'

# 様々な出力関数の描画
x = np.linspace(-3, 4, 100)                                        # 定義域 x の設定，本例の場合 [-3,4) を 100 刻み
relu = lambda x: np.maximum(0, x)                                  # 整流線形化関数 ReLU の定義
leaky_relu = lambda x: np.maximum(0, x) + 0.1 * np.minimum(0, x)   # リーキー ReLU の定義
elu = lambda x: (x > 0)*x + (1 - (x > 0)) * (np.exp(x) - 1)        # elu の定義
sigmoid = lambda x: (1+np.exp(-x))**(-1)                           # シグモイド関数の定義

def softmax(w, t = 1.0):
    """ソフトマックス関数の定義"""
    e = np.exp(w)
    dist = e / np.sum(e)
    return dist

x_softmax = softmax(x)

plt.figure(figsize=(8,6))
plt.plot(x, relu(x), label='ReLU', lw=2)
plt.plot(x, leaky_relu(x), label='Leaky ReLU',lw=2)
plt.plot(x, elu(x), label='Elu', lw=2)
plt.plot(x, sigmoid(x), label='シグモイド関数',lw=2)
plt.legend(loc=2, fontsize=16)
plt.title('様々な活性化関数', fontsize=20)
plt.ylim([-2, 4])
plt.xlim([-3, 3])
plt.show()
```

## 整流線型ユニット ReLU (Recutified Linear Unit)

**整流線型ユニット ReLU** とは，ニューラルネットワークの活性化関数の一つです。
シグモイド関数や，ハイパータンジェント関数に比べて，極端に単純な形をしています。
駄菓子菓子，生理学との対応についても根拠を持っています。

<!-- The **ReLU** (rectified linear unit) layer is another step to our convolution layer.
You’re applying an activation function onto your feature maps to increase non-linearity in the network.
This is because images themselves are highly non-linear!
It removes negative values from an activation map by setting them to zero.

Convolution is a linear operation with things like element wise matrix
multiplication and addition.
The real-world data we want our CNN to learn will be non-linear.
We can account for that with an operation like ReLU.
You can use other operations like tanh or sigmoid. ReLU, however, is a popular choice because it can train the network faster without any major penalty to generalization accuracy.

Want to dig deeper? Try Kaiming He, et al. [Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification](https://arxiv.org/abs/1502.01852).

If you need a little more info about [the absolute basics of activation functions, you can find that here](https://towardsdatascience.com/simply-deep-learning-an-effortless-introduction-45591a1c4abb)!


Here’s how our little buddy is looking after a ReLU activation function turns all of the negative pixel values black


```python
viz_layer(activated_layer)
```

<center>
<img src="https://komazawa-deep-learning.github.io/assets/output2.jpg" style="width:84%">
</center>
-->



# ソフトマックス関数

## ゲートとして

<div class="figure figcenter">
<img src="/2023assets/2006Oreilly_wm_fig2.svg" width="49%">
<div class="figcaption">

#### 図 ゲートの概念図
ゲートが開いているときは，感覚入力は作業記憶を更新できるが，閉じているときはそれができない。
このため，妨害刺激など無関連情報が以前に記憶した情報の維持を妨げるのを防ぐことができる。
O'Reilly (2006) より
</div></div>


<!-- 
## ニューラルネットワークと機械学習とのコスト関数 (損失関数，誤差関数) の類似

<div class="figcenter">
<img src="/2023assets/2016Marblestone_fig1.jpg" width="77%"><br/>
</div>
<div class="figcaption">

図 1. 従来のニューラルネットワークと脳のようなニューラルネットワークの設計の違い。

* **(A)** 従来の深層学習では，教師あり学習は外部から供給されたラベル付きデータに基づいて行われる。
* **(B)** 脳では，ネットワークの教師付き学習は，誤差信号に対する勾配降下によって行うことができるが，この誤差信号は内部で生成されたコスト関数から発生する必要がある。
これらのコスト関数は，遺伝と学習の両方によって指定された神経モジュールによって計算される。
内部で生成されたコスト関数は，より複雑な学習のブートストラップに使われるヒューリスティックスを作り出す。
例えば，顔を認識する領域は，まず線の上に 2 つの点があることのような単純なヒューリスティックスを使って顔を検出するように訓練され，その後，教師なし学習と社会的報酬処理に関連する他の脳領域からの誤差信号から生じる表現を使って，顕著な表情を識別するようにさらに訓練されるかもしれない。
* **(C)** 皮質深層ネットワークの内部で生成されたコスト関数と誤差駆動型訓練は，いくつかの特殊な系を含むより大きなアーキテクチャの一部を形成している。
ここでは，訓練可能な皮質領域をフィードフォワード神経回路網として図式化しているが，LSTM や他のタイプのリカレントネットワークの方がより正確なアナロジーかもしれない， 適応と恒常的可塑性，タイミング依存的可塑性，直接的電気接続，過渡的シナプス・ダイナミクス，興奮性／抑制性のバランス，自発的振動活動，軸索伝導遅延 (Izhikevich2006) など，多くの神経細胞やネットワークの特性が，このようなネットワークが何をどのように学習するかに影響を与えるだろう。 -->

<!-- FIGURE 1.
Putative differences between conventional and brain-like neural network designs.
(A) In conventional deep learning, supervised training is based on externally-supplied, labeled data.
(B) In the brain, supervised training of networks can still occur via gradient descent on an error signal, but this error signal must arise from internally generated cost functions.
These cost functions are themselves computed by neural modules specified by both genetics and learning.
Internally generated cost functions create heuristics that are used to bootstrap more complex learning.
For example, an area which recognizes faces might first be trained to detect faces using simple heuristics, like the presence of two dots above a line, and then further trained to discriminate salient facial expressions using representations arising from unsupervised learning and error signals from other brain areas related to social reward processing.
(C) Internally generated cost functions and error-driven training of cortical deep networks form part of a larger architecture containing several specialized systems.
Although the trainable cortical areas are schematized as feedforward neural networks here, LSTMs or other types of recurrent networks may be a more accurate analogy, and many neuronal and network properties such as spiking, dendritic computation, neuromodulation, adaptation and homeostatic plasticity, timing-dependent plasticity, direct electrical connections, transient synaptic dynamics, excitatory/inhibitory balance, spontaneous oscillatory activity, axonal conduction delays (Izhikevich2006) and others, will influence what and how such networks learn. -->
</div>

