---
title: 2025 年度開講 駒澤大学 人工知能 I および II
author: 浅川 伸一
layout: home
---
<link href="/css/asamarkdown.css" rel="stylesheet">
<div align='right'>
<a href='mailto:educ0233@komazawa-u.ac.jp'>Shin Aasakawa</a>, all rights reserved.<br>
Date: 25/Apr/2025<br/>
Appache 2.0 license<br/><br/>
</div>

# 本日のメニュー

1. 数式の読み方
2. 教師あり学習と教師なし学習
3. ロジスティック回帰とサボーとベクターマシン (SVM)
4. Eigneface and Fisherface


### Galileo Galilei (1623) The Assayer (translation by Stillman Drake) より

<div>

Sarsi: 哲学をする際には有名な作家の意見に基づかなければならないという確固たる信念があるように思える。
もしかしたら彼は，哲学とは『イーリアス』や『オーランド・フュリオーソ』のような，ある作家のフィクションであり，そこに書かれていることが真実かどうかが最も重要なことだと思っているのかもしれない。<br/>
Sarsi: 問題はそうではない。
哲学は宇宙という壮大な書物に書かれている。
しかし，まず言語を理解し，その文字を読むことを学ばなければ，その書物を理解することはできない。
<font style="color:navy;font-size:20pt;font-weight:600">この本は数学の言語で書かれており</font>，その文字は三角形や円などの幾何学的図形である，数学がなければ，人は暗い迷宮の中を彷徨うことになる。
</div>

<!-- > In Sarsi I seem to discern the firm belief that in philosophizing one must support oneself upon the opinion of some celebrated author, as if our minds ought to remain completely sterile and barren unless wedded to the reasoning of some other person.
Possibly he thinks that philosophy is a book of fiction by some writer, like the Iliad or Orlando Furioso, productions in which the least important thing is whether what is written there is true.
Well, Sarsi, that is not how matters stand.
Philosophy is written in this grand book, the universe, which stands continually open to our gaze.
But the book cannot be understood unless one first learns to comprehend the language and read the letters in which it is composed.
It is written in the language of mathematics, and its characters are triangles, circles, and other geometric figures without which it is humanly impossible to understand a single word of it; without these, one wanders about in a dark labyrinth. -->

上の文章の哲学とは，自然哲学，すなわち，現代では科学のことであろう.

# 実習

* [オリベッティ顔データベースを用いた機械学習実習 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2025notebooks/2025_0425olivetti_face_detection.ipynb){:target="_blank"}
* [課題提出用フォルダ](https://drive.google.com/drive/u/3/folders/1QrIvRv5WKvx9psO9bUCWaPlqUnWLk52V){:target="_blank"}

---

[今際の際に黒板に書いてあったファインマンの言葉，カリフォルニア工科大学アーカイブ写真](http://archives.caltech.edu/pictures/1.10-29.jpg){:target="_blank"}

### 概念の整理

<div class="figcenter">
<img src="/2025assets/2018Kriegeskorte_fig2_new.svg" style="width:44%;">
<img src='/2025assets/2017Goodfelllow_Fig1_4rev.svg' width="44%"><br/>
左: Kriegeskorte and Douglas (2018) Fig.2 を改変<br/>
右: Goodfellow et al. (2017) Fig.1 を改変
<!-- <img src='/assets/2017Goodfellow_Fig1_4ja.svg' width="33%"><br/> -->
<!-- Goodfellow et al. (2017) Fig.1 を改変 -->
</div>

# 関連用語

- 機械学習 Machine Learning
- データサイエンス Data Science
- AI
- 統計学 Statistics
- 数学
- 情報理論，通信理論


## 数式の読み方と表記

* 関数:
    * $f(x)$: エフ オブ エックス  (この「オブ」を読むことが重要。なぜなら「エフエックス」と読んでしまうと，$f\times x$ の意味だと誤解するから)
    * $P(x)$: ピー オブ エックス (ピーを使う場合には，確率であることが多い)
* $\in$: イン 「含む」ことを意味する ($x\in D$)
* $\partial$: 偏微分の意。統一した読み方は無いが，「パーシャル」とは「ディファレンシャル」と読む人もいる。偏微分については取り上げない。
* $\top$: 行列の転置 (transpose) を表す。
* $\sim$: 「従う」を意味する
* $P(A\|B)$: 「ピー オブ エー ギブン ビー」と読む。縦棒 ($\|$) を条件付きであることを意味する。
    したがって，行頭の数式は，B が与えられた条件で A が起こる確率を意味する
* $\Delta$: 「デルタ」と読むが，差分を表す場合が多い。
* ギリシャ文字: $\alpha,\beta,\gamma,...,\mu,\sigma,\omega$ 統計学の伝統に従って，よく分からないものに使われる場合が多い。よく分からないとは，データ平均を $m$ (または $\bar{X}$) で表し，母集団平均を対応するギリシャ文字 $\mu$ で表す。
同様に，データ分散を $s^2$ で表し，対応する母集団分散を $\sigma^2$ で表す，などである。同じことであるが，$\pi$ は円周率を表すこともあるが，場合によっては，母集団確率を表すこともある。

* ベクトル: 太字の小文字 $\mathbf{x}$
* 行列: 太字の大文字 $\mathbf{W}$



## 機械学習

<div class="figcenter">
<img src="/assets/sklearn_map.svg" style="width:88%"><br/>
scikit-learn の カンペ (cheat sheet) を改変
</div>

- 重回帰，逆行列，線形代数
- 主成分分析，固有値，変分法，
- tSNE
- ロジスティック回帰
- サポートベクトルマシン SVM
<!-- - [番組 nothotdog について](https://komazawa-deep-learning.github.io/nothotdog/){:target="_blannk"}-->
<!-- [nothotdog 体感デモ](https://github.com/ShinAsakawa/2019komazawa/blob/master/notebooks/nothotdog.ipynb)-->


<!-- - [初めての画像認識 <img src="/assets/colab_icon.svg">](https://github.com/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0515komazawa_ResNet50_demo.ipynb){:target="_blank"}-->
<!-- - [機械学習の超簡単デモ 伏線回収バージョン<img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2021_0507_3mnists_demo.ipynb){:target="_blank"} -->

<!-- ### 3 つのデータセット: MNIST, Fashion MNIST, KMNIST

- 機械学習分野で頻用されるデータセットとして，手書き数字認識データである MNIST があります。
- MNIST は FAIR (フェイスブック人工知能研究所) 現所長 の Yan LeCun によって作成されました。
NIST とは，アメリカ合衆国版の JIS です。すなわち，標準化機関の手書き数字認識用データセットを 修正した (modified) という意味から MNIST と呼ばれます。
- MNIST は データ数が ７万で，訓練データ数 6 万，テストデータ １ 万からなります。
データは，縦横それぞれ 28 画素からなっています。コンピュータで扱う際に，コンピュータにとってキリの良い 32 画素ではなく，
周囲を切り取ったために，28 画素になっています。
- Fasshion MNIST は， MNIST と同じ画像形式で，ファッション画像，具体的には 10 種類のアパレル画像データです。
- kmnist は日本語のくずし字データセットです。形式は MNIST, Fashion MNIST と同じです。 -->



## 数式の読み方と表記

* 関数:
    * $f(x)$: エフ オブ エックス  (この「オブ」を読むことが重要。なぜなら「エフエックス」と読んでしまうと，$f\times x$ の意味だと誤解するから)
    * $P(x)$: ピー オブ エックス (ピーを使う場合には，確率であることが多い)
* $\in$: イン 「含む」ことを意味する ($x\in D$)
* $\partial$: 偏微分の意。統一した読み方は無いが，「パーシャル」とは「ディファレンシャル」と読む人もいる。偏微分については取り上げない。
* $\top$: 行列の転置 (transpose) を表す。
* $\sim$: 「従う」を意味する
* $P(A\|B)$: 「ピー オブ エー ギブン ビー」と読む。縦棒 ($\|$) を条件付きであることを意味する。
    したがって，行頭の数式は，B が与えられた条件で A が起こる確率を意味する
* $\Delta$: 「デルタ」と読むが，差分を表す場合が多い。
* ギリシャ文字: $\alpha,\beta,\gamma,...,\mu,\sigma,\omega$ 統計学の伝統に従って，よく分からないものに使われる場合が多い。よく分からないとは，データ平均を $m$ (または $\bar{X}$) で表し，母集団平均を対応するギリシャ文字 $\mu$ で表す。
同様に，データ分散を $s^2$ で表し，対応する母集団分散を $\sigma^2$ で表す，などである。同じことであるが，$\pi$ は円周率を表すこともあるが，場合によっては，母集団確率を表すこともある。

* ベクトル: 太字の小文字 $\mathbf{x}$
* 行列: 太字の大文字 $\mathbf{W}$

`to`:$\to$, `mapsto`:$\mapsto$, `rightarrow`:$\rightarrow$ , `Rightarrow`:$\Rightarrow$

# 人工知能 AI とは何か

- 「人工知能の基礎」（小林 一郎）
    - 人の知能，つまり，人が行なう知的作業は，推論，記憶，認識，理解，学習，創造といった現実世界に適応するための能力を指す．
人工の「知能」とは，人の「知能」のある部分を機械に行わせることによって創られる．
- デジタル大辞泉 《artificial intelligence》コンピューターで，記憶・推論・判断・学習など，人間の知的機能を代行できるようにモデル化されたソフトウエア・システム．AI．

シャピロ (Shapiro, Stuart C., 1992) は次の 3 つの分野だと書いている。

1. 計算論的心理学 Computational Psychology:  __人間の知的活動を理解するために人間のように振る舞うコンピュータプログラムを作ること__
1. 計算論的哲学 Computational Philosophy:  __人間レベルの知的活動を計算論的に理解すること。計算論的理解=コンピュータ上に実装可能なモデル__
1. 計算機科学 Advanced Computer Science:  __コンピュータ科学の拡張，発展。現在のコンピュータはプログラムされたことしか実行できないが，人間はプログラムされていなくても勝手に振る舞う。__

* Shapiro, Stuart C. (1992), "Artificial Intelligence", in Stuart C. Shapiro (ed.), Encyclopedia of Artificial Intelligence, 2nd edition (New York: John Wiley & Sons)


# 時代背景

- 18世紀 第 1 次産業革命: <span style="color:Blue">蒸気機関，都市部に大規模工場が出現</span>
- 20世紀初頭 第 2 次産業革命: <span style="color:Blue">電気，オートメーション化，自動車，飛行機，電車による移動手段の変化</span>
- 20世紀後半 第 3 次産業革命: <span style="color:Blue">情報化，コンピュータ化，グローバル化</span>
- 21世紀から 第 4 次産業革命: <span style="color:Blue">AI 人間の能力を越える機械</span>

<!--from [http://bootcamp.lif.univ-mrs.fr:8080/mainpage](http://bootcamp.lif.univ-mrs.fr:8080/mainpage)-->

<center>
<img src='/assets/2009Gray_4th_paradigm.svg' style='width:66%'><br>
Gray (2009) The 4th paradigm より
</center>

# サポートベクターマシン (SVM: Support Vector Machines)

サポートベクターマシン（SVM）では、特に非線形分離可能なデータを取り扱う場合や、ある程度の誤分類が許容される場合に、誤分類を許容するためにスラック変数が導入される。
これらは、各データ点の誤分類の程度を測定し、コストパラメータ（C）によって、マージンの最大化と分類誤りの最小化とのトレードオフを制御する。
<!-- In Support Vector Machines (SVM), slack variables are introduced to allow for misclassifications, especially when dealing with non-linearly separable data or when some degree of error is acceptable. 
They measure the extent of misclassification for each data point, with the cost parameter (C) controlling the trade-off between maximizing the margin and minimizing classification errors.  -->

説明：
* **ハードマージン SVM**：<br/>
ハードマージン SVM は、誤分類のない、データ点を完全に分離する超平面を見つけることを目的としている。
しかし、このアプローチは、ノイズの多いデータや非線形分離可能なデータを扱う場合、過度に厳格になる可能性がある。
* **ソフトマージン SVM**：<br/>
ハードマージン SVM の制限を解決するため、ソフトマージン SVM はスラック変数 (グサイ $\xi$) を導入する。
これらの変数は、一部のデータ点の誤分類を許容し、ハードマージンの場合よりも厳格ではない「マージン」を効果的に作成する。
* **コストパラメータ（C）**：<br/>
コストパラメータ（C）は、マージンの最大化と誤分類エラーの最小化とのトレードオフのバランスを取る上で重要な役割を果たす。
C の値が大きいと誤分類が厳しく罰せられ、過学習を引き起こす可能性がある。
一方、C の値が小さいと誤分類を許容するが、より頑健なモデルとなる可能性がある。
* **スラック変数 (グサイ $\xi$)**<br/>
各データ点には対応するスラック変数が存在し、その点の誤分類の度合いを表す。
値が 0 は正しく分類された点を示し、0 より大きい値は誤分類された点を示し、値が大きいほど誤分類の度合いが大きくなる。
本質的に、スラック変数は SVM モデルに柔軟性を提供し、一部の誤分類を許容することで、より複雑なデータセットに対応し、汎化性能を向上させる。

<!-- Explanation: 
* Hard Margin SVM:<br/>
A hard margin SVM aims to find a hyperplane that perfectly separates data points, with no misclassifications. 
However, this approach can be overly strict, especially when dealing with noisy or non-linearly separable data. 
* Soft Margin SVM:<br/>
To address the limitations of hard margin SVM, soft margin SVM introduces slack variables (ξ). $\zeta$
These variables allow for some data points to be misclassified, effectively creating a "margin" that is not as strict as in the hard margin case. 
* Cost Parameter (C):<br/>
The cost parameter (C) plays a crucial role in balancing the trade-off between maximizing the margin and minimizing misclassification errors. 
A high value of C penalizes misclassifications heavily, potentially leading to overfitting, while a lower value of C allows for more misclassifications but can result in a more robust model. 
* Slack Variable (ξ):$\zeta$<br/>
Each data point has a corresponding slack variable, which represents the degree of misclassification for that point. 
A value of 0 indicates a correctly classified point, while a value greater than 0 indicates a misclassified point, with higher values indicating a greater degree of misclassification. 
In essence, slack variables provide flexibility to the SVM model, allowing it to handle more complex datasets and improve generalization performance by tolerating some errors in the training -->


[Soft Margin SVM: Exploring Slack Variables, the ‘C’ Parameter, and Flexibility](https://pub.aimind.so/soft-margin-svm-exploring-slack-variables-the-c-parameter-and-flexibility-1555f4834ecc){:target="_blank"}



## ありえないほど (unreasonable) 有能な (effectiveness) 数学

<!-- ガリレイは，宇宙は数学の言葉で書かれていると言いました。以来，数学は神の摂理を知るための道具であり続けています。 -->
<!-- 数学的知識の詳細は不要だが，その精神は理解しておく必要がある。 -->

- 万物は数なり --- ピタゴラス
- 宇宙は数学語で書かれている。数学なしでは迷宮を理解できない --- ガリレイ
- 世界について最も理解不能なことは，それが理解可能なことだ --- アインシュタイン<!--“The most incomprehensible thing about the world is that it is at all comprehensible.”- Albert Einstein, US (German-born) physicist (1879 - 1955)-->
- 微積分は神がこの宇宙を作ったときの言葉である --- ファインマン<!--Calculus was the language that God had used when creating this universe. -->
- 作れなければ理解できたと言えない --- ファインマン

<!-- - All things are number. --- Pythagras
- (The universe) is written in mathematical language,%%and its characters are triangles, circles and other geometric figures, ... without which it is impossible to humanly understand a word; without these one is wandering in a dark labyrinth. --- Galileo Galilei
- What I cannot create, I do not understand. --- [Richard Feynman](https://en.wikiquote.org/wiki/Richard_Feynman)-->


- 若者よ，数学は理解するものではない，ただ慣れるだけだ --- フォン・ノイマン
- 科学は説明しないし，解釈もしない。ただモデルを作るだけである。この場合モデルとは観察された現象を説明する数学(的構成物)である。そのモデルは，ひとえに期待どおり正確であることで正当化される。 --- フォン・ノイマン
- われわれの宇宙はただ単に数学で記述されているだけではない。宇宙は数学である，我々は皆，大きな数学的実態の一部なのだ。--- テグマーク
<!-- ...Our universe isn't just described by math, but that it is math in the sense that we're all parts of a giant mathematical object... --- Max Tegmark -->

<!--
Neumann
  The sciences do not try to explain, they hardly even try to interpret, they mainly make models. By a model is meant a mathematical construct which, with the addition of certain verbal interpretations, describes observed phenomena. The justification of such a mathematical construct is solely and precisely that it is expected to work.

  Young man, in mathematics you don't understand things. You just get used to them. [von Neumann](https://en.wikiquote.org/wiki/John_von_Neumann)

  any discussion of the nature of intellectual effort in any field is difficult, unless it presupposes an easy, routine familiarity with that field. In mathematics this limitation becomes very severe. ---[von Neumann](https://en.wikiquote.org/wiki/John_von_Neumann)

Neumann
  If one has really technically penetrated a subject, things that previously seemed in complete contrast, might be purely mathematical transformations of each other.

[There's no sense in being precise when you don't even know what you're talking about](https://www.brainyquote.com/quotes/john_von_neumann_137953)
- John von Neumann.

Neumann
  I think that it is a relatively good approximation to truth — which is much too complicated to allow anything but approximations — that mathematical ideas originate in empirics. [John von Neumann](https://en.wikiquote.org/wiki/John_von_Neumann)
-->

<!-- ## 数学

数学というと，心理学徒にとっては，心理統計が真っ先に思い浮かぶでしょう。
ですが，統計的検定のためだけに数学があるわけではなく，むしろ逆だと思っています。 -->


1. [1960 Wigner "Unreasonable Effectiveness of Mathmatics and Natural Sciences"](https://www.maths.ed.ac.uk/~v1ranick/papers/wigner.pdf){:target="_blank"}
2. [1967 Hamming "The Unreasonable Effectiveness of Mathematics"](https://www.tandfonline.com/doi/abs/10.1080/00029890.1980.11994966){:target="_blank"}
3. [2009 Norvig "The Unreasonable Effectiveness of Data"](https://static.googleusercontent.com/media/research.google.com/ja//pubs/archive/35179.pdf){:target="_blank"}
4. [2015 Karpathy "The Unreasonable Effectiveness of Recurrent Neural Networks"](https://karpathy.github.io/2015/05/21/rnn-effectiveness/){:target="_blank"}
5. 2016 Bangu "On The Unreasonable Effectiveness of Mathematics in the Natural Sciences"
6. [2018 Westhuizen "The Unreasonable Effectiveness of the Forget Gate"](https://arxiv.org/pdf/1804.04849.pdf){:target="_blank"}
7. [2021 Gao "The Unreasonable Effectiveness Of Neural Network Embeddings"](https://medium.com/aquarium-learning/the-unreasonable-effectiveness-of-neural-network-embeddings-93891acad097){:target="_blank"}

<!-- Arthur Lesk in molecular biology, "The Unreasonable Effectiveness of Mathematics in Molecular Biology".[6]
Max Tegmark in physics, "The Mathematical Universe".[8]
Ivor Grattan-Guinness in mathematics, "Solving Wigner's mystery: The reasonable (though perhaps limited) effectiveness of mathematics in the natural sciences".[9]
Vela Velupillai in economics, "The Unreasonable Ineffectiveness of Mathematics in Economics".[10] -->

# 統計学の危機


## [ASA アメリカ統計学会の声明](https://doi.org/10.1080/00031305.2016.1154108){:target="_blank"}

一方で，心理統計で用いられる母集団に対する信頼性は，しばしば疑問が呈されている。
アメリカ統計学会(ASA) では $p$ 値 を用いることに警告を発する宣言を出している。

出典: [ASA Statement on Statistical Significance and P-values](https://amstat.tandfonline.com/doi/pdf/10.1080/00031305.2016.1154108){:target="_blank"},
[その和訳](/2023/2016ASA_state_on_p_values_ja){:target="_blank"}

1. **P 値は，データが指定された統計モデルとどの程度相性が悪いかを示すことができる** P-values can indicate how incompatible the data are with a specified statistical model.
2. **P 値は，研究された仮説が真である確率を測定するものではない。そうではなく，データがランダムな偶然だけから，生成された確率を測定するものである** P-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone.
3. **科学的な結論やビジネスや政策の決定は，p 値が特定の閾値を超えたかどうかだけに基づくべきではない** Scientific conclusions and business or policy decisions should not be based only on whether a p-value passes a specific threshold.
4. **適切な推論を行うには，完全な報告と透明性が必要である** Proper inference requires full reporting and transparency.
5. **P 値や統計的有意性は，効果の大きさや結果の重要性を測定するものではない** A p-value, or statistical significance, does not measure the size of an effect or the importance of a result.
6. **それ自体では，p 値はモデルや仮説に関する証拠の良い尺度を提供しない。** By itself, a p-value does not provide a good measure of evidence regarding a model or hypothesis.

    * [基礎と応用社会心理学 (BASP)  編集方針 (2014, 2015)](/2023/2015Basic_and_Applied_Social_Psychology_ban_p_values_ja){:target="_blank"}
    * [アメリカ統計学会の声明 2014, 2015](/2023/2016ASA_state_on_p_values_ja){:target="_blank"}
    * [統計学の誤り : 統計的妥当性の「ゴールドスタンダード」である P 値は多くの科学者が想定しているほど信頼できるものではない](/2023/2014Nuzzo_Statistical_errors_ja){:target="_blank"}
    * [統計的有意性を引退させろ](/2023/2019Amrhein_Retire_statistical_significance_ja){:target="_blank"}

では，どうすればよのでしょうか。
おそらく，その答えの一つが機械学習であると考えることもできるのです。

# ソーカル事件と当世流行馬鹿噺 (ファッショナブル・ナンセンス)

* [ソーカル事件](https://ja.wikipedia.org/wiki/%E3%82%BD%E3%83%BC%E3%82%AB%E3%83%AB%E4%BA%8B%E4%BB%B6){:target="_blank"},
イアン・ソーカルとジャック・ブリクモン「境界侵犯 --- 量子重力の変形解釈学に向けて」と題したポストモダンの科学批評のパロディーを書き、（もちろん編集者にはそれがパロディーだとは告げず）カルチュラル・スダディーズの雑誌ソーシャル・テクストに投稿した。
ソーシャル・テクスト誌では「サイエンス・ウォーズ」特集号 (1996) でこのパロディー論文を，まじめな学術論文として掲載した。
その三週間後に、リンガ・フランカ誌に寄せた記事でソーカルはこのいたずらを暴露した。
* [知の欺瞞](https://www.amazon.co.jp/dp/4006002610){:target="_blank"} のことを考えてください。
* ただ **騙されない** ようにしたいと願うだけです。


* この授業は，文化，思想，に関する議論をする科目ではありません。
ましてや，文壇，言論界，などに対するいかなるメッセージも含むものではありません。
* ですが，[ソーカル事件](https://ja.wikipedia.org/wiki/%E3%82%BD%E3%83%BC%E3%82%AB%E3%83%AB%E4%BA%8B%E4%BB%B6){:target="_blank"}, や [知の欺瞞](https://www.amazon.co.jp/dp/4006002610){:target="_blank"} のことを考えてください。
- ただ **騙されない** ようにしたいと願うだけです。

* ソーカル事件とは： 1996 年，ニューヨーク大学物理学教授アラン・ソーカルは「ソーシャル・テキスト」誌に「境界を越える Towards a transformative hermeneutics of quantum gravity（量子重力の変容的解釈学に向けて）」と題する論文を書いた。
この論文は査読を経て受理され，出版された。
ソーカルは即座に，この論文全体がデマであることを告白した。
極端なポストモダニズムの科学批判のスタイルを暴露し，パロディにするために，狡猾な言葉で書かれた論文だった。
この記事は世界中で一面トップニュースとなり，激しく広範な論争を引き起こした。

黒木(「ソーカル事件」1998，大学の物理教育(2), 25-28) より
「科学者は非専門家の無知には筧容であるべきである．
しかし，権威ある知識人がデタラメを述べていて，さらに，それが多くの人達に影響を与えている（もしくはその危険性が高い）場合においては，科学の専門家はそのことをきちんと指摘すべぎだと思う．(27 ページ)」

* 堀 茂樹 (1998) きみはソーカル事件を知っているか？, 平凡社, 月刊百科, 1998 年 2 月号 No.424, p.14−15 および 3 月号 No.425, p.42−43
* 黒木 玄 (1998) ソーカル事件, 大学の物理教育，Vol.2, 23-28.
* ソーカル，アラン & ブリクモン，ジャン, (田崎，大野，堀 訳) (2012)，[__「知」の欺瞞 ---ポストモダン思想における科学の濫用__](https://www.iwanami.co.jp/book/b255892.html){:target="_blank"}, 岩波現代文庫/学術 261, 岩波書店.

