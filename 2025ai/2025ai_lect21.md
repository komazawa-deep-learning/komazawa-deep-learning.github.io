---
title: "第21回 2025年度開講 駒澤大学 人工知能"
author: "浅川 伸一"
layout: home
codemirror_mode: python
codemirror_mime_type: text/x-cython
---

<div align="right">
<a href='mailto:educ0233@komazawa-u.ac.jp'>Shin Aasakawa</a>, all rights reserved.<br>
Date: 07/Nov/2025<br/>
Appache 2.0 license<br/>
</div>

<link href="/css/asamarkdown.css" rel="stylesheet">


# 第 21 回 後期第 7 回

* [課題提出用フォルダ](https://drive.google.com/drive/u/6/folders/1eEeUBv6mst4fSJ-0ta6aoNGLajC0RF9p){:target="_blank"}

## 実習

* [足し算モデル <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2025notebooks/2025_1104seq2seq.ipynb){:target="_blank"}
* [符号化器・復号化器モデル ちはやふる <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2023notebooks/2023_1113chihaya_Transformer.ipynb){:target="_blank"}
* [PyTorch による Transfomer 実装 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2023notebooks/2023_0602Transformer_from_scratch.ipynb){:target="_blank"}
* [chatGPT <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2023notebooks/2023_0608rinna_chatGPT_demo.ipynb){:target="_blank"}

<!-- * [実習 オーバーフィッティング，アンダーフィッテング <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/notebooks/2020Sight_Visit_polynomilal_fittings_demo.ipynb){:target="_blank"} -->

<!-- * WEAVER++, Dell モデルの再現シミュレーション
  - [他言語プライミング課題での事象関連電位 （ERP) のシミュレーション Roelofs, Cortex (2016) <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/project-ccap/project-ccap.github.io/blob/master/notebooks/2021Roelofs_ERP_bilingual_lemret.ipynb){:target="_blank"}
  - [概念バイアス `Conceptual Bias` (Reolofs, 2016) 絵画命名，単語音読，ブロック化，マルチモーダル統合 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/project-ccap/project-ccap.github.io/blob/master/notebooks/2021Roelofs_Conceptual_bias.ipynb){:target="blank"}
  - [2 ステップ相互活性化モデルデモ (Foygell and Dell, 2000) <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/project-ccap/project-ccap.github.io/blob/master/notebooks/2020ccap_Foygel_Dell2000_2step_interactive_activaition_model_demo.ipynb){:target="_blank"}
  - [WEVER++ デモ 2020-1205 更新 Reolofs(2019) Anomia cueing <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/project-ccap/project-ccap.github.io/blob/master/notebooks/2020ccap_Roelofs2019_Anomia_cueing_demo.ipynb){:target="_blank"} -->

* [BERT の微調整 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_0623BERT_SNOW_training.ipynb)
* [BERT のマルチヘッド注意の視覚化 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_1007BERT_head_view.ipynb)
* [日本語 BERT 2 つの文の距離を求めるデモ <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0624BERTja_test.ipynb)
* [sentenceBERT <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2023notebooks/2023_0602minimam_sentenceBERT.ipynb)

<!-- * [1990 年代の Stroop 効果のシミュレーション<img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2023notebooks/2023_1110Stroop_1990Cohen_model.ipynb){:target="_blank"}
* [転移学習による Stroop 効果のデモ<img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2023notebooks/2023_1123Stroop_model.ipynb)
* [chatGPT <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2023notebooks/2023_0608rinna_chatGPT_demo.ipynb)
* [Stable-baselines3 を用いた PPO デモ Atari Lunalander 月面着陸 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2023notebooks/2023_0619stable_baselines3_demo_LunaLander_V2.ipynb)
* [画像認識における注意 CAM <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2023notebooks/2021_0618CAM_demo.ipynb)
* [Stable diffusion デモ <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2023notebooks/2023_0707stable_diffusion.ipynb)
* [リカレントニューラルネットワークによる文処理デモ 青空文庫より，夏目漱石 こころ](https://komazawa-deep-learning.github.io/character_demo.html)
* [CartoonGAN 実習<img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0628CartoonGAN_demo.ipynb)
* [加算型注意 (Bahdanu) と 内積型注意 (Loung) の実習 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_1022Two_attentions_additive_and_multiplicative_Seq2seq.ipynb) -->

* Huggingface RTL
  * [TRL - Transformer Reinforcement Learning](https://github.com/huggingface/trl/tree/main)


<!-- * PyTorch 関連

  * [Pytorch によるニューラルネットワークの構築 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_1115PyTorch_buildmodel_tutorial_ja.ipynb){:target="_blank"}
  * [Dataset とカスタマイズと，モデルのチェックポイント，微調整 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2023notebooks/2023_0824pytorch_simple_fine_tune_tutorial.ipynb){:target="_blank"}
  * [PyTorch Dataset, DataLoader, Sampler, Transforms の使い方 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2023notebooks/2023_0824pytorch_dataset_data_loader_sampler.ipynb){:target="_blank"} -->

# Transformer

Transformer は人工知能へのアプローチを根本的に変えたニューラルネットワークのアーキテクチャである。Transformer は、画期的な論文 [Attention is All You Need](https://dl.acm.org/doi/10.5555/3295222.3295349 "ACM Digital Library") で初めて導入され、それ以来、深層学習モデルの定番アーキテクチャとなった。OpenAI の **GPT**、Meta の **Llama**、Google の **Gemini** といったテキスト生成モデルを支えている。テキスト以外にも、Transformer は[音声合成](https://huggingface.co/learn/audio-course/en/chapter3/introduction "Hugging Face")にも応用されている。[画像認識](https://huggingface.co/learn/computer-vision-course/unit3/vision-transformers/vision-transformers-for-image-classification "Hugging Face")、[タンパク質構造予測](https://elifesciences.org/articles/82819 "eLife")、さらには[ゲームプレイ](https://www.deeplearning.ai/the-batch/reinforcement-learning-plus-transformers-equals-efficiency/ "Deep Learning AI")まで、様々な分野でその汎用性を示している。

基本的に、テキスト生成型 Transformer モデルは**次単語予測**原理で動作する。ユーザからのテキストプロンプトが与えられた時、この入力に続く**最も確率の高い次単語** を予測する。
Transformer の中核的な革新性は、**自己注意機構** である。これにより、従来のアーキテクチャよりも効果的に系列全体を処理し、長距離依存関係を捕捉できる。

* Transformer: マルチヘッド注意機構，位置符号化器，埋め込み表現，ソフトマックス関数
* 事前訓練とファインチューニング: マスク言語モデル，次文予測  <!--Masked Language model, next sentence prediction--->
* GTP-4: 符号化器・復号化器モデルを用いた画像と言語との融合
* プロンプトエンジニアリングと RLHF (人間のフィードバックによる強化学習): 報酬モデルと代理方針最適化 (Proximal Policy Optimization)

<div class="figcenter">
<img src="/assets/2017Vaswani_Fig2_1.svg" width="09%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<img src="/assets/2017Vaswani_Fig2_2.svg" width="19%">&nbsp;&nbsp;&nbsp;
<img src="/assets/2017Vaswani_Fig1.svg" width="29%">
<div class="figcaption">

Transformer ([2017Vaswani++](https://arxiv.org/abs/1706.03762)) Fig.2 を改変
</div></div>



上図で，`matmul` は行列の積，`scale` は，平均 0 分散 1 への標準化，`mask` は 0 と 1 とで，データを制限すること，`softmax` はソフトマックス関数である。

トランスフォーマーの注意とは，このソフトマックス関数である。

<!-- <div class="figure figcenter">
<img src="figures/2017Vaswani_Fig2_1.svg" width="19%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<img src="figures/2017Vaswani_Fig2_2.svg" width="29%">&nbsp;&nbsp;&nbsp;
<img src="figures/2017Vaswani_Fig1.svg" width="39%"> -->

<!-- # Transformer(2): Attention is all you need -->


$$
\text{MultiHead}\left(Q,K,V\right)=\text{Concat}\left(\text{head}_1,\ldots,\text{head}_{h}\right)W^O
$$
where, $\text{head}_i =\text{Attention}\left(QW_i^Q,KW_i^K,VW_i^V\right)$

The projections are parameter matrices $W_i^Q\in\mathbb{R}^{d_{\text{model}}\times d_k}$, $W_i^K \in\mathbb{R}^{d_{\text{model}}\times d_k}$,
$W_i^V\in\mathbb{R}^{d_{\mathop{model}}\times d_v}$, and $W^O\in\mathbb{R} ^{hd_v\times d_{\mathop{model}}}$.
$h=8$, $d_k=d_v=\frac{d_{\mathop{model}}}{h}=64$

$$
\text{FFN}(x)=\max\left(0,xW_1+b_1\right)W_2+b_2
$$

$$
\text{PE}_{(\text{pos},2i)} = \sin\left(\frac{\text{pos}}{10000^{\frac{2i}{d_{\mathop{model}}}}}\right)
$$

$$
\mathop{PE}_{(\mathop{pos},2i+1)} = \cos\left(\frac{\mathop{pos}}{10000^{\frac{2i}{d_{\mathop{model}}}}}\right)
$$

<!-- # Transformer(3): Attention is all you need -->

<div class="figcenter">
<img src="/assets/2017Vaswani_Fig1.svg">
<div class="figcaption" style="width:33%">
[Vaswani+2017](https://arxiv.org/abs/1706.03762) Fig. 1 より
</div></div>

<!-- # Sejnowski2022

<div class="figcenter">
<img src="figures/2022Sejnowski_fig5.jpg" width="66%">
<div class="figcaption">

トランスフォーマーのループと皮質-基底核のループの比較。
(左) トランスフォーマーは，出力を入力とループさせて単語系列を生成するフィードフォワード自己回帰型アーキテクチャを持つ (Vaswani+2017)。
示された単一のエンコーダ/デコーダモジュールは N 層 深く (Nx) 積み重ねることができる。
(右) 位相的に写像された運動皮質は大脳基底核に投射し，大脳皮質にループバックして，話し言葉の単語列のような一連の動作を生成する。
大脳皮質のすべての部分が大脳基底核に投影され，前頭前野と大脳基底核の間の同様のループによって，思考の系列が生み出される。

thalamus: 視床，
putamen: 被殻
SMA: supplementary motor area 補足運動野
PM: premotor cortex 運動前野
STN: subthalamic nucleus 視床下核
GPi: internal segment of globus pallidus 淡蒼球内節
GP: globus pallidus     淡蒼球
M1: 一次運動野
</div></div>
-->

## 1 位置符号器 Position encoders

 Transformer の入力には，上述の単語表現に加えて，位置符号器からの信号も重ね合わされる。
位置 $i$ の信号は次式で周波数領域へと変換される:

$$
\text{PE}_{(\text{pos},2i)} = \sin\left(\frac{\text{pos}}{10000^{\frac{2i}{d_{\text{model}}}}}\right)\\
\text{PE}_{(\text{pos},2i+1)} = \cos\left(\frac{\text{pos}}{10000^{\frac{2i}{d_{\text{model}}}}}\right)
$$

位置符号器による位置表現は，$i$ 番目の位置情報をワンホット表現するのではなく，
周波数領域に変換することで周期情報を表現する試みと見なし得るだろう。

<div class="figcenter">
<img src="/assets/PE_example.svg" width="66%">
<div class="figcaption">
位置符号化に用いられる符号化
</div></div>


## Transformer アーキテクチャ

Transformer は、以下の **3 要素** で構成される:

1. **埋め込み embeddings**:テキスト入力は、単語または下位単語であるトークンと呼ばれる小さな単位に分割される。これらのトークンは、単語の意味を捉える埋め込みと呼ばれる数値ベクトルに変換される。
2. **Transformer ブロック**: 入力データを処理および変換するモデルの基本的な構成要素。各ブロックには以下が含まれる：
    * **注意機構 Attention Mechanism**：Transformer ブロックの中核成分。トークンが他のトークンと相互作用し、文脈情報や単語間の関係を把握できるように訓練される。
    * **多層パーセプトロン MLP（Mulit-Layered Perceptrons）層**：各トークンに対して独立して動作するフィードフォワードネットワーク。注意層ははトークン間の情報を選択，（経路づけ，フィルタリング）する。MLP は各トークン間の表現を後続層へ伝播する。
3. **出力確率 Probabilities**：最後の線形層とソフトマックス層は、処理された埋め込みを確率に変換し、モデルが系列内の次トークンについて予測できるようにする。


### 埋め込み Embeddings

埋め込み表現により，テキストをモデルが扱える数値表現に変換される。
プロンプトを埋め込みに変換するには、次の手順が必要である：
    1. 入力のトークン化、
    2. トークン埋め込みの取得、
    3. 位置情報の追加
    4. トークンと位置の符号化を足し合わせて最終的な埋め込みを得る。


* ステップ 1: トークン化<br/>
トークン化とは、入力テキストをトークンと呼ばれるより小さく扱いやすい単位に分割する処理だ。トークンは単語単位でも部分単語単位でもよい。`「Data」`や`『visualization』`は単一のトークンだが、`「empowers」`は 2 つのトークンに分割される。トークンの全語彙はモデル訓練前に決定される：GPT-2 の語彙は 50,257 個の固有トークンを持つ。入力テキストを固有 ID を持つトークンに分割したことで、埋め込み表現からそれらのベクトル表現を取得できる。
* ステップ 2. トークン埋め込み<br/>
GPT-small は語彙内の各トークンを 768 次元のベクトルで表現する。ベクトルの次元はモデルによって異なる。これらの埋め込みベクトルは `(50,257,768)` という形状の行列に格納され、約 3900 万個のパラメータを含む！この巨大な行列により、モデルは各トークンに意味的な意味を割り当てられる。
* ステップ 3. 位置符号化 PE: Position Encoder<br/>
埋め込み層は、入力プロンプト内での各トークンの位置に関する情報も符号化する。モデルによって位置符号化手法は異なる。
* ステップ 4. 最終埋め込み<br/>
最後に、トークンと位置符号化を合計して最終的な埋め込み表現を得る。この結合された表現は、トークンの意味と入力系列における位置の両方を捉える。

### Transformer Block

Transformer の処理の中核は、マルチヘッド自己注意機構と多層パーセプトロン層で構成される Transformer ブロックにある。
ほとんどのモデルは、こうしたブロックを複数個、順番に積み重ねて構成されている。トークンの表現は、最初のブロックから最後のブロックへと層を重ねるごとに変形され、モデルが各トークンに対する複雑な理解を構築することを可能にする。この層状のアプローチが、入力の高次表現を生み出す。小規模な GPT-small では 12 個のブロックで構成されている。

### マルチヘッド注意

自己注意機構により、モデルは入力系列の関連部分に焦点を当てられる。これによりデータ内の複雑な関係や依存性を捉えることが可能となる。

* Step 1: Query, Key, Value 行列<br/>
各トークンの埋め込みベクトルは、クエリ (Q)、キー (K)、値 (V) の 3 つのベクトルに変換される。これらのベクトルは、入力埋め込み行列を Q、K、V 用に学習された重み行列で乗算することで得られる。

  - **クエリ (Q)** は検索エンジンのバーに入力する検索テキストである。これは**より多くの情報を得たい**トークンである。
  - **キー (K)** は検索結果ウィンドウ内の各ウェブページのタイトルである。これはクエリが注目できる可能性のあるトークンを表す。
  - **値 (V)** は表示されるウェブページの実際のコンテンツだ。適切な検索語（クエリ）と関連する結果（キー）を一致させた後、最も関連性の高いページのコンテンツ（値）を取得したい。

これらの Q,K,V ベクトルを用いることで、モデルは予測を生成する際に各トークンにどれだけの注意を向けるべきかを決定する注意得点を計算できる。

*  ステップ 2: マルチヘッド分割<br/>
クエリ(Q)、キー(K)、値 (V) ベクトルは複数のヘッドに分割される。GPT-small の場合 12 個のヘッドに分割される。各ヘッドは埋め込みのセグメントを独立して処理し、異なる構文的・意味的関係を捕捉する。この設計により多様な言語的特徴の並列学習が可能となり、モデルの表現力が向上する。

* ステップ 3：マスク化自己注意 Masked Self-Attention

各ヘッドにおいて、マスク化自己注意の計算を行う。この仕組みにより、モデルは入力の関連部分に焦点を当てつつ、将来のトークンへのアクセスを制限することで、系列を生成できる。

  - **注意得点**: クエリ行列とキー行列の内積は、各クエリと各キーの整合性を決定し、全入力トークンの関係を反映した正方行列を生成する。
  - **マスキング**: 注意行列の上三角部分にマスクし、モデルが将来のトークンにアクセスするのを防ぐ。これらの値は負の無限大に設定される。モデルは未来を「覗き見」せずに次のトークンを予測する方法を学ぶ必要がある。
  - **ソフトマックス**: マスク後、注意得点はソフトマックス演算によって確率に変換される。これは各得点の指数を計算する。行列の各行の合計は 1 となり、左側にある他の全てのトークンとの関連性を示す。

* ステップ 4: 出力と連結

モデルはマスク化自己注意得点を用い、それらを 値 行列と乗算することで自己注意機構の最終出力を得る。GPT-2 は 12 の自己注意ヘッドを持ち、各ヘッドはトークン間の異なる関係を捕捉する。これらのヘッドの出力を連結し、線形射影を通す。

### 多層パーセプトロン MLP: Multi-Layer Perceptrons

自己注意の複数のヘッドが入力トークン間の多様な関係を捕捉した後、連結された出力は多層パーセプトロン (MLP) 層を通過し、モデルの表現能力を高める。MLP ブロックは 2 つの線形変換で構成され、その間に GELU 活性化関数が挟まれている。最初の線形変換は入力次元を 4 倍に拡大し、768 から 3072 とする。2 番目の線形変換は次元を元の 768 に戻し、後続層が同次元の入力を受け取るようにする。自己注意機構とは異なり、MLP はトークンを独立して処理し、単に一つの表現から別の表現へ写像するだけである。
<!-- After the multiple heads of self-attention capture the diverse relationships between the input tokens, the concatenated outputs are passed through the Multilayer Perceptron (MLP) layer to enhance the model\'s representational capacity. The MLP block consists of two linear transformations with a GELU activation function in between. The first linear transformation increases the dimensionality of the input four-fold from `768` to `3072`. The second linear transformation reduces the dimensionality back to the original size of `768`, ensuring that the subsequent layers receive inputs of consistent dimensions. Unlike the self-attention mechanism, the MLP processes tokens independently and simply map them from one representation to another. -->

## 確率

入力が全 Transformer ブロックを通過した後、出力は最終線形層を通過し、トークン予測の準備が整う。この層は最終的な表現を 50,257 次元の空間に射影し、辞書内の各トークンには logit と呼ばれる対応する値が割り当てられる。どのトークンも次の単語となり得るため、この処理により各トークンが次の単語となる確率に基づいて単純にランク付けできる。次に、ソフトマックス関数を適用してロジットを合計が1になる確率分布に変換する。これにより、各トークンの出現確率に基づいて次のトークンをサンプリングできるようになる。
<!--After the input has been processed through all Transformer blocks, the output is passed through the final linear layer to prepare it for token prediction. This layer projects the final representations into a `50,257` dimensional space, where every token in the vocabulary has a corresponding value called `logit`. Any token can be the next word, so this process allows us to simply rank these tokens by their likelihood of being that next word. We then apply the softmax function to convert the logits into a probability distribution that sums to one. This will allow us to sample the next token based on its likelihood. -->

<img src="/2025assets/softmax.png" width="49%;"><br/>
<!-- ![](./article_assets/softmax.png){width="70%"} -->
図 5. 語彙内の各トークンには、モデルの出力ロジットに基づいて確率が割り当てられる。これらの確率は、各トークンがシーケンスの次の単語となる可能性を決定する。
<!-- Figure [5]{.attention}. Each token in the vocabulary is assigned a probability based on the model\'s output logits. These probabilities determine the likelihood of each token being the next word in the sequence. -->

最後のステップは、この分布からサンプリングして次のトークンを生成することである。この過程において `temperature` ハイパーパラメータは重要な役割を果たす。数学的に言えば、これは非常に単純な操作である：モデルの出力ロジットを単に`temperature` で割るだけだ。
<!-- The final step is to generate the next token by sampling from this distribution The `temperature` hyperparameter plays a critical role in this process. Mathematically speaking, it is a very simple operation: model output logits are simply divided by the `temperature`: -->

- `temperature = 1`: ロジット値を 1 で割っても、ソフトマックス出力には影響しない。
- `temperature < 1`: 温度を下げると確率分布が鋭くなり、モデルの自信と決定論が高まる。これにより出力の予測可能性が増す。
- `temperature > 1`: 温度を上げると確率分布が柔らかくなり、生成テキストにランダム性が増す。これはモデルが **創造性** を発揮すると言われる現象だ。

<!-- - `temperature = 1`: Dividing logits by one has no effect on the softmax outputs.
- `temperature < 1`: Lower temperature makes the model more confident and deterministic by sharpening the probability distribution, leading to more predictable outputs.
- `temperature > 1`: Higher temperature creates a softer probability distribution, allowing for more randomness in the generated text -- what some refer to as model *"creativity"*. -->

さらに、サンプリングプロセスは top-k と top-p パラメータを用いてさらに調整できる：
<!-- In addition, the sampling process can be further refined using `top-k` and `top-p` parameters:-->

- `top-kサンプリング`：候補トークンを確率が最も高い上位kトークンに限定し、可能性の低い選択肢を除外する。
- `top-pサンプリング`：累積確率が閾値pを超える最小のトークン集合を考慮し、多様性を保ちつつ最も可能性の高いトークンのみを寄与させる。


<!--- `top-k sampling`: Limits the candidate tokens to the top k tokens with the highest probabilities, filtering out less likely options. 
- `top-p sampling`: Considers the smallest set of tokens whose cumulative probability exceeds a threshold p, ensuring that only the most likely tokens contribute while still allowing for diversity.
-->

temperature，top-k，top-p を調整することで、決定論的出力と多様性のある出力のバランスを取ることができ、モデルの挙動を特定のニーズに合わせて調整できる。
<!--By tuning `temperature`, `top-k`, and `top-p`, you can balance between deterministic and diverse outputs, tailoring the model\'s behavior to your specific needs. -->

## 高度なアーキテクチャ機能<!-- ## Advanced Architectural Features-->

Transformer モデルの性能を向上させる高度なアーキテクチャ機能がいくつか存在する。モデルの全体的な性能には重要だが、アーキテクチャの核心概念を理解する上ではそれほど重要ではない。層正規化、ドロップアウト、残差結合は、特に学習段階で Transformer モデルにおいて重要な構成要素である。層正規化は学習を安定させ、モデルの収束を早める。ドロップアウトはニューロンをランダムに無効化することで過学習を防ぐ。残差接続は勾配がネットワークを直接流れることを可能にし、勾配消失問題の防止に寄与する。
<!--There are several advanced architectural features that enhance the performance of Transformer models. While important for the model's overall performance, they are not as important for understanding the core concepts of the architecture. Layer Normalization, Dropout, and Residual Connections are crucial components in Transformer models, particularly during the training phase. Layer Normalization stabilizes training and helps the model converge faster. Dropout prevents overfitting by randomly deactivating neurons. Residual Connections allows gradients to flow directly through the network and helps to prevent the vanishing gradient problem. -->


### 層正規化 Layer Normalization

層正規化は、学習過程を安定させ収束を改善する。これは特徴量全体で入力を正規化し、活性化値の平均と分散が一定になるようにする。この正規化により内部共変量シフトに関連する問題を軽減でき、モデルがより効果的に学習し、初期重みへの依存性を低減できる。層正規化は各 Transformer ブロックで 2 回適用される。1 回目は自己注意機構の前、2 回目は MLP 層の前である。
<!--Layer Normalization helps to stabilize the training process and improves convergence. It works by normalizing the inputs across the features, ensuring that the mean and variance of the activations are consistent. This normalization helps mitigate issues related to internal covariate shift, allowing the model to learn more effectively and reducing the sensitivity to the initial weights. Layer Normalization is applied twice in each Transformer block, once before the self-attention mechanism and once before the MLP layer.-->

### ドロップアウト Dropout

ドロップアウトは、ニューラルネットワークの過学習を防ぐための正則化手法である。学習中にモデルの重みの一定割合をランダムにゼロに設定することで、モデルがより頑健な特徴を学習するよう促し、特定のニューロンへの依存を減らす。これによりネットワークは未知の新規データに対してより良く一般化できるようになる。モデルの推論時にはドロップアウトは無効化される。これは実質的に、学習済み部分ネットワークの集合体を使用していることを意味し、結果としてモデルの性能向上につながる。

### 残差結合 Residual Connections

残差結合は 2015 年に ResNet モデルで初めて導入された。このアーキテクチャの革新は、非常に深いニューラルネットワークの学習を可能にし、深層学習に革命をもたらした。本質的に残差接続とは、1 つ以上の層を迂回するショートカットであり、ある層の入力をその出力に加える。これにより消失勾配問題が緩和され、複数の Transformer ブロックを積み重ねた深いネットワークの学習が容易になる。 GPT-2 では、各 Transformer ブロック内で残差接続が 2 回使用される。MLP の前と後にそれぞれ配置され、これにより勾配がより容易に流れ、誤差逆伝播時に初期層が十分な更新を受けられるようになる。



## 微調整 (fine-tunig) 以外の課題調整法

<div class="figure figcenter">
<img src="/2023assets/2022Quyang_instructGPT_fig2ja.svg" width="99%">
<div class="figcaption">

instructGPT の概要 [2022Quyang+](https://arxiv.org/abs/2203.02155) Fig.2 を改変

</div></div>



# BERT

## BERT の入力表現

<div class="figure figcenter">
<img src="/assets/2018Devlin_BERT_Fig2.svg" width="49%">
<div class="figcaption">
埋め込みトークンの総和，位置符号器，分離埋め込みの 3 者
</div></div>

<!-- <div class="figure figcenter">
<img src="figures/2018Devlin_BERT_Fig2.svg">
</div> -->

## BERT の事前訓練: マスク化言語モデル

全入力系列のうち 15% をランダムに [MASK] トークンで置き換える

* 入力はオリジナル系列を [MASK] トークンで置き換えた系列
* ラベル: オリジナル系列の [MASK] 部分にの正しいラベルを予測

%Rather than always replacing the chosen words with [MASK], the date generator will do the following:

* 80%: オリジナル入力系列を [MASK] で置換
y $\rightarrow$ my dog is  [MASK].
* 10%: [MASK] の位置の単語をランダムな無関連語で置き換える
my dog is hairy $\rightarrow$ my dog is apple
* 10%: オリジナル系列

## BERT の事前訓練: 次文予測課題

言語モデルの欠点を補完する目的，次の文を予測

[SEP] トークンで区切られた 2 文入力
* 入力: the man went to the store [SEP] he bought a gallon of milk.
* ラベル: IsNext
* 入力: the man went to the store [SEP] penguins are flightless  birds.
* ラベル: NotNext

### BERT のファインチューニング

<div class="figcenter">
<img src="/2023assets/2019Liu_mt-dnn.png" width="66%">
<div class="figcaption">

[Liu+2019](https://arxiv.org/abs/1901.11504) Fig. 1
</div></div>

<!-- <div class="figcenter">
<img src="figures/2017Vaswani_Fig2_1ja.svg" width="22%">
<img src="figures/2017Vaswani_Fig2_2ja.svg" width="22%">
<div class="figcaption">
From Vaswani+2017 transformer Fig. 2
</div></div> -->

<!-- # BERT: ファインチューニング (1) -->

<div class="figcenter">
<img src="/assets/2018Devlin_BERT_Fig3.svg">
<div class="figcaption">

(a), (b) は文レベル課題，(c),(d)はトークンレベル課題, E: 入力埋め込み表現,
$T_i$: トークン $i$ の文脈表象。[CLS]: 分類出力記号, [SEP]:文分離記号
</div></div>

# GPT-4
加えて，chatGPT の後続モデルである GPT-4 では，マルチモーダル，すなわち，視覚と言語の統合が進んだ。

<div class="figcenter">
<img src="/2023assets/2023kosmos_coverpage.png" width="49%">
<div class="figcaption">

[Kosmos-1 の概念図](https://arXiv.org/abs/2302.14045)
</div></div>

<!-- まず第一に，大規模ではない，言語モデルについて考えます。
言語モデルは，機械翻訳などでも使われる技術です。
ですから，DeepL や Google 翻訳で，使っている方もいることでしょう。

chatGPT を使える方は，上記太字のキーワードについて，chatGPT に質問してみることをお勧めします。
とりわけ 注意 については，認知，視覚，心理学との関連も深く，注意の障害は，臨床，教育，発達などの分野と関係するでしょう。 -->


# BERT: ファインチューニング手続きによる性能比較

<center>
<img src="/assets/2019Devlin_mask_method21.jpg" width="66%"><br/>
マスク化言語モデルのマスク化割合の違いによる性能比較
</center>

マスク化言語モデルのマスク化割合は マスクトークン:ランダム置換:オリジナル=80:10:10 だけでなく，
他の割合で訓練した場合の 2 種類下流課題，
MNLI と NER で変化するかを下図 \ref{fig:2019devlin_mask_method21} に示した。
80:10:10 の性能が最も高いが大きな違いがあるわけではないようである。

<!-- # BERT モデルサイズ比較
<center>
<img src="./assets/2019Devlin_model_size20.jpg" style="width:69%"><br/>
</center>
 -->

# BERT: モデルサイズ比較

<center>
<img src="/assets/2019Devlin_model_size20.jpg" width="59%"><br/>
モデルのパラメータ数による性能比較
</center>

パラメータ数を増加させて大きなモデルにすれば精度向上が期待できる。
下図では，横軸にパラメータ数で MNLI は青と MRPC は赤 で描かれている。
パラメータ数増加に伴い精度向上が認められる。
図に描かれた範囲では精度が天井に達している訳ではない。パラメータ数が増加すれば精度は向上していると認められる。


# BERT: モデル単方向，双方向モデル比較

<center>
<img src="/assets/2019Devlin_directionality19.jpg" width="59%"><br/>
言語モデルの相違による性能比較
</center>

言語モデルをマスク化言語モデルか次単語予測の従来型の言語モデルによるかの相違による性能比較を
下図 \ref{fig:2019devlin_directionality19} に示した。
横軸には訓練ステップである。訓練が進むことでマスク化言語モデルとの差は 2 パーセントではあるが認められるようである。


# BERT: 埋め込みモデルによる構文解析

BERT の構文解析能力を下図示した。
各単語の共通空間に射影し，単語間の距離を計算することにより構文解析木と同等の表現を得ることができることが報告されている [@2019HewittManning_structural]。

<div class="figure figcenter">
<img src="/assets/2019hewitt-header.jpg" width="44%">
<img src="/assets/2019HewittManning_blogFig1.jpg" width="22%">
<img src="/assets/2019HewittManning_blogFig2.jpg" width="22%">
<div class="figcaption">
BERT による構文解析木を再現する射影空間
From `https://github.com/john-hewitt/structural-probes``
</div></div>

word2vec において単語間の距離は内積で定義されていた。
このことから，文章を構成する単語で張られる線形内積空間内の距離が構文解析木を与えると見なすことは不自然ではない。

そこで構文解析木を再現するような射影変換を見つけることができれば BERT を用いて構文解析が可能となる。
例えば上図における chef と store と was の距離を解析木を反映するような空間を見つけ出すことに相当する。
2 つの単語 $w_i$, $w_j$ とし単語間の距離を $d\left(w_i,w_j\right)$ とする。 適当な変換を施した後の座標を $h_i$, $h_j$ とすれば，求める変換 $B$ は次式のような変換を行なうことに相当する:

$$
\min_{B}\sum_l\frac{1}{\left|s_\ell\right|^2}\sum_{i,j}\left(d\left(w_i,w_j\right)-\left\|B\left(h_i-h_j\right)\right\|^2\right)
$$

ここで $\ell$ は文 s の訓練文のインデックスであり，各文の長さで規格化することを意味している。

# 注意の研究史 (1) 両耳分離聴 dichotomous listening 

<center>
<img src="/2025assets/Broadbent_Filter_Model.jpg" width="74%;"><br>
<img src="/2025assets/Treisman_Attenuation_Model.jpg" width="74%">
<!-- ![ブロードベント(1958)](./assets/Broadbent_Filter_Model.jpg){style="width:74%"}<br>
![トリーズマン(1964)](./assets/Treisman_Attenuation_Model.jpg){style="width:74%"} -->
</center>

# 注意の研究史 (2) 離断脳 split brain

<center>
<img src="/2025assets/sperry1968exp.svg" width="69%;">
<!-- ![スペリー (1968) split brain](./assets/sperry1968exp.svg){style="width:69%"} -->
</center>

# 注意の研究史 (3) 注意のエンゲージメント，ディスエンゲージメント

- ポズナー(1980) , ポズナーとコーエン(1984) <!--復帰抑制 (IOR: Inhibition of return)-->

<center>
<img src="/2025assets/1982Posner_Fig1.svg" style="width:30%">
<img src="/2025assets/1982Posner_Fig6.svg" style="width:34%">
</center>


# 注意の研究史 (4) 特徴統合理論 FIT

<center>
<img src="/2025assets/1988Treisman_FIT.svg" width="43%">
<!-- ![Triesman 1988 Fig.1](./assets/1988Treisman_FIT.svg){style="width:43%"} -->
</center>

# 注意の研究史 (5) 特徴統合理論 検索非対称性

<center>
<img src="/2025assets/1988Treisman_Fig3.svg" width="64%">
<!--![Triesman (1988) Fig. 5](./assets/1988Treisman_Fig5.svg){style="width:39%"}-->
</center>


# 注意の研究史 (6) スポットライトメタファー

- サーチライト(クリック, 1984)，
- スポットライト(ラバージ, 1985)，
- ズームレンズ(エリクセン, 1986)，

# 注意の研究史 (7) Guided Search 2.0 

- 最初のトップダウン注意モデル

<div class="figcenter">
<img src="/2025assets/1994Wolfe_GS2Fig2.jpg" style="width:64%"></br>
<div class="figcaption">

The architecture of the guided search 2.0. Modified from (1994)Wolfe Guided Search2, Fig. 2
</div></div>
<!--- **bottom-up** and **top-down** processes-->


# 注意の研究史 (8) 計算モデル

- コッホ Koch と ウルマン Ullman (1985) 勝者専有 Winner-take-all 回路

<div class="figcenter">

<img src="/2025assets/2015Itti_Fig2nocap.svg" width="77%">
<!-- ![Itti and Koch 計算論モデル(1999,2001)](./assets/2015Itti_Fig2nocap.svg){style="width:49%"} -->
<div class="figcaption">

初期のボトムアップ注意理論とモデル。<br/>
(a) Treisman&Gelade(1980) の特徴統合理論は、複数の特徴地図と、位置地図を走査し、現在注目している位置に特徴を収集・結合する注目の焦点を仮定(Treisman & Souther(1985) )
(b) Koch&Ullman(1985) は、すべての特徴地図からボトムアップ入力を受け取る顕著性地図の概念を導入した。この地図では、勝者占有回路 (WTA: winner-take-all) ネットワークが最も顕著な位置を選択し、その後の処理を行う。<br/>
(c) Milanese+(1994) は、最も初期の計算モデルの一つを提供した。彼らは Koch&Ullman の枠組みの多くの要素を取り入れ、警告下位システム（動きに基づく顕著性地図）やトップダウン下位システム（以前に認識された物体の記憶に基づいて顕著性地図を調整できる）などの新しい成分を追加した。 <br/>
(d) Itti+(1998) は、Koch&Ullman の理論に基づき、マルチスケール特徴地図、顕著性地図、勝者占有、そして復帰抑制を含む、純粋にボトムアップで課題非依存的モデルの完全な計算実装を提案した。<br/>
(e) Itti+ のモデルの重要な要素の一つは、注意関心演算子 (attention interest operator)（$N(\cdot)$ と表記）を明確に定義することである。これにより、各特徴地図が最終的な顕著性地図に寄与する重みは、特徴地図の混雑度に依存する。これは、ある位置が他のすべての位置よりも著しく目立つ特徴地図（図示した方位地図の場合のように）は、空間内の特定の位置を次の注目点として明確に支持するため、顕著性に大きく寄与するはずであるという考えを具体化している。対照的に、多くの場所で同等の反応が引き起こされる特徴地図（示されている強度地図など）は、次にどの場所を見るべきかを明確に示さないため、あまり寄与しないはずである。

<!-- Early bottom-up attention theories and models. <br/>
(a) Feature integration theory of Treisman&Gelade(1980) posits several feature maps, and a focus of attention that scans a map of locations and collects and binds features at the currently attended location. (from Treisman&Souther(1985)). 
(b) Koch & Ullman (1985) introduced the concept of a saliency map receiving bottom-up inputs from all feature maps, where a winner-take-all (WTA) network selects the most salient location for further processing. <br/>
(c) Milanese+(1994) provided one of the earliest computational models. They included many elements of the Koch&Ullman framework, and added new components, such as an alerting subsystem (motion-based saliency map) and a top-down subsystem (which could modulate the saliency map based on memories of previously recognized objects). <br/>
(d) Itti+(1998) proposed a complete computational implementation of a purely bottom-up and task-independent model based on Koch & Ullman's theory, including multiscale feature maps, saliency map, winner-take-all, and inhibition of return. <br/>
(e) One of the key elements of Itti et al.'s model is to clearly de ne an attention interest operator, here denoted N(.), whereby the weight by which each feature map contributes to the final saliency map depends on how busy the feature map is. This embodies the idea that feature maps where one location signi cantly stands out from all others (as is the case in the orientation map shown) should strongly contribute to salience because they clearly vote for a particular location in space as the next focus of attention. In contrast, feature maps where many locations elicit comparable responses (e.g., intensity map shown) should not strongly contribute because they provide no clear indication of which location should be looked at next. -->
</div>
</div>

# 注意の研究史 (9)

<div class="figcenter">
<img src="/2025assets/2012PetersenPosner_Fig2a.svg" width="44%">
<img src="/2025assets/2012PetersenPosner_Fig2b.svg" width="44%">
<img src="/2025assets/2012PetersenPosner_Fig2c.svg" width="55%">
</div>
<div class="figcaption">

(a) 背側および腹側の定位ネットワーク（Corbetta&Shulman(2002) より引用）。背側注意ネットワーク（薄緑）は、前頭眼野（FEF）と頭頂間溝/上頭頂葉（IPS/SPL, intraparietal sulcus/superior parietal lobe）から構成される。腹側注意ネットワーク（緑）は、側頭頭頂接合部（TPJ:Temporo-Parietal Junction）と腹側前頭皮質（VFC:Ventral Frontal Cortex）の領域から構成される。<br/>
(b) 実行制御系の 2 つのネットワーク。丸で囲まれた領域は、Posner&Petersen(1990) による実行制御系の元の構成要素を示す。残りの領域は、従来の帯状回-弁蓋部系（黒）の精緻化と前頭頭頂系（黄色）の追加によるもの。Dosenbach+(2007) を改変。<br/>
Frontoparietal control system: moment-to-moment task 前頭頭頂葉制御系：瞬間的課題<br/>
Cingulo-opercular system: task set maintenance 帯状回-蓋蓋部系：課題セットの維持<br/>
precuneus: 楔前部<br/>
(c) 別々の制御系を反映した安静時相関。図は脳の 3 方面からの見え方（左：背側方向から、中央：側方向から、右：正中方向から）を示す。これらの分離可能な安静時ネットワークは、図 a と b に示されている機能に基づく区別と一致している。背側注意（緑）、腹側注意（緑）、帯状回-弁蓋部（黒）、前頭頭頂部（黄） Power+(2011) を改変。

<!-- (a) The dorsal and ventral orienting networks (after Corbetta & Shulman 2002). The dorsal attention network (light green) consists of frontal eye fields (FEF) and the intraparietal sulcus/superior parietal lobe (IPS/SPL). The ventral attention network (teal ) consists of regions in the temporoparietal junction (TPJ) and the ventral frontal cortex (VFC).

(b) Two networks of the executive control system. The circled region indicates the original member of the executive control system from Posner & Petersen (1990). The remaining regions come from the elaboration of the original cingulo-opercular system (black) and the addition of the frontoparietal system (yellow) (adapted from Dosenbach+2007). 


(c) Resting-state correlation reflecting separate control systems. The figure illustrates three views of the brain (left, dorsal view; middle, tilted lateral view; right, medial view). These separable resting networks are consistent with the distinctions based on functional criteria exhibited in panels a and b: dorsal attention ( green), ventral attention (teal), cingulo-opercular (black), frontoparietal ( yellow) (adapted from Power et al. 2011).  -->

ピーターセンとポズナーのレビュー(2012版)<br>
</div>



<!--
    - ![Fig. 2a](./assets/2012PetersenPosner_Fig2a.svg){style="width:29%"}  
    - ![Fig. 2b](./assets/2012PetersenPosner_Fig2b.svg){style="width:49%"}</br>-->
<!-- - ![Fig. 2c](./assets/2012PetersenPosner_Fig2c.svg)-->

- 木村，米谷，平山 レビュー(2013) データセット，オープンソースデモの整備
- [Oxford handbook of attention (2014)](https://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780199675111.001.0001/oxfordhb-9780199675111)

<div class="figcenter">
<img src="/2025assets/2015Itti_Fig3.svg" width="77%;">
<div class="figcaption">

Figure 3: Survey of bottom-up and top-down computational models, classi ed according to 13 factors. Factors in order are: Bottom-up ($f_1$), Top-down ($f_2$), Spatial (-)/Spatio-temporal(+) ($f_3$), Static ($f_4$), Dynamic ($f_5$), Synthetic ($f_6$) and Natural ($f_7$) stimuli, Task-type ($f_8$), Space-based(+)/Object-based(-) ($f_9$), Features ($f_{10}$), Model type ($f_{11}$), Measures ($f_{12}$), and Used dataset ($f_{13}$). In Task type ($f_8$) column: free-viewing (f); target search (s); interactive (i). In Features (f10) column: CIO: color, intensity and orientation saliency; CIOFM: CIO plus flicker and motion saliency; $M^{\star}=$motion saliency, static saliency, camera motion, object (face) and aural saliency (Speech-music); $LM^{\star}=$ contrast sensitivity, perceptual decomposition, visual masking and center-surround interactions; $\text{Liu}^{\star}=$ center-surround histogram, multi-scale contrast and color spatial-distribution; $R^{\star}=$ luminance, contrast, luminance-bandpass, contrast-bandpass; $\text{SM}^{\star}=$ orientation and motion; $J^{\star}=$ CIO, horizontal line, face, people detector, gist, etc; $S^{\star}=$ color matching, depth and lines; :) = face. In Model type ($f_{11}$) column, R means that a model is based RL. In Measures ($f_{12}$) column: $K^{\star}=$ used Wilcoxon-Mann-Whitney test (The probability that a random chosen target patch receives higher saliency than a randomly chosen negative one); DR means that models have used a measure of detection/classi cation rate to determine how successful was a model. PR stands for Precision-Recall. In dataset (f13) column: Self data means that authors gathered their own data. For a detailed de nition of these factors please refer to Borji&Itti(2012PAMI).
</div>
<img src="/2025assets/2015Itti_Fig4.svg" width="77%;">
<div class="figcaption">

Figure 4: Example images (first row), human eye movement heatmaps (second row), and saliency maps from 26 computational models. The three vertical dashed lines separate the three datasets used (Bruce&Tsotsos, Kootstra&Schomacker, and Judd+). Black rectangles indicate the model originally associated with a given image dataset. Please see Borji+(2012 TIP) for additional details.
</div></div>


- [DeepGaze II](https://arxiv.org/abs/1610.01563)

<div class="figcenter">
<img src="/2025assets/2007Buschman_FigS1.svg" width="55%;">
</div>
<div class="figcaption">

注意制御の模式図。ボトムアップ型、つまり外向的な注意の方向付けにおいては、選択性は頭頂葉皮質から前頭葉皮質へと前方に流れ込んだ。一方、トップダウン型、つまり内向的な注意の方向付けにおいては、選択性は前頭葉皮質から流れ込んだ。これらの結果は、トップダウンとボトムアップの両方の影響を伴う注意のモデルを支持するものであり、行動のトップダウン方向付けは前頭葉皮質に由来することを示唆している。
(Buschman&Miller(2007) Fig. S1)
<!-- Schematic of Control of Attention. During bottom-up, external direction of attention, selectivity flowed forward from parietal cortex into frontal cortex. In contrast, when attention was directed in a top-down, internal, manner selectivity flowed from the frontal cortex. These results support models of attention with both top-down and bottomup influences, and suggests that top-down direction of behavior originates in the frontal cortex. -->
</div>

<div class="figcenter">
<img src="/2025assets/2015IttiBorji_fig9.jpeg" width="77%">
<div class="figcaption">

近年のより複雑なトップダウンモデルの例。<br/>
(a) Akamine+(2012) のモデル。動的ベイジアンネットワークを用いて、ボトムアップの顕著性の影響と、トップダウンの能動／受動状態の影響を空間と時間にわたって組み合わせている。このモデルではトップダウンの状態（能動 vs. 受動）は非常に単純であるが、提案された数学的枠組みは、より複雑なトップダウンの影響にも容易に拡張できる。<br/>
(b) Borji+(2012 AAAI) の DBN アプローチを 2 つのタイムスライスに展開したグラフィカル表現。$X_t$ は現在のサッカード位置、$Y_t$ は現在注目している物体、$F^{i}_{t}$ は現在のシーンにおける物体 $i$ を記述する関数。すべての変数は離散的である。また、注目されている物体の確率の時系列プロットと、タグ付けされた物体と視線の動きが重ねられたサンプルフレームも表示している。<br/>
(c) DBN モデルによる予測されたサッカード地図のサンプル（b に表示）。赤い円は観察者の眼の位置を示し、各地図のピーク位置（青い四角）が重ねられている。距離が短いほど予測精度が高いことを示している。左上から右下の画像は、プレイヤーが顧客に食べ物や飲み物を提供しなければならないホットドッグブッシュゲームのサンプルフレーム。MEP はゲームプレイ中のすべてのフレームの平均目の位置を表す。G は画像中央の単純なガウス地図である。BU は Itti モデルのボトムアップ顕著性地図。REG(1) は、前に注目した物体を現在注目している物体と移動位置に写像する回帰モデル。REG(2) は REG(1) に似ているが、入力ベクトルは、前に注目した物体が追加され、シーンで利用可能な物体で構成される。SVM(1) と SVM(1) は REG(1) と REG(2) に対応する、SVM 分類器を使用する。Mean BU は、ゲームコース全体でどの領域が顕著であるかを示す平均 BU 地図。同様に、DBN(1) と DBN(2) は REG(1) と REG(2) に対応し、DBN(1) ではネットワークスライスは 1 つのノードのみで構成される。 DBN(2) では、各ネットワークスライスは、以前注目していた物体と、シーン内の以前の物体の情報で構成され、最終的に Rand はホワイトノイズランダムつづになる。
<!-- Examples of recent more complex top-down models. <br/>
(a) Model of Akamine et al. (2012) which combines bottom-up saliency in uences and top-down active/passive state in uences over space and time using a dynamic Bayesian network. Although the top-down state is quite simple in this model (active vs. passive), the proposed mathematical framework could easily extend to more complex top-down influences.<br/>
(b) Graphical representation of the DBNs approach of Borji et al. (2012 AAAI) unrolled over two timeslices. $X_t$ is the current saccade position, $Y_t$ is the currently attended object, and $F^{i}_{t}$ is the function that describe object $i$ at the current scene. All variables are discrete. It also shows a time series plot of probability of objects being attended and a sample frame with tagged objects and eye  xation overlaid.<br/> 
(c) Sample predicted saccade maps of the DBN model (shown in b). Each red circle indicates the observers eye position superimposed with each maps peak location (blue squares). Smaller distance indicates better prediction. Images from top-left to bottom-right are: a sample frame from the hot-dog bush game where the player has to serve customers food and drink, MEP stands for the mean eye position over all frames during the game play, G is just a trivial Gaussian map at the image center, BU is the bottom-up saliency map of the Itti model, REG(1) is a regression model which maps the previous attended object to the current attended object and  xation location, REG(2) is similar to REG(1) but the input vector consists of the available objects at the scene augmented with the previously attended object, SVM(1) and SVM(1) correspond to REG(1) and REG(2) but using an SVM classifier, Mean BU is the average BU map showing which regions are salient throughout the game course, Similarly DBN(1) and DBN(2) correspond to REG(1) and REG(2) meaning that in DBN(1) network slice consists of just one node for previously attended object while in DBN(2) each network slice consists f the previously attended object as well information of the previous objects in the scene, and  nally Rand is a white noise random map. -->
</div>

<img src="/2025assets/2015IttiBorji_fig8.jpeg" width="88%;">
<div class="figcaption">

空間変調を伴うトップダウンモデル。<br/>
(a) Ehinger+(2009) のモデル。人物を見つけるという課題を与えられた場合、注意地図は 3 つのガイダンスソースから情報を得る。(1) 大まかなシーン構造に基づいて、与えられたシーン内で人物がどこに現れる可能性があるか（例えば、歩道に現れる可能性があるか）に関する空間事前情報を提供する空間地図。(2) 目的のターゲットの特徴に類似した視覚的特徴が画像内で観測される場所を示す地図。 (3) ボトムアップの顕著性地図。<br/>
(b) 複合ソースモデルは、3 つの成分モデルを単独で使用した場合よりも優れた性能を示し、有意に優れている。また、経験的文脈オラクル（人間が特定のシーンにおける人間の出現場所を手動で示すモデル）よりも優れた性能を示す。<br/>
(c) 運転などの複雑で自然な課題に従事している際の人間の視線行動からトップダウンの事前確率を学習するモデル（Peters&Itti(2007)）。課題依存の学習成分は、訓練フェーズ中に、異なる粗いシーンの種類と観察された眼球運動との間の関連付けを構築する（例：運転者は道路が左折すると左を見る傾向がある）。検査中は、類似のシーンへの露出によってトップダウンの顕著性地図が生成され、これが標準的なボトムアップの顕著性地図と組み合わされて、注意を誘導する最終的な（BU*TD）優先度地図が生成される。 <br/>
(d) (c) のモデルをドライビングビデオゲームに適用した結果の例。青い菱形は各地図のピーク位置を表し、オレンジ色の円は人間のドライバーの現在の目の位置を表す。ここでは、ボトムアップ（BU）顕著性地図では主人公が最も興味深いシーン要素であるとみなされているが、トップダウン（TD）地図によってより正確に予測されたように、ドライバーは道路の曲がり角と地平線を見ている。<br/>
Peters & Itti (2007) より。
<!-- Top-down models that involve spatial modulation. <br/>
(a) Model of Ehinger+(2009) where an attention map is informed by three guidance sources, given the task of  nding people: (1) a spatial map that, based on the coarse scene structure, provides a spatial prior on where humans might appear in the given scene (e.g., they might appear on sidewalks); (2) A map that indicates where visual features in the image that resemble the features of the desired targets are observed; (3) a bottom-up saliency map.<br/> 
(b) The combined-source model performs best and signi cantly better than any of the three component models taken alone, and also performs better than an empirical context oracle (where a set of humans manually indicated where humans might appear in the given scenes).<br/> 
(c) A model that learns top-down priors from human gaze behavior while engaged in complex naturalistic tasks, such as driving (Peters&Itti(2007)). A task-dependent learner component builds, during a training phase, associations between distinct coarse types of scenes and observed eye movements (e.g., drivers tend to look to the left when the road turns left). During testing, exposure to similar scenes gives rise to a top-down salience map, which is combined with a standard bottom-up salience map to give rise to the  nal (BU*TD) priority map that guides attention. <br/>
(d) Example results from the model of (c) applied to a driving video game. Blue diamonds represent the peak location in each map and orange circles represent the current eye position of the human driver. Here the bottom-up (BU) salience map considers that the main character is the most interesting scene element, but, as more correctly predicted by the top-down (TD) map, the driver is looking into the road's turn and on the horizon line. <br/>
From Peters & Itti (2007). -->
</div>

<img src="/2025assets/2015IttiBorji_fig7.jpeg" width="66%;">
<div class="figcaption">

特徴ゲインを調整するトップダウンモデル。<br/>
(a) Wolfe(1994) の誘導探索理論は、ボトムアップ特徴地図はトップダウン司令によって重み付けおよび調整可能であると予測した。<br/>
(b) ターゲット物体 ($P(\theta|T)$) とディストラクタ ($P(\theta|D)$) の両方の特徴値 $\theta$ の期待分布に関するトップダウンの知識に基づいて、各特徴地図の重みを最適に計算する計算フレームワーク。各特徴のゲインは、これらの分布が与えられた場合の、ターゲット対ディストラクタの期待信号対雑音比に反比例して設定される (Navalpakkam&Itti(2006;2007))。<br/>
(c) 画像の例 (上段)、重み付けされていない単純な顕著性地図 (中段)、およびサンプル訓練画像から収集された特徴分布に基づく最適バイアス付き顕著性地図 (下段)。これらの例では、純粋なボトムアップモデルによれば、関心対象物体は最も顕著ではなかったが、ターゲットとディストラクタの特徴分布から計算されたトップダウン ゲインを使用してモデルにバイアスをかけると、最も顕著になる (Navalpakkam&Itti2006)。
<!-- Top-down models that modulate feature gains. <br/>
(a) The Guided Search theory of Wolfe (1994) predicted that bottom-up feature maps can be weighted and modulated by top-down commands. <br/>
(b) Computational framework to optimally compute the weight of each feature map, given top-down knowledge of the expected distribution of feature values $\theta$ for both target objects ($P(\theta|T)$) and distractors ($P(\theta|D)$). The gain of each feature is set inversely proportionally to the expected target-to-distractor signal-to-noise ratio given these distributions (Navalpakkam&Itti(2006;2007)). <br/>
(c) Examples of images (top row), naive un-weighted saliency maps (middle row), and optimally-biased saliency maps based on feature distributions gathered from sample training images (bottom row). Although the object of interest was not the most salient according to a purely bottom-up model in these examples, it becomes the most salient once the model is biased using top-down gains computed from the target and distractor feature distributions (Navalpakkam&Itti2006). -->
</div>

<img src="/2025assets/2015IttiBorji_fig6a.jpeg" width="33%;">
<img src="/2025assets/2015IttiBorji_fig6b.jpeg" width="33%;"><br/>
<img src="/2025assets/2015IttiBorji_fig6b2.jpeg" width="33%;">
<img src="/2025assets/2015IttiBorji_fig6c.jpeg" width="66%;">
<div class="figcaption">

空間バイアス、特徴バイアス、そしてより複雑な意味論的トップダウンモデルを探求するための実験的動機。<br/>
(a) 人間のドライバーが時速50マイルで開けた道路を3回走行した際の、異なる道路位置への注視の割合（各パネルに1回ずつ。点は1未満の非ゼロの割合を示す）。3回の繰り返し（上から下のパネル）を通して、注視が地平線の左側に密集し始めたことがわかる（Mourant & Rockwell, 1970より）。これは、トップダウンモデルが、タスクが注意の配置において空間バイアスをどのように誘発するかを時間の経過とともに学習する動機となる。<br/>
(b) サルが様々な妨害刺激の中から手がかりとなる標的を探した際の前頭眼野（FEF）における神経活動記録から、標的を見つけるためにサルが行ったサッカード運動の回数は、最初のサッカード運動開始時（50ms）付近の標的位置における神経活動と負の相関関係にあることが明らかになった（散布図は、1つの記録部位から得られた1試行あたり1つの点と、負の傾きを示す線形回帰の例を示している。ヒストグラムは、全記録部位における傾きの分布を示しており、有意な傾きは黒、その他はすべて灰色で示されている）。これは、トップダウンモデルが探索標的の特定の特徴に対するバイアスを利用して、注意をより早く標的へと誘導しようと試みる可能性を示唆している（Zhou & Desimone, 2011より）。<br/>
(c) クリケットの打者の眼球運動記録から、彼らの眼球運動は「ボールが放たれた瞬間を監視し、地面に落ちると予想される場所へ予測的なサッカード運動を行い、ボールがバウンドするのを待ち、バウンド後100～200msの間その軌道を追う」ことが明らかになった(Land & McLeod, 2000)。これは、このより複雑なシナリオにおける人間の視線行動を完全に理解するには、物理​​学、重力、バウンドなどに関するある程度の知識が必要である可能性を示唆している。<br/>
(d) サンドイッチを作る際の眼球運動記録は、課題に必要な一連のステップが展開される間、明らかに次に必要なアイテムに向けられており、探索や探索はほとんど行われていない(Land & Hayhoe, 2001)。したがって、このようなより複雑なシナリオに対処するには、シーン内のオブジェクトの認識と記憶もトップダウンモデルに必要となる可能性が高い。
<!-- Experimental motivation to explore spatial biases, feature biases, and more complex semantic top-down models. 
(a) Percentage of fixations onto different road locations while human drivers drove at 50 miles/hour on an open road three times (once each panel; dots indicate non-zero percentages smaller than 1). We can see that over the three repetitions (top to bottom panels), eye fixations started clustering more tightly around the left side of the horizon line (from Mourant & Rockwell, 1970). This motivates top-down models to learn over time how a task may induce some spatial biases in the deployment of attention. 
(b) Neural recordings in the frontal eye fields (FEF) as monkeys searched from a cued target among various distractors reveals that the number of saccades the animal made to find the target is negatively correlated with neural firing at the target location around ( 50ms) the onset of the first saccade (scatter plot shows examples, one dot per trial, from one recording site, and the negatively-sloped linear regression; histogram shows distributions of slopes over all recording sites, with the significant ones in black and all others in gray). This suggests that top-down models can also exploit biasing for specific features of a search target to attempt to guide attention faster towards the target (from Zhou & Desimone, 2011). 
(c) Eye movement recordings of cricket batsmen revealed that their \eye movements monitor the moment when the ball is released, make a predictive saccade to the place where they expect it to hit the ground, wait for it to bounce, and follow its trajectory for 100-200 ms after the bounce" (Land & McLeod, 2000). This suggests that some knowledge
of physics, gravity, bouncing, etc. may be necessary to fully understand human gaze behavior in this more complex scenario. 
(d) Eye movement recordings while making a sandwich are clearly aimed towards the next required item during the unfolding of the successive steps required by the task, with very little searching or exploration (Land & Hayhoe, 2001). Thus, recognition and memorization of objects in the scene is also likely to be required of top-down models to tackle such more complex scenario. -->
</div>
</div>