---
title: 第04回 2025 年度開講 駒澤大学 心理学特講 IIIA
author: 浅川 伸一
layout: home
---
<link href="/css/asamarkdown.css" rel="stylesheet">
<div align="center">
<font size="+1" color="navy"><strong>ディープラーニングの心理学的解釈</strong></font><br/><br/>
</div>

<div align='right'>
<a href='mailto:educ0233@komazawa-u.ac.jp'>Shin Aasakawa</a>, all rights reserved.<br>
Date: 09/May/2025<br/>
Appache 2.0 license<br/>
</div>

<!-- 
https://archmdmag.com/what-is-pareidolia-and-simulacra/

パレイドリア（Pareidolia）という言葉は、ギリシャ語の「Para」（傍ら、共に、並んで）と「eidos」（イメージ、形、形状）に由来する。パレイドリアとは、漠然としたランダムな刺激（典型的には音や心像）が重要なものとして知覚される心理現象を表す言葉である。パレイドリアはアポフェニアの一種で、1958年にクラウス・コンラッド（Klaus Conrad）によって作られた造語である。コンラッドはアポフェニアを「異常な意味性の具体的な経験を伴う、つながりの動機づけられない視覚」と定義した。
The Word Pareidolia comes from the Greek ‘Para’ – beside, with or alongside, and ‘eidos’ meaning image, form or shape. Pareidolia is the term used to describe the psychological phenomena involving a vague and random stimulus, typically a sound or image, being perceived as significant. Pareidolia is a type of Apophenia – a term coined in 1958 by Klaus Conrad, who defined Apophenia as ‘Unmotivated seeing of connections accompanied by a specific experience of an abnormal meaningfulness’.

シミュラクラ（ラテン語で「類似、類似性」を意味する Simulacrum から）は、「彫像や絵画のような別のものの表現、特に神の表現」を表すのに使われる用語であり、したがって、意図的に他の何かに似せて作られた物体や類似物を指す。パレイドリアには、EVP（電子音声現象）も含まれる。1971 年、クラウス・ラウディーヴは EVP の発見を詳述した『Breakthrough』を著したが、これはポピュラー音楽における「バックマスキング」と同様、聴覚的パレイドリアと表現されている。
Simulacra, (from the Latin Simulacrum which means ‘Likeness, similarity”) is the term used to describe ‘A representation of another thing, such as a statue or painting, esp. of a god’ and therefore refers to an object or likeness that has been deliberately created to resemble something else. Pareidolia include EVP or electronic voice phenomena. In 1971, Klaus Raudive wrote ‘Breakthrough’, detailing the discovery of EVP, which is described as auditory Pareidolia, as indeed is ‘backmasking’ in popular music.

Typical examples of visual Pareidolia include ‘seeing’ the shapes of animals in clouds and faces in orbs and other random objects. Carl Sagan hypothesised that humans have the ability to identify the human face from birth, and there is evidence to suggest an innate tendency to pay attention to faces from infancy and by two months of age the child’s face perception skills have developed to such a degree that specific areas of the brain, namely the fusiform gyri and lesser temporal gyri are activated by viewing faces. The face is an important site for the identification of others and conveys significant social information, such as moods etc. which suggests our ability to recognise faces from such a young age is part of our fight or flight system. This ‘Hard-Wired’ ability allows us to use basic details to recognise faces from a distance and in poor visibility, but can also lead us to misinterpret random images or patterns of light and shade as faces. A common theme of Pareidolia is the perception of iconic religious imagery in ordinary objects, most commonly the image of Jesus, The Virgin Mary and the word ‘Allah’, although the simplicity of letter forms in the Arabic alphabet, and the flexibility in Islamic calligraphy (and the particular shape of the word Allah’) make it easy to read into many formations of parallel lines and lobes on a common base.

Examples of Religious Imagery in common objects are:

<img src="https://archmdmag.com/wp-content/uploads/2020/06/ee9c416d61ac29727fc96f279a94b38a.jpg" width="50%">

In September, 2007, the so-called “monkey tree phenomenon” caused a minor social mania in Singapore. A callus on a tree there resembles a monkey, and believers have flocked to the tree to pay homage to the Monkey God.

<img src="https://archmdmag.com/wp-content/uploads/2020/06/f2aa03c74da91797ded5439d9bcfa1fd.jpg" width="50%">

1996年末、フロリダにある金融ビルのガラスファサードがメディアの注目を集めた。その絵は流れるような線で構成され、顔のない女性の頭と肩のベールを示唆していた。
In late 1996, the glass facade of a finance building in Florida attracted widespread media attention. The image was composed of flowing lines that suggested the veiled head and shoulders of a faceless woman.

その絵は聖母マリアを描いたものだと信者たちに信じられていた。虹色に輝いていた。その後数年間で、この絵には推定100万人の観光客が訪れた。この建物は、オハイオ州を拠点とするカトリック復興主義グループ、シェパード・オブ・クライスト・ミニストリーズによって購入された。建物は聖母マリア・ビルディングと呼ばれた。2004 年 3 月 1 日、窓の最上部 3 枚が破壊者によって割られた。窓はイエス・キリストの絵に取り替えられた。地元の化学者であるチャールズ・ロバーツは、元の窓ガラスを調査し、虹色の染みは風化と結びついた水の沈着によって生じたもので、古い瓶によく見られるような化学反応であると説明した。
The image was believed by the faithful to depict the Virgin Mary. It was iridescent and had “rainbow colors”. The image drew an estimated one million visitors over the next several years. The building was purchased by Shepherds of Christ Ministries, an Ohio-based Catholic revivalism group. The building was dubbed the  Virgin Mary Building. On March 1, 2004, the three uppermost panes of the window were broken by a vandal. The windows were replaced with a picture of Jesus Christ. A local chemist, Charles Roberts, had examined the original windows and explained that the iridescent stain had been produced by water deposits combined with weathering, yielding a chemical reaction like that often seen on old bottles.

ロバーツは、スプリンクラーが原因である可能性が高いと言った。この建物にはまた、キリスト降誕の聖書の場面が窓の側面にたくさん描かれていた。しかし、これらの画像は人工的に作られたものだった。マザー・テレサの顔は、テネシー州ナッシュビルにあるボンゴ・ジャバのシナモンパンに描かれていた。1996 年 10 月 15 日、従業員のライアン・フィニーによって発見され、同社はTシャツやマグカップを販売し、事業化した。マザー・テレサは同社に連絡し、これらの販売を中止するよう求めた。カフェのオーナーとマザー・テレサの弁護士との話し合いで、妥協が成立した。カフェは、NunBun グッズを限られた量しか販売せず、店舗でのみ販売し、絵のライセンスを取得しないことに同意した。饅頭はボンゴジャワのアトラクションとして残った。2005 年 12 月 25 日、饅頭は喫茶店に侵入した際に盗まれた。
Roberts said that it was likely that the water sprinkler was the cause of it. The Building also had a large number of different bible scenes from the nativity on the windows wrapping around the side of it. These images, however, were artificially created. The face of Mother Teresa was seen in a cinnamon bun at Bongo Java in Nashville, Tennessee It was first discovered on 15 October 1996 by employee Ryan Finney and was turned into an enterprise by the company, selling T-shirts and mugs. Mother Teresa contacted the company and asked them to stop these sales. Discussions between the cafe owner and Mother Teresa’s attorney brought about a compromise. The cafe agreed to only sell a limited amount NunBun merchandise and sell it only at their store and not license the images. The bun remained as an attraction at Bongo Java. On 25 December 2005 the bun was stolen during a break-in at the coffee house.

<img src="https://archmdmag.com/wp-content/uploads/2020/06/f2072ab4b300f5f791cbe1de83095924.jpg" width="50%">

ボンゴ・ジャヴァのオーナーは、ヌンバンの返還に対して5,000ドルの報奨金を出していた。テネシー州ナッシュビルの新聞『テネシアン』紙に、「フー・デュネット 」と名乗る人物からこの菓子の写真が送られてきた。その写真には、女性の像の近くにあるNunBunが写っている写真、2人の男性に持たれている写真、加工された写真で顔が見えない写真、ビーチに横たわり左手にNunBunを持っている男性の写真などが写っていた。
The owner of Bongo Java had offered a $5,000 reward for the return of the NunBun. Photographs of the pastry had been sent to the Nashville, TN newspaper The Tennessean from a person identifying themselves as “Hu Dunet.” It shows the NunBun near a statue of a woman, a picture showing it being held by two men, their faces obscured by alterations to the photograph, and a picture of a man lying on a beach holding the bun in his left hand

<img src="https://archmdmag.com/wp-content/uploads/2020/06/grilledcheese_0825.jpg" width="50%">

2004年11月23日、フロリダ州ハリウッドに住むダイアナ・デュイザーによって、聖母マリアの似顔絵が入ったグリルドチーズサンドイッチがイーベイ・オークションに出品され、28,000ドルで落札された。デュイザーは、「10年前にこのサンドイッチを作った。一口かじったとき、私を見上げている顔が見えた--それは聖母マリアが私を見つめていた。すごくショックだった。彼女は綿毛に包まれたトーストをプラスチックの容器に入れ、台の上に置いていた。デュイザーは、10年前のものであるにもかかわらず、このトーストにはカビも生えていないし、崩れた形跡もないと主張した。彼女はまた、その神秘的な性質が、近くのカジノで7万ドルの勝利を含む幸運をもたらしたと信じている。このサンドイッチを購入したのは、売名行為で知られるオンラインカジノのGoldenPalace.comである。同社によると、このサンドイッチを持って世界ツアーを行い、その後販売し、収益はチャリティーに寄付する予定だという。サンドイッチを作るのに使われたフライパンもeBayで売られた。
On November 23, 2004, a grilled cheese sandwich that contained the likeness of the Virgin Mary was sold for $28,000 in an eBay auction by Diana Duyser from Hollywood, Florida. Duyser explained, “I made this sandwich 10 years ago. When I took a bite out of it, I saw a face looking up at me – it was Virgin Mary staring back at me. I was in total shock.” She kept the toast surrounded by cotton wool, in a plastic container on a stand. Duyser claimed that although a decade old, the toast has not shown any sign of mold or crumbling, which she considered as “a miracle”. She also believed its mystical properties have brought her blessings, including a $70,000 win in a nearby casino. The sandwich was purchased by the online casino, GoldenPalace.com, which is known for its publicity stunts. The company said that they planned to undertake a world tour with the sandwich and then sell it, with proceeds going to charity. The pan that was used to make the sandwich was also sold on eBay. -->

<img src="https://archmdmag.com/wp-content/uploads/2020/06/2000px-Inkblot.svg_-1536x1040.png" width="50%">

<!-- 心理学者の中には、心理検査でパレイドリアを利用する者もいる。時折、心理学者はロールシャッハ・インクブロット・テストを使って、その人の隠された感情を解釈することがある。このテストでは、紙にインクを垂らし、その紙を半分に折ってイメージを作る。心理学者は、その結果できた画像を解釈するよう患者に求める。理論的には、患者は自分の心の奥底にある考えを、そうでなければランダムなイメージに投影する。しかし、この治療法には何の根拠もないため、心理学者の間では広く異論がある。
Some psychologists rely on pareidolia in psychological examinations. Occasionally, psychologists will use the Rorschach inkblot test to interpret a person’s supposed hidden emotions. The test includes an image that is created by dropping ink on paper, and folding the paper in half. The psychologist then asks their patient to interpret the resulting image. In theory, the patient projects their innermost thoughts onto the otherwise random image. However, this method of therapy is widely disputed by psychologists, as it has no grounding in facts.

そして、考古学や自然界におけるパレイドリアもある。雲から岩層、石、航空写真、さらには宇宙考古学に至るまで、イメージはあらゆるところに、そして毎日現れる。そして、私たちのハードワイヤリングによって、私たちはこれらの幻想的なものを、私たちが認識している何かに似せて解釈してしまうのだ。 以下は、これらの地域からのイメージのギャラリーである。
And then we come to Pareidolia in Archaeology and the natural world. From clouds to rock formations, stones, aerial images and even Astroarchaeology, Images appear everywhere and every day. And due to our hard-wiring, we interprete these fantastic things to resemble something we recognise.  Below is a gallery of images from those areas mentioned.

By Kirst D’Raven -->

<img src="https://archmdmag.com/what-is-pareidolia-and-simulacra/2d979afc00000578-0-image-a-1_1445347315479/" width="50%">


# 実習ファイル

* [最小限のニューラルネットワーク <img src="/assets/colab_icon.svg" alt="最小限のニューラルネットワーク">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2023notebooks/2023_0929miniam_XOR.ipynb){:target="_blank"}
* [画像認識モデル実習 <img src="/assets/colab_icon.svg" alt="画像認識モデル実習">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021komazawa_cogsy000_CNN_demo.ipynb#scrollTo=3LVOKnq2NuPj){:target="_blank"}
* [顔検出 <img src="/assets/colab_icon.svg" alt="顔検出">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2025notebooks/2025_0428opencv_face_detect_recognizer.ipynb){:target="_blank"}
* [課題提出用フォルダ](https://drive.google.com/drive/u/3/folders/1aenqcvlAQ7T-hv9-zsbrfntqpTbUj2EP){:target="_blank"}

* [畳み込みニューラルネットワークの事前訓練済モデルによる中間表現の可視化 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2022notebooks/2022_1024CNN_layer_visualization.ipynb){:target="_blank"}
- [LeNet PyTorch <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2021_0528LeNet_pytorch.ipynb){:target="_blank"}
* [特徴点検出アルゴリズム 画像フィルタ <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/notebooks/2020Sight_visit_feature_extractions_demo.ipynb){:target="_blank"}
* [DOG などのフィルタと Harr 特徴による顔検出 a.k.a ビオラ＝ジョーンズ アルゴリズム <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2021_0528edge_and_face_detection_algorithm_not_cnn.ipynb){:target="_blank"}


## デモ

- [グーグルによるニューラルネットワークの遊び場 (プレイグランド)](https://project-ccap.github.io/tensorflow-playground/){:target="_blank"}

---

先週の最小ネットワークの解
<center>
<img src="/2023assets/xor.svg">
<img src="/2023assets/xor-graph.svg">
</center>


## 福島のネオコグニトロン (Fukushima, 1980)

* S 細胞と C 細胞との繰り返し。最初の多層（深層）化された物体認識モデルととらえることが可能
    - S 細胞：生理学の単純細胞 simple cells に対応。受容野 receptive fields の概念を実現。特徴抽出，特徴検出。<br/>
    - C 細胞：複雑細胞 complex cells に対応。広い受容野。位置，回転，拡大縮小の差異を吸収<br>

<div class="figure figcenter">
<img src="/assets/Neocognitron.jpeg" width="55%">
<img src="/assets/Fukushima.jpeg" style="width:24%"><br>
<div class="figcaption">

ネオコグニトロンの模式図
</div></div>

## LeNet5 (LeCun1998)

* **LeNet**. Yann LeCun (現 Facebook AI 研究所所長)による CNN 実装
 [LeNet](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf){:target="_blank"} 手書き数字認識

<center>
<img src="/assets/1998LeNet5.png" width="84%"><br/>
<div style="text-align:left; width:77%;background-color:cornsilk">

LeNet5 の論文より改変
</div>
</center>

- 畳込層とプーリング層（発表当初はサブサンプリング）との繰り返し
  - 畳込とプーリングは<font color="green">局所結合</font>
- MNIST を用いた１０種類の手書き文字認識
- 最終２層は全結合層をつなげて最終層１０ニューロン，最終層の各ニューロンの出力がそれぞれの数字（０から９までの１０種）に対応する


# ニューラルネットワーク

* イメージネットコンテストの結果

<!-- ## 本日のキーワード -->


<center>
<img src='/assets/imagenet_result2017.png' style='width:74%'><br/>
画像認識の進歩
</center>

## ニューラルネットワークの歴史

### 第 1 次ニューロブーム

#### 1950年代:
- ウォーレン・マッカロックとワイルダー・ピッツによる **形式ニューロン** の提案
(サイバネティクスの創始者ノーバート・ウィーナーの集めた研究者集団)

<center>
<img src='/assets//mcculloch.jpg' style="width:38%">
<img src='/assets//pitts.jpg' style='width:50%'><br>
<!-- <img src='https://komazawa-deep-learning.github.io/assets//mcculloch.jpg' style="width:38%">
<img src='https://komazawa-deep-learning.github.io/assets//pitts.jpg' style='width:50%'><br> -->
ウォーレン・マッカロック と ワイルダー・ピッツ<br>
<!--img src='../assets/mcculloch.jpg' style="width:19%">
<img src='../assets/pitts.jpg' style='width:25%'><br>-->
</center>

形式ニューロンは，シナプス結合荷重ベクトルと出力を決定するための伝達関数とで構成される(次式)

$$
y_{i}=\phi\left(\sum_jw_{ij}x_j\right),\tag{eq:formal_neuron}
$$

ここで $y_{i}$ は $i$ 番目のニューロンの出力，$x_{j}$ は $j$ 番目のニューロンの出力，$w_{ij}$ はニュ
ーロン $i$ と $j$ との間の **シナプス結合荷重**。
$\phi$ は活性化関数。

<center>
<img src='/assets/Formal_r.svg' style="width:84%"><br/>
<!-- <img src='https://komazawa-deep-learning.github.io/assets//Formal_r.svg' style="width:84%"><br>
 -->
形式ニューロン
</center>



## AlexNet

<img src="/2023assets/alex_net_block_diagram.png"><br/>


## 畳み込み演算

<center>
<img src="/assets/dmoulin_gif/full_padding_no_strides.gif" style="width:33%">
<img src="/assets/dmoulin_gif/same_padding_no_strides_transposed.gif" style="width:33%"><br/>
<div style="text-align=:left; width:66%; background-color:cornsilk">

左:入力層 5x5青，出力層緑，カーネルサイズ3x3, フルパディング，ストライド=1.<br/>
右:入力層 5x5青，出力層緑，カーネルサイズ3x3, フルパディング，ストライド=1. トランスポーズド畳み込み
</div>
<img src="/assets/dmoulin_gif/numerical_max_pooling.gif" style="width:33%">
<img src="/assets/dmoulin_gif/numerical_average_pooling.gif" style="width:33%"><br/>
<div style="text-align=:left; width:66%; background-color:cornsilk">

左: 最大値プーリング。
右: 平均値プーリング
</div>
<div style="text-align=:left; width:44%; background-color:cornsilk">
Dmoulin and Visin (2020) より
</div>

<img src="/assets/dmoulin_gif/padding_strides.gif" style="width:33%">
<img src="/assets/dmoulin_gif/padding_strides_odd.gif" style="width:33%">
<img src="/assets/dmoulin_gif/padding_strides_odd_transposed.gif" style="width:33%"><br/>
<div style="text-align=:left; width:44%; background-color:cornsilk">

左: padding_strides, 中:padding_strides_odd, 右:padding_stride_transposed
</div>
<img src="/assets/dmoulin_gif/same_padding_no_strides.gif" style="width:33%">
<img src="/assets/dmoulin_gif/same_padding_no_strides_transposed.gif" style="width:33%">
<div style="text-align=:left; width:44%; background-color:cornsilk">

右:same_padding_no_strides, 左: same_padding_no_strides_transposed
</div>
<img src="/assets/dmoulin_gif/arbitrary_padding_no_strides.gif" style="width:33%">
<img src="/assets/dmoulin_gif/arbitrary_padding_no_strides_transposed.gif" style="width:33%">
<div style="text-align=:left; width:44%; background-color:cornsilk">
右:arbitrary padding no strides, 左: artibtrary padding no stride transposed
</div>
</center>

<div class="figcenter">

<iframe src="/conv-demo/index.html" width="140%" height="640px;" style="border:none;"></iframe>
</div>


## HMAX 最大値プーリング Riesenhuber&Poggio(1999)

<div class="figcenter">
<img src="/assets/1999Riesenhuber_Poggio_fig2.svg" style="width:49%">
<div class="figcaption" style="width:66%;">

<font style="font-weight:bold">モデルのスケッチ</font><br/>
単純細胞から作られた複雑細胞の古典的なモデルを拡張したもので，線形演算 (福島の表記法では `S` ユニット，テンプレート・マッチング 図中の実線) と非線形演算 (`C`プーリングユニット，最大値 MAX 演算を行う 図中破線) を持つ層の階層で構成。
細胞入力の最大値を選択，その値を用いてセルを駆動する非線形の MAX 演算は複雑細胞に対して，線形入力の合計とは異なりモデルの特性の鍵となる概念である。
この 2 種類の操作は 異なる位置にチューニングされた求心性結合をプールすることでパターン特異性と並進不変性を，また異なるスケールにチューニングされた求心性結合をプールすることで、スケール不変性をもたらした (図示せず)。<br/>
Riesenhuber&Poggio(1999) Fig. 2 より
</div></div>


<div class="figcenter">
<img src="/assets/1999Riesenhuber_Poggio_fig3a.svg" style="width:44%">
<img src="/assets/1999Riesenhuber_Poggio_fig3b.svg" style="width:44%"><br/>
<div class="figcaption" style="width:99%">

MAX 機構 高度に非線形な形状調整の特性。<br/>
「最適」特徴を決定するために考案された「単純化手順」を用いて得られた下側頭葉細胞の応答（選好刺激に対する反応が等しくなるように正規化された反応)。
実験では，もともと細胞は「水のボトル」の画像 (一番左の物体) に非常に強い反応を示した。
その後，刺激を単色の輪郭に単純化したところ，細胞の発火が増加し，さらに，楕円を支える棒からなるパドルのような物体に変化した。
この物体が強い反応を引き起こすのに対し，棒や楕円だけではほとんど反応しなかった。
Riesenhuber&Poggio(1999) Fig 3A.
</div></div>

実験とモデルの比較。
白棒はの実験用ニューロンの反応を示す。
黒と灰色の棒は 選好刺激の 幹-楕円 の基部の遷移に合わせてチューニングしたモデル細胞の反応を示している。
モデル細胞は 直上図に示したモデルを簡略化したもの。
受容野の各位置に 2 種類の S1 特徴があり，それぞれが遷移領域の左側または右側にチューンしていて，その出力が C1 ユニットに入力され MAX 関数 (黒棒) または SUM 関数 (灰色棒) を用いてプールされている。
モデル細胞は 実験ニューロンの 選好刺激が受容野内にあるときに反応が最大になるよう，C1 ユニットに接続されていた。

図 3. MAX 機構の高度に非線形な形状チューニング特性。
(a) `最適` 特徴を決定するために考案された `単純化手続`(26) を用いて得られた，実験的に観察された IT 細胞の応答 (好ましい刺激に対する応答が 1 に等しくなるように正規化された応答)。
実験では，細胞はもともと「水瓶」 (一番左の物体) の画像にかなり強く反応した。
その後，刺激は単色の輪郭に「単純化」され，細胞の発火が増加し，さらに楕円を支える棒からなるパドルのような物体に変化した。
この物体は強い反応を引き起こしたが，棒や楕円だけではほとんど全く反応を起こさなかった (図は許可を得て使用)。
(b) 実験とモデルの比較。
白棒は (a) の実験ニューロンの反応。
黒棒と灰色棒は，優先刺激の幹-楕円底遷移に同調させたモデルニューロンの反応を示す。
このモデルニューロンは，図 2 に示したモデルの単純化された版の最上部にあり，受容野の各位置に 2 種類の S1 特徴のみが存在し，それぞれが遷移領域の左側または右側に同調し，MAX 関数 (黒棒グラフ) または SUM 関数 (灰色棒グラフ) のいずれかを用いてそれらをプールする C1 ユニットに供給される。
モデルニューロンは，実験ニューロンの好ましい刺激がその受容野にあるときに，その反応が最大になるように，これらの C1 ユニットに接続された。
<!-- Fig. 3. Highly nonlinear shape-tuning properties of the MAX mechanism.
(a) Experimentally observed responses of IT cells obtained using a `simplification procedure`(26) designed to determine `optimal` features (responses normalized so that the response to the preferred stimulus is equal to 1).
In that experiment, the cell originally responded quite strongly to the image of a `water bottle` (leftmost object).
The stimulus was then `simplified` to its monochromatic outline, which increased the cell’s firing, and further, to a paddle-like object consisting of a bar supporting an ellipse.
Whereas this object evoked a strong response, the bar or the ellipse alone produced almost no response at all (figure used by permission).
(b) Comparison of experiment and model.
White bars show the responses of the experimental neuron from (a).
Black and gray bars show the response of a model neuron tuned to the stem-ellipsoidal base transition of the preferred stimulus.
The model neuron is at the top of a simplified version of the model shown in Fig. 2, where there were only two types of S1 features at each position in the receptive field, each tuned to the left or right side of the transition region, which fed into C1 units that pooled them using either a MAX function (black bars) or a SUM function (gray bars).
The model neuron was connected to these C1 units so that its response was maximal when the experimental neuron’s preferred stimulus was in its receptive field. -->


<!-- MAX 機構に対する追加的な間接的支持は，IT 細胞の好ましい特徴，つまり細胞を駆動するための刺激成分を決定するために，「単純化手順」(26 )または「複雑性減少」(27) を用いた研究から得られている。 -->
MAX 機構に対する追加的な間接的支持は，IT 細胞の好ましい特徴，つまり細胞を駆動するための刺激成分を決定するために，「単純化手順」または「複雑性減少」を用いた研究から得られている。
これらの研究では一般的に，IT 細胞の高度に非線形な同調を発見している (図 3a)。
このような同調は MAX 応答関数 (図 3b 黒棒) と一致する。
線形モデル (図 3b 灰色棒) では，入力画像のわずかな変化に対す るこの強い応答の変化を再現できないことに注意。
<!--Additional indirect support for a MAX mechanism comes from studies using a `simplification procedure`(26) or `complexity reduction`(27) to determine the preferred features of IT cells, that is, the stimulus components that are responsible for driving the cell.
These studies commonly find a highly nonlinear tuning of IT cells (Fig. 3a).
Such tuning is compatible with the MAX response function (Fig. 3b, black bars).
Note that a linear model (Fig. 3b, gray bars) could not reproduce this strong change in response for small changes in the input image.-->


## 従来モデルと深層学習との対比

<div class="figcenter">
<img src='/assets/2013LeCun-tutorial-icml_15.svg' style="width:66%"><br/>

LeCun (2013)
</div>

我々人間は，外界を認識するために必要な計算を，生物種としての発生の過程と，個人の発達を通しての経験に基づく認識系を保持していると見ることができる。
従って我々の視覚認識には化石時代に始まる光の受容器としての眼の進化の歴史と発達を通じた個人の視覚経験が反映された結果でもある。
人工知能の目標は，この複雑な特徴検出過程をどうやったらコンピュータが獲得できるかということでもある。
外界を認識するために今日まで考案されてきたモデル（例えば，ニューラルネットワーク，サポートベクターマシンなどは）は複雑である。
ですがモデルを訓練するための学習方法はそれほど難しくない。
この意味で画像認識課題が正しく動作するためのポイントは，認識系が問題を解く事が可能なほど複雑であるかどうかではなく，十分に複雑が視覚環境，すなわち画像認識の場合，外部の艦橋を反映するために十分な量の像データを容易すことができるか否かにある。
今日の CNN による画像認識性能の向上は，簡単な計算方法を用いて複雑な外部環境に適応できる認識系を構築する方法が確立したからであると言うことが可能であろう。

下図 <!--[fig:2012Ng_01](#fig:2012Ng_01){reference-type="ref"reference="fig:2012Ng_01"} -->
に画像処理の例を挙げた。

<center>
<img src="/assets/2012Ng_ML_and_AI_01.png" style="width:66%">
</center>

## Sutton のブログより

<center>
<div style="text-align: left;width: 88%;background-color: powderblue;">
人工知能の長年の目標は，困難な領域でも超人的な能力をタブラ・ラサ方式で学習するアルゴリズムである。
最近では AlphaGo が囲碁の世界チャンピオンを破った初めてのプログラムとなった。
AlphaGo の木探索は，深層ニューラルネットワークを用いて局面の評価と手の選択を行う。
このニューラルネットワークは，人間の熟練した手からの教師付き学習と， 自分自身の競技からの強化学習によって訓練されている。
ここでは，人間のデータやガイダンス，ゲームルール以外の領域の知識を必要としない，強化学習のみに基づいたアルゴリズムを導入する。
AlphaGo は自分自身の教師となり AlphaGo 自身の手の選択や AlphaGo のゲームの勝敗を予測するようにニューラルネットワークが学習される。
このニューラルネットワークは，木探索の強度を向上させ，その結果，より質の高い手の選択が可能となり，次の反復ではより強力な自己対戦が可能となる。
タブララサからスタートした私たちの新しいプログラム AlphaGo Zero は，既発表のチャンピオンに敗れた AlphaGo に対して 100-0 で勝利するという超人的な成績を達成した。
</div>
</center>

* [David Silver homepage](https://www.davidsilver.uk/){:target="_blank"}

1. [計算論的認知神経科学 Kriegeskorte and Douglas, 2018, Cognitive computational neuroscience](https://project-ccap.github.io/2018Kriegeskorte_Douglas_Cognitive_Computational_Neuroscience.pdf){:target="_blank"}
1. [視覚系の畳み込みニューラルネットワークモデル，過去現在未来 Lindsay, 2020, Convolutional Neural Networks as a Model of the Visual System: Past, Present, and Future](https://project-ccap.github.io/2020Lindsay_Convolutional_Neural_Networks_as_a_Model_of_the_Visual_System_Past_Present_and_Future.pdf){:target="_blank"}
1. [計算論的視覚と正則化理論 Poggio, Torre, Koch, 1985](https://komazawa-deep-learning.github.io/2021cogpsy/1985Poggio_Computational_Vision_and_Regularization_Theory.pdf){:target="_blank"}
1. [皮質における物体認識の階層モデル Riesenhuber and Poggio (1999) Nature](https://komazawa-deep-learning.github.io/2021cogpsy/1999Riesenhuber_Poggio_Hierarchical_models_of_object_recognition_in_cortex.pdf){:target="_blank"}




## 経路仮説と残差ネット

* 腹側経路 ventral pathways ("what" 経路)
* 背側経路 dorsan pathways ("where" 経路)

<center>
<img src="/assets/1982Ungerleider_Mishkin.jpg" width="49%">
<div style="text-align:left;width:88%;color:teal">

* 下左: 物体弁別課題と下側頭回損傷。
* 下右: 目印課題と頭頂葉損傷。
Ungerleider&Mishkin1982 より。
</div></center>

<center>
<img src="/2023assets/2004Hickok_dorsal_ventral_language_fig1a.jpg" width="49%">
<img src="/2023assets/2004Hickok_dorsal_ventral_language_fig1b.jpg" width="49%">
<div style="text-align:left;width:94%;color:teal">
左: 言語の機能解剖学的枠組み。Hickok&Poeppel2000 より

右: 脳の側面図に示したモデル構成要素の一般的な場所。
モデル内のある機能に関連する皮質領域は，その機能に特化しているという仮説ではない。
調音に基づく音声符号を支援すると考えられる前頭葉領域の定義は，物品の命名と調音リハーサル処理の機能画像研究にお
ける活性化領域の一般的な分布から得られる (例えば Awh+1996, Hickok+2003, Indefrey&Levelt)。
帯状の領域 (上側頭溝) は，音素レベルの表現を支援すると思われる領域。
</div>
</center>

## ResNet におけるスキップ結合

<img src="/assets/ResNet_Fig2.svg" width="33%"><br/>
<img src="/assets/2015ResNet30.svg" width="94%"><br/>

#### R-CNN

<img src="/2023assets/2015Ren_Faster_R-CNN_fig2.svg">

<!--<img src="/assets/2017He_MaskRCNN_41.svg">
<img src="/assets/2015Fast_R-CNN_Fig1.svg">
<img src="/assets/2015Faster_RCNN_RPN.svg">
<img src="/assets/1998LeCun_Fig2_CNN.svg">
<img src="/assets/2017He_MaskRCNN_02SemSeg.svg">
<img src="/assets/2017He_MaskRCNN_08.svg">
<img src="/assets/2017He_MaskRCNN_02Oject.svg">
<img src="/assets/2013Girshick_RCNN_Fig1.svg"> -->

