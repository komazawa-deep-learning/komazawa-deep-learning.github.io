{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2022notebooks/2022_1028komazawa_neural_networks_primer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1469ed95-40d5-4ced-bbff-ded6691ee8e3",
      "metadata": {
        "id": "1469ed95-40d5-4ced-bbff-ded6691ee8e3"
      },
      "source": [
        "# 1. ニューラルネットワークモデルの定義\n",
        "\n",
        "以下に [PyTorch](https://pytorch.org/) を⽤いた，最も簡単なニューラルネットワークの定義を示します。\n",
        "\n",
        "近年のニューラルネットワークモデルを構築するためのライブラリの特徴として， **自動微分** が挙げられます。\n",
        "自動微分により，**誤差逆伝播法 back propagation** のための微分計算部分をコーディングする手間が不要になります。\n",
        "\n",
        "このため，ニューラルネットワークモデルを作成する場合には，モデルのプロトタイプ (雛形) を定義する部分 `class` の内部にある関数定義 `def` は，最低二つあれば良いことになります。\n",
        "\n",
        "二つとは，`__init__()` と `forward()` です。\n",
        "`__init__()` 関数は初期化を担当し，`forward()` 関数は，前向きの処理，すなわち，入力データを処理して出力するまでを記述することになります。\n",
        "学習に必要な `backward()` 関数は，上で書いた自動微分が自動的に計算されるので，不要となります。\n",
        "\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class perceptron(nn.Module):\n",
        "    def __init__(self, in_features=2, out_features=1):\n",
        "        super().__init__()\n",
        "        self.layer = nn.Linear(in_featuers, out_features)\n",
        "        self.act_f = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, data):\n",
        "        out = self.act_f(self.layer(data))\n",
        "         return out\n",
        "    \n",
        "network = perceptron()\n",
        "   \n",
        "print(network.state_dict())\n",
        "print(network)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20ba3d4f-a8cc-4f30-bb46-45644e1e1e94",
      "metadata": {
        "id": "20ba3d4f-a8cc-4f30-bb46-45644e1e1e94"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class perceptron(nn.Module):\n",
        "    def __init__(self, in_features=2, out_features=1):\n",
        "        super().__init__()\n",
        "        self.layer = nn.Linear(in_features=in_features, out_features=out_features)\n",
        "        self.act_f = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = self.layer(X)\n",
        "        X = self.act_f(self.layer(X))\n",
        "        return X\n",
        "\n",
        "net = perceptron()\n",
        "print(f'net.eval():{net.eval()}')\n",
        "print(f'net.state_dict():{net.state_dict()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "676397ee-6c7c-4adc-833f-4a50226012a9",
      "metadata": {
        "id": "676397ee-6c7c-4adc-833f-4a50226012a9"
      },
      "source": [
        "# 2. 活性化関数"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# グラフ内の表記に日本語を使うための準備\n",
        "try:\n",
        "    import japanize_matplotlib\n",
        "except ImportError:\n",
        "    !pip install japanize_matplotlib\n",
        "    import japanize_matplotlib"
      ],
      "metadata": {
        "id": "p18aiqp7JLii"
      },
      "id": "p18aiqp7JLii",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0a5bfd6-59c0-4505-b979-2f7327ad3604",
      "metadata": {
        "id": "f0a5bfd6-59c0-4505-b979-2f7327ad3604"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from scipy.special import expit as sigmoid\n",
        "\n",
        "x = np.linspace(-2,2)\n",
        "plt.plot(x, sigmoid(x), label=\"シグモイド関数\")\n",
        "plt.plot(x, np.tanh(x), label=\"ハイパータンジェント\")\n",
        "plt.plot(x, np.clip(x, 0, 6), label=\"ReLU6\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d662766-3609-4d5c-afa9-acac1bcf2e31",
      "metadata": {
        "id": "4d662766-3609-4d5c-afa9-acac1bcf2e31"
      },
      "source": [
        "# 3. 損失関数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "784772cd-d94a-40c4-9551-568f6113dd3a",
      "metadata": {
        "id": "784772cd-d94a-40c4-9551-568f6113dd3a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "epsilon = 10 ** -4\n",
        "print(epsilon)\n",
        "x = np.linspace(0+epsilon, 1-epsilon)\n",
        "\n",
        "plt.grid()   # マス目を表示するため\n",
        "plt.plot(x, - np.log(x), label=\"$-\\log(x)$\", c=\"red\")\n",
        "plt.plot(x, - np.log(1-x), label=\"$-log(1-x)$\", c=\"green\")\n",
        "plt.xlabel(\"確率 $p(x)$\")\n",
        "plt.ylabel(\"損失値 $\\ell$\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "bce = x * np.log(x) + (1-x) * np.log(1-x)\n",
        "plt.grid()   # マス目を表示するため\n",
        "plt.plot(x, bce)\n",
        "plt.title(\"交差エントロピー\")\n",
        "plt.xlabel(\"確率 $p(x)$\")\n",
        "plt.ylabel(\"損失値 $\\ell$\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9e10364-58a4-4f31-871f-da5bf33fe33e",
      "metadata": {
        "id": "a9e10364-58a4-4f31-871f-da5bf33fe33e"
      },
      "source": [
        "# 4. パーセプトロン"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d135073-605f-48e4-b81c-7e28857d3e41",
      "metadata": {
        "id": "8d135073-605f-48e4-b81c-7e28857d3e41"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class perceptron(nn.Module):\n",
        "    def __init__(self, in_features=2, out_features=1):\n",
        "        super().__init__()\n",
        "        self.layer = nn.Linear(in_features=in_features, out_features=out_features)\n",
        "        self.act_f = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = self.layer(X)\n",
        "        out = self.act_f(X)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46c9b080-7657-4e03-9aa4-8bec0e8bdd74",
      "metadata": {
        "id": "46c9b080-7657-4e03-9aa4-8bec0e8bdd74"
      },
      "outputs": [],
      "source": [
        "net = perceptron() # モデルの実体化（インスタンス化）\n",
        "loss_f = nn.MSELoss()  # 損失関数の 定義\n",
        "\n",
        "import torch.optim as optim\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01) # 最適化の定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3baa46e4-ff3d-44eb-8a1a-9f8da4048946",
      "metadata": {
        "id": "3baa46e4-ff3d-44eb-8a1a-9f8da4048946"
      },
      "outputs": [],
      "source": [
        "X = torch.Tensor([[0,0],[0,1],[1,0],[1,1]])\n",
        "y = torch.Tensor([[0],[1],[1],[1]])\n",
        "print(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8d9a3f6-02cb-4b17-8237-f2f2f6bc5aaa",
      "metadata": {
        "id": "c8d9a3f6-02cb-4b17-8237-f2f2f6bc5aaa"
      },
      "outputs": [],
      "source": [
        "net = perceptron()\n",
        "loss_f = nn.MSELoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
        "net.train()\n",
        "iter_max = 10 ** 3\n",
        "interval = iter_max >> 2\n",
        "for i in range(iter_max):\n",
        "    pred = net(X)\n",
        "    loss = loss_f(pred, y)\n",
        "    if (i % (iter_max >> 2)) == 0:\n",
        "        print(f'{i:<5d} 損失: {loss.detach().numpy():.3f}')\n",
        "    loss.backward() # Updating gradients\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2660ebbd-d822-473a-83a3-49d24ec4ee48",
      "metadata": {
        "id": "2660ebbd-d822-473a-83a3-49d24ec4ee48"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}