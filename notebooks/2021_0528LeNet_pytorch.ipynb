{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2021_0528LeNet_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG1j3LVAX0Hm"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/komazawa-deep-learning/komazawa-deep-learning.github.io/master/assets/1998LeCun_Fig2_CNN.svg\"> <br/>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WX7-4c8-cUGf",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "try:\n",
        "    import japanize_matplotlib\n",
        "except ImportErrors:\n",
        "    !pip install japanize_matplotlib\n",
        "    import japanize_matplotlib\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzEGfaGBQxq3",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import requests\n",
        "\n",
        "mnist_urls = {\n",
        "    #http://yann.lecun.com/exdb/mnist/\n",
        "    'Xtrain': 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
        "    'Ytrain': 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
        "    'Xtest': 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
        "    'Ytest':'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'\n",
        "}\n",
        "\n",
        "fashionmnist_urls = {\n",
        "    #https://github.com/zalandoresearch/fashion-mnist\n",
        "    'Xtest': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz',\n",
        "    'Ytest': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz',\n",
        "    'Xtrain': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz',\n",
        "    'Ytrain': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz'\n",
        "}\n",
        "\n",
        "kmnist_urls = {\n",
        "    #http://codh.rois.ac.jp/kmnist/\n",
        "    'Xtrain': 'http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-images-idx3-ubyte.gz',\n",
        "    'Ytrain': 'http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-labels-idx1-ubyte.gz',\n",
        "    'Xtest': 'http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-images-idx3-ubyte.gz',\n",
        "    'Ytest': 'http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-labels-idx1-ubyte.gz'\n",
        "}\n",
        "\n",
        "\n",
        "def download_mnist(dataset):\n",
        "    #上で定義したデータセットの情報を元にデータをダウンロードする\n",
        "    for name, url in dataset.items():\n",
        "        fname = url.split('/')[-1]\n",
        "        print(url, fname)\n",
        "        r = requests.get(url, timeout=35) #timeout=None はサーバからの応答が遅い場合永遠に待ち続ける\n",
        "        with open(fname, 'wb') as f:\n",
        "            f.write(r.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Gt_U_34cd-h",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def load_mnist(path, kind='train'):\n",
        "    \"\"\"ダウンロードしたデータを読み込む関数\"\"\"\n",
        "    import os\n",
        "    import gzip\n",
        "    import numpy as np\n",
        "\n",
        "    \"\"\"Load MNIST data from `path`\"\"\"\n",
        "    labels_path = os.path.join(path,\n",
        "                               '%s-labels-idx1-ubyte.gz'\n",
        "                               % kind)\n",
        "    images_path = os.path.join(path,\n",
        "                               '%s-images-idx3-ubyte.gz'\n",
        "                               % kind)\n",
        "\n",
        "    with gzip.open(labels_path, 'rb') as lbpath:\n",
        "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
        "                               offset=8)\n",
        "\n",
        "    with gzip.open(images_path, 'rb') as imgpath:\n",
        "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
        "                               offset=16).reshape(len(labels), 784)\n",
        "\n",
        "    return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jxqa6CYpc5vG",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# 存在しているファイルを一旦削除\n",
        "fnames = ['train-images-idx3-ubyte.gz','train-labels-idx1-ubyte.gz', 't10k-images-idx3-ubyte.gz', 't10k-labels-idx1-ubyte.gz']\n",
        "for fname in fnames:\n",
        "    if os.path.exists(fname):\n",
        "        print(fname)\n",
        "        os.remove(fname)\n",
        "\n",
        "#データの表示\n",
        "mnist_labels = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "fashionmnist_labels = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat' ,\n",
        "                       'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "kmnist_labels = ['お', 'き', 'す', 'つ', 'な', 'は', 'ま', 'や', 'れ', 'を']\n",
        "# '0,U+304A,お', '1,U+304D,き', '2,U+3059,す', '3,U+3064,つ', '4,U+306A,な',\n",
        "# '5,U+306F,は', '6,U+307E,ま', '7,U+3084,や', '8,U+308C,れ', '9,U+3092,を'\n",
        "\n",
        "labels = mnist_labels\n",
        "#labels = fashionmnist_labels\n",
        "#labels = kmnist_labels\n",
        "\n",
        "#以下の 3 つのデータセットのうち 1 つを選んで実習してみましょう\n",
        "dataset = mnist_urls\n",
        "#dataset = fashionmnist_urls\n",
        "#dataset = kmnist_urls\n",
        "\n",
        "download_mnist(dataset)\n",
        "\n",
        "X_train, Y_train = load_mnist('.', kind='train')\n",
        "X_test, Y_test = load_mnist('.', kind='t10k')\n",
        "\n",
        "_Y = np.zeros((len(Y_train),10))\n",
        "for i in range(len(_Y)):\n",
        "    _Y[i,Y_train[i]] = 1\n",
        "#Y_train = _Y\n",
        "\n",
        "_Y = np.zeros((len(Y_test),10))\n",
        "for i in range(len(_Y)):\n",
        "    _Y[i,Y_test[i]] = 1\n",
        "#Y_test = _Y\n",
        "\n",
        "# 時間節約のためデータ数を制限\n",
        "n_train = 60000             # 訓練データ数 今回は 60000 なので全データを使用します。\n",
        "n_val = 1000                # 検証データ数\n",
        "n_test = 10000              # テストデータ数\n",
        "X_train = X_train[-n_train:]\n",
        "Y_train = Y_train[-n_train:]\n",
        "X_val = X_train[-n_val:]\n",
        "Y_val = Y_train[-n_val:]\n",
        "X_test = X_test[-n_test:]\n",
        "Y_test = Y_test[-n_test:]\n",
        "\n",
        "#次行の数字を変更して実施してください。ただし数字の範囲は 0 から 59999 までです\n",
        "No = int(input('次行の数字を変更して実施してください。ただし数字の範囲は 0 から 59999 までです:'))\n",
        "#No = 666\n",
        "plt.figure(figsize=(1,1))    #表示する縦横の大きさ，単位はインチ\n",
        "#plt.title('label:{}'.format(labels[np.argmax(Y_train[No])]))\n",
        "plt.title('label:{}'.format(labels[Y_train[No]]))\n",
        "plt.axis(False)\n",
        "plt.imshow(X_train[No].reshape(28,28), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjDvDkL2Bbd7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# このセルはおまじない\n",
        "X_train = np.copy(X_train)\n",
        "X_train.setflags(write=1)\n",
        "X_test = np.copy(X_test)\n",
        "X_test.setflags(write=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ba0mgvBRdNAS",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#PyTorch の必要なライブラリを輸入\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWtuQxEPe-ZN",
        "tags": []
      },
      "outputs": [],
      "source": [
        "batch_size = 64           #バッチサイズ，処理速度と収束速度に影響します\n",
        "test_batch_size = 1000\n",
        "max_epochs = 14           #訓練する総エポック数\n",
        "lr = 1.0                  #学習率\n",
        "gamma = 0.7\n",
        "#use_cuda = True           #GPU の使用を宣言\n",
        "seed = 42\n",
        "log_interval = 10\n",
        "save_model = False\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "#device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if device==\"cuda\" else {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RiWDLZioU64",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#駒沢大学用データセットの定義\n",
        "class koma_mnist_dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y, transform=None):\n",
        "        super(koma_mnist_dataset, self).__init__()\n",
        "        self.transform = transform\n",
        "        self.data = X.reshape(-1,28,28)\n",
        "        self.label = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        if self.transform:\n",
        "            _X = self.transform(self.data[ind])\n",
        "            _y = int(self.label[ind])\n",
        "        else:\n",
        "            _X = self.data[ind]\n",
        "            _y = int(self.label[ind])\n",
        "        return _X, _y\n",
        "\n",
        "# _dataset = koma_mnist_dataset(X_train, Y_train, transform_)\n",
        "\n",
        "koma_mnist_train_loader = torch.utils.data.DataLoader(\n",
        "    koma_mnist_dataset(X_train, #.reshape(-1,28,28),\n",
        "                       Y_train,\n",
        "                       transform=transforms.Compose([transforms.ToTensor(),\n",
        "                                                    transforms.Normalize((0.1307,), (0.3081,))]\n",
        "                                                    )\n",
        "                       ),\n",
        "                       batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "koma_mnist_test_loader = torch.utils.data.DataLoader(\n",
        "    koma_mnist_dataset(X_test,\n",
        "                       Y_test,\n",
        "                       transform=transforms.Compose([transforms.ToTensor(),\n",
        "                                                     transforms.Normalize((0.1307,), (0.3081,))]\n",
        "                                                    )\n",
        "                ),\n",
        "                batch_size=test_batch_size, shuffle=False, **kwargs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "-kOCTbh0VoJA"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/komazawa-deep-learning/komazawa-deep-learning.github.io/master/assets/1998LeCun_Fig2_CNN.svg\"> <br/>\n",
        "</center>\n",
        "\n",
        "$$\n",
        "\\text{out}\\left(N_i, C_{\\text{out}_j}\\right) =\n",
        "\\text{bias}\\left(C_{\\text{out}_j}\\right) +\n",
        "      \\sum_{k = 0}^{C_{\\text{in}} - 1} \\text{weight}\\left(C_{\\text{out}_j}, k\\right) \\star \\text{input}(N_i, k)\n",
        "$$\n",
        "ここで，\n",
        "\n",
        "* $\\star$: 2D 交差相関 (cross-correlation) 演算子\n",
        "* $N$: バッチサイズ，\n",
        "* $C$: チャンネル (特徴) 数\n",
        "* $H$: 画像の縦，単位は画素数\n",
        "* $W$: 画像の横幅,\n",
        "\n",
        "<!-- ### Shape:\n",
        "\n",
        "* Input: $(N, C_{in}, H_{in}, W_{in})$ or $(C_{in}, H_{in}, W_{in})$\n",
        "* Output: $(N, C_{out}, H_{out}, W_{out})$ or  $(C_{out}, H_{out}, W_{out})$,\n",
        "where\n",
        "$$\\begin{aligned}\n",
        "H_{out} &= \\left\\lfloor\\frac{H_{in}  + 2 \\times \\text{padding}[0] - \\text{dilation}[0]\n",
        "\\times (\\text{kernel_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\\\\\n",
        "W_{out} &= \\left\\lfloor\\frac{W_{in}  + 2 \\times \\text{padding}[1] - \\text{dilation}[1]\n",
        "\\times (\\text{kernel_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\n",
        "\\end{aligned}$$\n",
        " -->\n",
        "<!-- $$\n",
        "H_{out} = \\left\\lfloor\\frac{H_{in}  + 2 \\times \\text{padding}[0] - \\text{dilation}[0]\n",
        "\\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\n",
        "$$\n",
        "\n",
        "$$\n",
        "W_{out} = \\left\\lfloor\\frac{W_{in}  + 2 \\times \\text{padding}[1] - \\text{dilation}[1]\n",
        "\\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\n",
        "$$\n",
        "\n",
        "\n",
        " -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "p0HQ_6e4VoJB"
      },
      "source": [
        "<!-- # #(12 ** 2) * 64\n",
        "# #np.sqrt(9216 / 64)\n",
        "# #np.sqrt(9216)\n",
        "# #help(F.max_pool2d)\n",
        "# #help(nn.Conv2d)\n",
        "# #X_train.shape\n",
        "# #28 * 28\n",
        "# #26 * 26  / 4 * 64\n",
        "# #13 * 13\n",
        "# 24 * 24 / 4 * 64 -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArTYGLx-hU4z",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# LeNet の定義\n",
        "class LeNet_orig(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # 最初の畳み込み層\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=1,\n",
        "            out_channels=6,\n",
        "            kernel_size=3,\n",
        "            padding='same',\n",
        "            stride=1)\n",
        "\n",
        "        # 2 番目の畳み込み層\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5, 1)\n",
        "        self.dropout1 = nn.Dropout(p=0.25)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(\n",
        "            in_features=400,\n",
        "            out_features=128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # 最初の畳み込み層\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=1,\n",
        "            out_channels=32,\n",
        "            kernel_size=3,\n",
        "            stride=1)\n",
        "\n",
        "        # 2 番目の畳み込み層\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.dropout1 = nn.Dropout(p=0.25)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(\n",
        "            in_features=9216,\n",
        "            out_features=128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch, log_interval=10):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print(f'訓練エポック: {epoch}',\n",
        "                  f'[{batch_idx * len(data):>5d}/{len(train_loader.dataset)}',\n",
        "                  f'({100. * batch_idx / len(train_loader):5.2f}%)]',\n",
        "                  f' 損失値: {loss.item():.3f}')\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print(f'---テストデータ: 平均損失: {test_loss:.4f}, 精度: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):5.2f}%)')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdmYl5nAg5KE",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#訓練の実行\n",
        "model = LeNet().to(device)\n",
        "model = LeNet_orig().to(device)\n",
        "optimizer = optim.Adadelta(model.parameters(), lr=lr)\n",
        "\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
        "for epoch in range(1, max_epochs + 1):\n",
        "    test(model, device, koma_mnist_test_loader)\n",
        "    train(model, device, koma_mnist_train_loader, optimizer, epoch, log_interval=10 ** 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_g8_183XOfD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}