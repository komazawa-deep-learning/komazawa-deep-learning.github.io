{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2025notebooks/2026_0116NB0000.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 学生番号：\n",
        "* 氏名："
      ],
      "metadata": {
        "id": "hTWkQI54yZgy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 前期キーワード\n",
        "\n",
        "* 機械学習 ML:Machine Learning\n",
        "* 人工知能 AI:Artificial Intelligence\n",
        "* ニューラルネットワーク NN: Neural Networks\n",
        "* ダートマス会議\n",
        "* 深層学習 DL: Deep Learning\n",
        "* 分類 Classification\n",
        "* 回帰 Regression\n",
        "* ロジスティック回帰 Logistic Regression\n",
        "* サポートベクターマシン Support Vector Machines\n",
        "* 教師あり学習 Supervised Learning\n",
        "* 教師なし学習 Unsupervised Learning\n",
        "* 次元圧縮 Demensionality Reductions\n",
        "* 入力信号 Input Signals\n",
        "* 出力信号 Output Signals\n",
        "* 訓練データ，検査データ，検証データ Training dataset, Test dataset, Validation dataset\n",
        "* 過学習 over-learning\n",
        "* 精度 accuracy，適合度 precision，再現率 recall，F1 値 F1 value\n",
        "* 主成分分析 PCA: Pricipal Component Analysis\n",
        "* パーセプトロン Perceptrons\n",
        "* ニューロン Neurons\n",
        "* マッカロック・ピッツの形式ニューロン McCallogh and Pitts's Forma Neurons\n",
        "* ソフトマックス関数 Softmax functions\n",
        "* 誤差逆伝播(バックプロパゲーション)法 The Back-Propagation method\n",
        "* 誤差関数, 損失関数，目的関数: Error, Loss, Objective functions\n",
        "* 活性化関数 Activation functions\n",
        "* 整流線型化関数 ReLU ReCtified Linear Unit\n",
        "* シグモイド関数 The Sigmoid function\n",
        "* 勾配降下法 Gradient Descent method\n",
        "* ブラインド ハイカー アナロジー Blind Hiker's analogy\n",
        "* 学習率 Learning Ratio\n",
        "* 最適化 Optimization\n",
        "* 勾配消失問題 Gradient vanishing Problems\n",
        "* 勾配爆発問題 Gradient explosion Problems\n",
        "* 信用割当問題 Credit Assignment Problems\n",
        "* ネオコグニトロン Neocognitrons\n",
        "* 畳み込みニューラルネットワーク CNN: Convolutional Neural Networks\n",
        "* LeNet\n",
        "* 交差エントロピー Cross Entropy\n",
        "* 敵対生成ネットワーク Generative Adversarial Networks\n",
        "* 拡散モデル Diffusion Models\n",
        "* 基盤モデル Fundation Models\n",
        "* 変分自己符号化器モデル VAE: Variational Auto-Encoders\n",
        "* 変分下限 ELBO: Evidence Lower BOund\n",
        "* ソーカル事件\n",
        "\n",
        "## 後期キーワード\n",
        "\n",
        "* 言語モデル LM: Language Models\n",
        "* 系列予測 Serial predictions\n",
        "* フーリエ変換 Fourier Transform\n",
        "* 時系列分析 Time Series Analysis\n",
        "* AR (Auto-Regresion), ARMA (Auto-Regression with Moving Average), ARIMA (Auto-Regression Integrated with Moving Average)\n",
        "* カルマンフィルタ Kalman Filters\n",
        "* SRN 単純再帰型ニューラルネットワーク Simple Recurrent Neural Networks\n",
        "* LSTM 長-短期記憶 Long Short-Term Memory\n",
        "* word2vec\n",
        "* Transformer\n",
        "* BERT\n",
        "* 位置符号化器 Position Encoders\n",
        "* GPT: Generative Pre-trained Transformer\n",
        "* 埋め込みベクトル Embeddings (vectors)\n",
        "* マルチヘッド注意 Multihead Attentions\n",
        "* マスク化言語モデル Masked Language Models\n",
        "* RAG: Retrieval Augmented Generations 検索拡張生成\n",
        "* プロンプトエンジニアリング Prompt Engineering\n",
        "* 強化学習 RL:Reinforcement Learning\n",
        "    * 動作主 Agent\n",
        "    * 状態 State\n",
        "    * 報酬 Reward\n",
        "    * 価値 Value\n",
        "    * 方針 Policy\n",
        "    * 割引率 discount ratio\n",
        "    * Q 関数 （行動価値関数）\n",
        "    * SARSA\n",
        "    * TD 学習\n",
        "    * マルコフ決定過程 Markov Decision Processes\n",
        "    * ベルマン方程式 Bellman's Equation\n",
        "    * 信用割当問題 Credit Assignment Problems\n",
        "    * エピソード（軌跡，ロールアウト），Episodes, Trajectories, Rollouts\n",
        "    * 優位(アドバンテージ)関数，\n",
        "    * 経験再生 Experience Replay\n",
        "    * セルフプレイ Self Plays\n",
        "    * DQN: Deep Q Networks\n",
        "    * RLHF: 人間のフィードバックによる強化学習 Reinforcemnet Learning with Human Feedbacks\n",
        "    * Agent57\n",
        "* 世界モデル World models\n",
        "* 視覚言語行動モデル VLA (Vision-Language-Action) models\n"
      ],
      "metadata": {
        "id": "yLxBuIr3z_5z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 設問\n",
        "\n",
        "1. 上記のキーワードのうち任意の ３ つを選び，chatGPT, Groq, Gemini などの AI に入力して，それぞれのキーワードの関連を出力させよ。その出力を記せ。\n",
        "2. 1 で出力された文章に対して，異議や改善点を指摘し，AI による再出力を記せ。\n",
        "3. 上記 3 つのキーワードと自分の関心のある心理学現象，あるいは心理学テーマとの関連から，研究計画を AI に立案させ，その回答を記せ。\n",
        "4. 上の研究計画に対して，AI に批判，改善点，深堀り，などを指示し，AI からの回答を記せ。\n"
      ],
      "metadata": {
        "id": "krxtPF4Iydrc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 回答 1:\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "p88rjXU-ylax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 回答 2:\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CLGL0zIZyonK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 回答 3:\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3TrrVfleyoOA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 回答 4:\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tNkFSqxhy2Vx"
      }
    }
  ]
}