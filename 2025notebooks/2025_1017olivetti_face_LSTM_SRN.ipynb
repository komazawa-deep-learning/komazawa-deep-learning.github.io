{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2025notebooks/2025_1017olivetti_face_LSTM_SRN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5-amTpixBS_o",
      "metadata": {
        "id": "5-amTpixBS_o"
      },
      "source": [
        "# オリベッティ顔データセットを用いた機械学習実習\n",
        "\n",
        "* filename: 2025_1017olivetti_face_LSTM_SRN.ipynb\n",
        "* author: 浅川 伸一 asakawa@ieee.org\n",
        "* date: 2025_1010\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0956f10b-f104-44e8-bf7d-8f516b27b3c8",
      "metadata": {
        "id": "0956f10b-f104-44e8-bf7d-8f516b27b3c8"
      },
      "outputs": [],
      "source": [
        "%config InlineBackend.figure_format = 'retina'\n",
        "import IPython\n",
        "isColab = 'google.colab' in str(IPython.get_ipython())\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "try:\n",
        "    import japanize_matplotlib\n",
        "except ImportError:\n",
        "    !pip install japanize_matplotlib\n",
        "    import japanize_matplotlib\n",
        "\n",
        "import numpy as np\n",
        "# numpy の表示桁設定\n",
        "np.set_printoptions(precision=5, suppress=False)\n",
        "\n",
        "# オリベッティ顔データセットの読み込み\n",
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "data = fetch_olivetti_faces()\n",
        "X, y = data.data, data.target\n",
        "print(f'訓練データサイズ X.shape:{X.shape}')\n",
        "print(f'教師データサイズ y.shape:{y.shape}')\n",
        "print(data.DESCR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a06cd9f-036f-4b7c-8c90-80444efe935b",
      "metadata": {
        "id": "9a06cd9f-036f-4b7c-8c90-80444efe935b"
      },
      "outputs": [],
      "source": [
        "# データの表示\n",
        "nrows = 40   # nrows 人分のデータを表示\n",
        "ncols = 10\n",
        "fig, fig_axes = plt.subplots(ncols=ncols, nrows=nrows, figsize=(ncols * 1.4, nrows * 1.4), constrained_layout=True)\n",
        "# constrained_layout は subplot や 凡例やカラーバーなどの装飾を自動的に調整して，\n",
        "# ユーザが要求する論理的なレイアウトをできるだけ維持しながら， 図ウィンドウに収まるようにします。\n",
        "\n",
        "for i in range(nrows):\n",
        "    for j in range(ncols):\n",
        "        x = i * 10 + j\n",
        "        fig_axes[i][j].imshow(X[x].reshape(64,64), cmap='gray')\n",
        "        fig_axes[i][j].axis('off')\n",
        "        fig_axes[i][j].set_title(f'num:{x}, ID:{y[x]}')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bNppGAoBhAp",
      "metadata": {
        "id": "1bNppGAoBhAp"
      },
      "outputs": [],
      "source": [
        "# 男女の判別のため教師データを作成\n",
        "# 男であれば 0, 女であれば 1 とする\n",
        "y_sex = np.zeros_like(y)\n",
        "for woman_start in [70, 90, 310, 340]:\n",
        "    for i in range(10):\n",
        "        y_sex[woman_start+i]=1\n",
        "\n",
        "for i in range(0, len(X),10):\n",
        "    print(f'{i:3d}', end=\":\")\n",
        "    for j in range(10):\n",
        "        print(y_sex[i+j], end=\" \")\n",
        "    print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d665e752-c7d5-48dd-9cbc-622e143046ca",
      "metadata": {
        "id": "d665e752-c7d5-48dd-9cbc-622e143046ca"
      },
      "source": [
        "# 系列情報処理実習\n",
        "\n",
        "データである 400 枚の画像はそれぞれ縦横 64 画素である。これを 1 次元にすれば 1 枚の画像は 4096 次元のベクトルである。\n",
        "したがって，系列予測課題とみなすこともできる。\n",
        "\n",
        "以下ではデータを一次元系列データとして視覚化を行う\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34748e56-f5d1-45ea-b88e-b5ae2de7d773",
      "metadata": {
        "id": "34748e56-f5d1-45ea-b88e-b5ae2de7d773"
      },
      "outputs": [],
      "source": [
        "# 表示させたい画像番号を指定するリスト\n",
        "image_nums = [0, 10, 20, 30]\n",
        "image_nums = [70, 90, 310, 340]\n",
        "\n",
        "figs, axes = plt.subplots(len(image_nums), 2, figsize=(12, 1.5 * len(image_nums)), tight_layout=False)\n",
        "for i, image_num in enumerate(image_nums):\n",
        "    x = X[image_num]\n",
        "\n",
        "    #figs, axes = plt.subplots(1,2, figsize=(12,3), tight_layout=False)\n",
        "    #figs.suptitle(f'データ番号:{N}')\n",
        "\n",
        "    axes[i][0].plot(x)\n",
        "    axes[i][0].set_ylim(0,1)\n",
        "\n",
        "    axes[i][1].imshow(x.reshape(64,64), cmap='gray')\n",
        "    axes[i][1].set_xticks([])\n",
        "    axes[i][1].set_yticks([])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "031c1057-2f8a-4958-bcac-ef4bae613ff1",
      "metadata": {
        "id": "031c1057-2f8a-4958-bcac-ef4bae613ff1"
      },
      "source": [
        "# SRN, LSTM リカレントニューラルネットワークモデルによる近似"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 系列データを PyTorch で使えるような形式の系列データに変換\n",
        "import torch\n",
        "\n",
        "class _dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X:np.array=X, y:np.array=y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx:int):\n",
        "        inp = torch.Tensor(self.X[idx].reshape(64,64))\n",
        "        tch = self.y[idx]\n",
        "        return inp, tch\n",
        "\n",
        "_ds = _dataset(X=X, y=y)       # こちらは人物同定\n",
        "#_ds = _dataset(X=X, y=y_sex)  # 性別判定\n",
        "\n",
        "# データを訓練データと検証データとに分割\n",
        "N_train = int(_ds.__len__() * 0.9)  # 訓練データ数\n",
        "N_val = _ds.__len__() - N_train     # 検証データ数 = 全データ - 訓練データ\n",
        "\n",
        "# データ分割\n",
        "train_ds, val_ds = torch.utils.data.random_split(\n",
        "    dataset=_ds,\n",
        "    lengths=(N_train,N_val), generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "# 上で分割したデータをデータローダに変換\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "val_dl   = torch.utils.data.DataLoader(val_ds,   batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "KXcFoXyo3sgP"
      },
      "id": "KXcFoXyo3sgP",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class _SRN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim # 中間層の次元数\n",
        "        self.layer_dim = layer_dim   # 中間層の層数\n",
        "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='tanh')\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        hid = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
        "        out, hid = self.rnn(x, hid)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "\n",
        "class _LSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim # 中間層の次元数\n",
        "        self.layer_dim = layer_dim   # 中間層の層数\n",
        "        self.rnn = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Initialize hidden state with zeros\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
        "        h1 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
        "        hid = (h0, h1)\n",
        "        out, hn = self.rnn(x, hid)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "input_dim = 64    # 入力層の次元数\n",
        "hidden_dim = 256  # 中間層の次元数\n",
        "layer_dim = 2     # 中間層の層数\n",
        "output_dim = 40    # 出力層の次元数\n",
        "#output_dim = 2    # 出力層の次元数\n",
        "\n",
        "model0 = _SRN(input_dim, hidden_dim, layer_dim, output_dim)\n",
        "model1 = _LSTM(input_dim, hidden_dim, layer_dim, output_dim)\n",
        "error = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.001\n",
        "optimizer0 = torch.optim.Adam(model0.parameters(), lr=learning_rate)\n",
        "optimizer1 = torch.optim.Adam(model1.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "jywRHvRN2BPA"
      },
      "id": "jywRHvRN2BPA",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_dim = 64\n",
        "num_epochs = 50\n",
        "\n",
        "model = model1\n",
        "optimizer = optimizer1\n",
        "# model = model0\n",
        "# optimizer = optimizer0\n",
        "\n",
        "loss_list = []\n",
        "iteration_list = []\n",
        "accuracy_list = []\n",
        "count = 0\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    losses = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    model.eval()\n",
        "    for inps, tchs in val_dl:\n",
        "        outs = model(inps)\n",
        "        preds = torch.max(outs.data, 1)[1] # Get predictions from the maximum value\n",
        "        total += tchs.size(0)\n",
        "        correct += (preds == tchs).sum()\n",
        "\n",
        "    accuracy = 100 * correct / float(total)\n",
        "    iteration_list.append(epoch+1)\n",
        "\n",
        "    model.train()\n",
        "    for i, (inps, tchs) in enumerate(train_dl):\n",
        "        optimizer.zero_grad()\n",
        "        outs = model(inps)\n",
        "        loss = error(outs, tchs)\n",
        "        loss.backward() # Calculating gradients\n",
        "        optimizer.step() # Update parameters\n",
        "        losses += loss.item()\n",
        "\n",
        "    print(f'epoch:{epoch:03d}  Loss: {losses:8.3f}  Accuracy: {accuracy:6.3f}%')\n",
        "    accuracy_list.append(accuracy)\n",
        "    loss_list.append(losses) # store loss and iteration"
      ],
      "metadata": {
        "id": "fm7x7HgE8kml"
      },
      "execution_count": null,
      "outputs": [],
      "id": "fm7x7HgE8kml"
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization loss\n",
        "plt.plot(iteration_list,loss_list)\n",
        "plt.xlabel(\"Number of iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"RNN: Loss vs Number of iteration\")\n",
        "plt.show()\n",
        "\n",
        "# visualization accuracy\n",
        "plt.plot(iteration_list,accuracy_list,color = \"red\")\n",
        "plt.xlabel(\"Number of iteration\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"RNN: Accuracy vs Number of iteration\")\n",
        "#plt.savefig('graph.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cvvv6MsVEbFA"
      },
      "id": "cvvv6MsVEbFA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e47b2258-a955-4834-98d1-a67ceaa10040",
      "metadata": {
        "id": "e47b2258-a955-4834-98d1-a67ceaa10040"
      },
      "outputs": [],
      "source": [
        "# リカレントニューラルネットワークモデルの定義\n",
        "class _SRN(nn.Module):\n",
        "    \"\"\"単純再帰型ニューラルネットワーク a.k.a. エルマンネット\"\"\"\n",
        "    def __init__(self, input_size=1, hidden_size=16, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn(x)         # RNN output for all time steps\n",
        "        out = out[:, -1, :]          # Take output from the last time step\n",
        "        return self.fc(out)          # Pass through linear layer\n",
        "\n",
        "\n",
        "class _LSTM(nn.Module):\n",
        "    \"\"\"長‐短期記憶 LSTM: Long-Short Term Memory ネットワーク\"\"\"\n",
        "    def __init__(self, input_size=1, hidden_size=64, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn(x)         # RNN output for all time steps\n",
        "        out = out[:, -1, :]          # Take output from the last time step\n",
        "        return self.fc(out)          # Pass through linear layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f323d14c-0705-4699-b5e3-ddd2de50f483",
      "metadata": {
        "id": "f323d14c-0705-4699-b5e3-ddd2de50f483"
      },
      "outputs": [],
      "source": [
        "# 系列データを PyTorch で使えるような形式の系列データに変換\n",
        "class seq_dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data:np.array, seq_len:int=10):\n",
        "        self.data = data\n",
        "        self.seq_len = seq_len\n",
        "        _X, _y = self.make_sequences(data)\n",
        "        self._X = _X\n",
        "        self._y = _y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._X)\n",
        "\n",
        "    def __getitem__(self, idx:int):\n",
        "        inp = torch.Tensor(self._X[idx]).reshape(-1,1)\n",
        "        tch = torch.Tensor([self._y[idx]])\n",
        "        return inp, tch\n",
        "\n",
        "    def make_sequences(self, data:np.array):\n",
        "        xs, ys = [], []\n",
        "        for i in range(len(data) - self.seq_len):\n",
        "            x = data[i:i+self.seq_len] # Sequence of length `seq_length`\n",
        "            y = data[i+self.seq_len]   # Target is the next value\n",
        "            xs.append(x)\n",
        "            ys.append(y)\n",
        "        return np.array(xs), np.array(ys)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7b40c31-818a-4179-9888-f5a63a1e0d8e",
      "metadata": {
        "id": "f7b40c31-818a-4179-9888-f5a63a1e0d8e"
      },
      "source": [
        "## データの選択"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "398f5015-4d8e-4641-8310-4e05cde0de9b",
      "metadata": {
        "id": "398f5015-4d8e-4641-8310-4e05cde0de9b"
      },
      "outputs": [],
      "source": [
        "# 使用するデータを選ぶ\n",
        "N = 70  # N の値は 0 から 399 までの整数，オリベッティ顔画像データの刺激番号\n",
        "data = X[N]\n",
        "s_ds = seq_dataset(data=data)\n",
        "\n",
        "# データを訓練データと検証データとに分割\n",
        "N_train = int(s_ds.__len__() * 0.9)  # 訓練データ数\n",
        "N_val = s_ds.__len__() - N_train     # 検証データ数 = 全データ - 訓練データ\n",
        "\n",
        "# データ分割\n",
        "train_ds, val_ds = torch.utils.data.random_split(\n",
        "    dataset=s_ds,\n",
        "    lengths=(N_train,N_val), generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "# 上で分割したデータをデータローダに変換\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "val_dl   = torch.utils.data.DataLoader(val_ds,   batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "9wcp0mLbg3gI"
      },
      "id": "9wcp0mLbg3gI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## モデルの実体化と訓練の実施:\n",
        "\n",
        "以下のセル 2 行目の hidden_size を変化させて性能を比較せよ"
      ],
      "metadata": {
        "id": "9cPbRp5Qg_lu"
      },
      "id": "9cPbRp5Qg_lu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e679768-9df6-4866-bf6d-7b397034df12",
      "metadata": {
        "id": "8e679768-9df6-4866-bf6d-7b397034df12"
      },
      "outputs": [],
      "source": [
        "# モデルを実体化\n",
        "hidden_size = 8  # 中間層の素子数\n",
        "model0 = _SRN(hidden_size=hidden_size);model0.eval()\n",
        "model1 = _LSTM(hidden_size=hidden_size);model1.eval()\n",
        "\n",
        "# 損失関数の定義: MSE 平均二乗誤差 Mean Square Error\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# 学習に用いる最適化関数の定義\n",
        "lr = 1e-2  # lr: learning rate\n",
        "optimizer0 = optim.Adam(model0.parameters(), lr=lr)\n",
        "optimizer1 = optim.Adam(model1.parameters(), lr=lr)\n",
        "\n",
        "# 実習用，上で定義した SRN か LSTM かを選択する\n",
        "_model = model0\n",
        "_optimizer = optimizer0\n",
        "\n",
        "\n",
        "EPOCHS = 30                        # 訓練回数を設定\n",
        "train_losses, val_losses = [], []  # 訓練損失値と検証損失値を保存するための空リストを定義\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    _model.eval()\n",
        "    losses = []\n",
        "    for inps, tchs in val_dl:\n",
        "        outs = _model(inps)\n",
        "        loss = criterion(outs, tchs)\n",
        "        losses.append(loss.item())\n",
        "    val_losses.append(np.mean(losses))\n",
        "\n",
        "    _model.train()\n",
        "    losses = []\n",
        "    for inps, tchs in train_dl:\n",
        "        outs = _model(inps)\n",
        "        loss = criterion(outs, tchs)\n",
        "\n",
        "        _optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        _optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "    train_losses.append(np.mean(losses))\n",
        "\n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        print(f\"Epoch [{epoch+1:03d}/{EPOCHS:03d}]\",\n",
        "              f'訓練損失:{train_losses[-1]:8.4f}',\n",
        "              f'検証損失:{val_losses[-1]:8.4f}' )\n",
        "\n",
        "# 学習曲線を描画\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.plot(train_losses, label='訓練誤差')\n",
        "plt.plot(val_losses, label='検証誤差')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "224b3514-0207-4b69-b95e-84254ed7c80d",
      "metadata": {
        "id": "224b3514-0207-4b69-b95e-84254ed7c80d"
      },
      "outputs": [],
      "source": [
        "# 画像の復元\n",
        "_model.eval()\n",
        "y_hats, ys = [], []\n",
        "for i in range(s_ds.__len__()):\n",
        "    x, y = s_ds.__getitem__(i)\n",
        "    y_hat = _model(x.unsqueeze(0))\n",
        "    y_hats.append(y_hat.cpu().detach().numpy()[0])\n",
        "    ys.append(y.cpu().detach().numpy()[0])\n",
        "\n",
        "y_hats, ys = np.array(y_hats), np.array(ys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "145a0873-b1f4-4dc9-958b-e20dc8760655",
      "metadata": {
        "id": "145a0873-b1f4-4dc9-958b-e20dc8760655"
      },
      "outputs": [],
      "source": [
        "from matplotlib import gridspec\n",
        "\n",
        "fig = plt.figure(figsize=(12, 2)) # 全体の図の大きさを指定\n",
        "gs = gridspec.GridSpec(ncols=3, nrows=1,\n",
        "                       width_ratios=[4, 1,1],\n",
        "                       #height_ratios=[1, 2],\n",
        "                       wspace=0.1) # , hspace=0.4) # Adjust spacing between subplots\n",
        "\n",
        "ax0 = fig.add_subplot(gs[0, 0]) # left\n",
        "ax0.plot(range(2000), y_hats[-2000:], color='red', label='予測')\n",
        "ax0.plot(range(2000), ys[-2000:], color='green', label='実データ')\n",
        "ax0.legend()\n",
        "ax0.set_title('RNN による予測結果')\n",
        "\n",
        "ax1 = fig.add_subplot(gs[0, 1]) # middle\n",
        "ax1.imshow(np.concatenate( (np.zeros((10,1)), y_hats)).reshape(64,64), cmap='gray')\n",
        "ax1.set_title('再構成')\n",
        "ax1.set_xticks([])\n",
        "ax1.set_yticks([])\n",
        "\n",
        "ax2 = fig.add_subplot(gs[0, 2]) # right\n",
        "ax2.imshow(data.reshape(64,64), cmap='gray')\n",
        "ax2.set_title('実データ')\n",
        "ax2.set_xticks([])\n",
        "ax2.set_yticks([])\n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# カルマンフィルタ Kalman filter 実習"
      ],
      "metadata": {
        "id": "JRlXHAh3li4Q"
      },
      "id": "JRlXHAh3li4Q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fea97b10-904f-49bb-91b1-c0eb4eacff50",
      "metadata": {
        "id": "fea97b10-904f-49bb-91b1-c0eb4eacff50"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import filterpy\n",
        "except ImportError:\n",
        "    !pip install filterpy\n",
        "    import filterpy\n",
        "\n",
        "from filterpy.kalman import KalmanFilter\n",
        "from filterpy.common import Q_discrete_white_noise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f9ba3b6-d7fb-42cf-9b16-3448c7764588",
      "metadata": {
        "id": "1f9ba3b6-d7fb-42cf-9b16-3448c7764588"
      },
      "outputs": [],
      "source": [
        "N=0\n",
        "zs = X[N] #.reshape(1,-1)\n",
        "zs_mean = zs.mean(axis=0)\n",
        "zs_cov = np.cov(zs)\n",
        "\n",
        "kf = KalmanFilter(dim_x=1, dim_z=1) # zs.shape[0])\n",
        "#kf = KalmanFilter(dim_x=zs.shape[0],dim_z=zs.shape[0])\n",
        "\n",
        "kf.x = zs_mean\n",
        "kf.F = zs_cov\n",
        "kf.H = zs_cov\n",
        "\n",
        "xs, Cov = [], []\n",
        "for z in zs:\n",
        "    kf.predict()\n",
        "    kf.update(z)\n",
        "    xs.append(kf.x)\n",
        "    Cov.append(kf.P)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68d8d5c0-8a9c-484f-ace2-f1e860a92089",
      "metadata": {
        "id": "68d8d5c0-8a9c-484f-ace2-f1e860a92089"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(2,2))\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.imshow(np.array(xs).reshape(64,64), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e71b2d50-918d-467a-82e9-666b38238abf",
      "metadata": {
        "id": "e71b2d50-918d-467a-82e9-666b38238abf"
      },
      "source": [
        "# ARIMA 実習\n",
        "\n",
        "### 自己相関 (AR) 和分 (I) 移動平均 MA モデル\n",
        "\n",
        "ARIMA モデルとは自己相関 AR, 移動平均 MA, およびその和分 I をあわせた系列予測モデルである。\n",
        "\n",
        "教科書には p, d, q としてそれぞれ AR, I, MA の次数を決める。\n",
        "(p,d,q) = (1,0,0) であれば，1 次の自己相関となる。すなわち次式である：\n",
        "$$\n",
        "AR(1): y_{t} = \\alpha y_{t-1} + c + \\epsilon\n",
        "$$\n",
        "ここで時刻 $t$ の値 $y_{t}$ を予測する際に，直前の時刻 $t-1$ の値 $y_{t-1}$ の値から予測することになる。\n",
        "$c$ は切片，$\\alpha$ は回帰係数，$\\epsilon$ は誤差である。\n",
        "\n",
        "AR(2) すなわち 2 次の自己相関モデルであれば次式となる。\n",
        "$$\n",
        "AR(2): y_{t} = \\alpha_{1}y_{t-1} + \\alpha_{2}y_{t-2} + c + \\epsilon\n",
        "$$\n",
        "\n",
        "ただし以下のような制約が存在する。\n",
        "* AR(1)モデル: $−1<\\phi_1<1$<br/>\n",
        "* AR(2)モデル: $−1<\\phi_2<1,\\phi_1+\\phi_2<1,\\phi_2−\\phi_1<1$\n",
        "\n",
        "AR(m) m > 2 の場合制約は複雑になる。\n",
        "\n",
        "$m$ 次の自己相関モデル AR(m) であれば，次式となる：\n",
        "$$\n",
        "y_{t} = \\sum_{i=1}^{m}\\alpha_{i}y_{i} + c + \\epsilon\n",
        "$$\n",
        "\n",
        "ARIMA モデル，$d$ 階差分系列, $y_t-y_{t-d}$ を ARMA モデルで表現するのが ARIMA モデルである。\n",
        "$$\n",
        "ARIMA(p,d,q):y_{t} - y_{t-d} = c + \\sum_{i=1}^{p}\\phi_{i}y_{t-i} + \\sum_{i=1}^{q}\\theta_{i}\\epsilon_{t-1}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2da8df6-89e2-4a73-8d06-54ee739f56ea",
      "metadata": {
        "id": "a2da8df6-89e2-4a73-8d06-54ee739f56ea"
      },
      "source": [
        "## 移動平均モデル\n",
        "\n",
        "$$\n",
        "y_t = c + \\epsilon_t + \\theta_1\\epsilon_1+\\cdots+\\theta_{t-q}\\epsilon_{t-q}\n",
        "= c + \\epsilon_t + \\sum_{i=1}^{q}\\theta_{i}\\epsilon_{t-i},\n",
        "$$\n",
        "ここで $\\epsilon_{t}$ は白色雑音である。上式を q 次の移動平均モデル MA(q) と呼ぶ。\n",
        "\n",
        "MA(1) であれば次式となる：\n",
        "$$\n",
        "MA(1):y_t = c + \\epsilon + \\theta_1\\epsilon_{t-1}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ae8f2c3-ae43-42dc-80dd-922c2aba39e4",
      "metadata": {
        "id": "2ae8f2c3-ae43-42dc-80dd-922c2aba39e4"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "x = X[0]\n",
        "# ARIMA Model\n",
        "for order in [(1,0,0), (1,1,0), (1,1,2)]:\n",
        "    model = ARIMA(x, order=order)\n",
        "    model_fit = model.fit()\n",
        "    print(model_fit.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f1ae023-5178-4fbb-b6de-594b9ad81ed2",
      "metadata": {
        "id": "7f1ae023-5178-4fbb-b6de-594b9ad81ed2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5b84e16-768d-4542-a109-42180bd3b112",
      "metadata": {
        "id": "f5b84e16-768d-4542-a109-42180bd3b112"
      },
      "outputs": [],
      "source": [
        "# Plot residual errors\n",
        "residuals = pd.DataFrame(model_fit.resid)\n",
        "fig, ax = plt.subplots(1,2, figsize=(12,3))\n",
        "residuals.plot(title=\"Residuals\", ax=ax[0])\n",
        "residuals.plot(kind='kde', title='Density', ax=ax[1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "369f538d-21b5-4529-a694-9cf202e55a72",
      "metadata": {
        "id": "369f538d-21b5-4529-a694-9cf202e55a72"
      },
      "outputs": [],
      "source": [
        "from statsmodels.graphics.tsaplots import plot_predict\n",
        "#plot_predict(model_fit)\n",
        "#plt.show()\n",
        "\n",
        "fig, axes = plt.subplots(1,2, figsize=(4,2))\n",
        "axes[0].imshow(model_fit.predict().reshape(64,64), cmap='gray')\n",
        "axes[1].imshow(x.reshape(64,64),cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04146c6c-a7bd-4b31-bd66-2952cbec1346",
      "metadata": {
        "id": "04146c6c-a7bd-4b31-bd66-2952cbec1346"
      },
      "outputs": [],
      "source": [
        "#model_fit.conf_int?\n",
        "\n",
        "model_fit.standardized_forecasts_error.shape\n",
        "#(steps=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FFT 実習"
      ],
      "metadata": {
        "id": "GyhThchClFf3"
      },
      "id": "GyhThchClFf3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3393d402-895c-4188-9f06-eb4377b46ded",
      "metadata": {
        "id": "3393d402-895c-4188-9f06-eb4377b46ded"
      },
      "outputs": [],
      "source": [
        "x = X[N]\n",
        "y_fft = np.fft.fft(x)\n",
        "\n",
        "y_fft1 = y_fft.copy()\n",
        "y_fft2 = y_fft.copy()\n",
        "\n",
        "threshold = 32\n",
        "threshold = 64\n",
        "# threshold = 128\n",
        "# threshold = 512\n",
        "\n",
        "# ローパスフィルタ\n",
        "y_fft1.real[threshold:] = 0.\n",
        "y_fft1.imag[threshold:] = 0.\n",
        "\n",
        "# ハイパスフィルタ\n",
        "y_fft2.real[:threshold] = 0.\n",
        "y_fft2.imag[:threshold] = 0.\n",
        "# 直交成分を足し合わせる\n",
        "y_fft2.real[0] = y_fft.real[0]\n",
        "y_fft2.imag[0] = y_fft.imag[0]\n",
        "\n",
        "# 逆変換\n",
        "y_ifft1 = np.fft.ifft(y_fft1)\n",
        "y_ifft2 = np.fft.ifft(y_fft2)\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "\n",
        "#plt.plot(x, label='オリジナル')\n",
        "plt.plot(y_ifft2.real, label='ハイパスフィルタ')\n",
        "plt.plot(y_ifft1.real, label='ローパスフィルタ', lw=4)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01012e63-c634-4eab-aeb5-d5c6cc002823",
      "metadata": {
        "id": "01012e63-c634-4eab-aeb5-d5c6cc002823"
      },
      "outputs": [],
      "source": [
        "figs, axes = plt.subplots(1,2,figsize=(4,2))\n",
        "axes[0].imshow(y_ifft2.real.reshape(64,64),cmap='gray')\n",
        "axes[0].set_title('ハイパスフィルタ')\n",
        "axes[1].imshow(y_ifft1.real.reshape(64,64),cmap='gray')\n",
        "axes[1].set_title('ローパスフィルタ')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53434c1f-04e9-48e8-9f70-59b463a10253",
      "metadata": {
        "id": "53434c1f-04e9-48e8-9f70-59b463a10253"
      },
      "outputs": [],
      "source": [
        "# 2d fft\n",
        "y_fft2d = np.fft.fft2(x.reshape(64,64))\n",
        "\n",
        "# 逆変換\n",
        "y_ifft2d_1 = np.fft.ifft2(y_fft2d)\n",
        "#y_ifft2 = np.fft.fft2.ifft(y_fft2d)\n",
        "\n",
        "#np.set_printoptions(precision=3)\n",
        "plt.figure(figsize=(3,3))\n",
        "plt.imshow(y_ifft2d_1.real, cmap='gray') #.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a86af60b-0399-435d-b11d-1797f55e0379",
      "metadata": {
        "id": "a86af60b-0399-435d-b11d-1797f55e0379"
      },
      "outputs": [],
      "source": [
        "y_fft2d_1 = y_fft2d.copy()\n",
        "y_fft2d_2 = y_fft2d.copy()\n",
        "\n",
        "threshold = 32\n",
        "threshold = 64\n",
        "# threshold = 128\n",
        "#threshold = 1024\n",
        "\n",
        "# ローパスフィルタ\n",
        "y_fft2d_1.real[threshold:, threshold:] = 0.\n",
        "y_fft2d_1.imag[threshold:, threshold:] = 0.\n",
        "\n",
        "# ハイパスフィルタ\n",
        "y_fft2d_2.real[:threshold, :threshold] = 0.\n",
        "y_fft2d_2.imag[:threshold, :threshold] = 0.\n",
        "# 直交成分を足し合わせる\n",
        "y_fft2d_2.real[0,0] = y_fft2d.real[0,0]\n",
        "y_fft2d_2.imag[0,0] = y_fft2d.imag[0,0]\n",
        "\n",
        "# 逆変換\n",
        "y_ifft2d_1 = np.fft.ifft2(y_fft2d_1)\n",
        "y_ifft2d_2 = np.fft.ifft2(y_fft2d_2)\n",
        "\n",
        "figs, axes = plt.subplots(1,2,figsize=(4,2))\n",
        "axes[0].imshow(y_ifft2d_1.real.reshape(64,64),cmap='gray')\n",
        "axes[0].set_title('ハイパスフィルタ')\n",
        "axes[1].imshow(y_ifft2d_2.real.reshape(64,64),cmap='gray')\n",
        "axes[1].set_title('ローパスフィルタ')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f182fe3c-8354-40fd-920f-b5df80af9b66",
      "metadata": {
        "id": "f182fe3c-8354-40fd-920f-b5df80af9b66"
      },
      "outputs": [],
      "source": [
        "N = 4096 >> 0\n",
        "np.random.seed(42)\n",
        "epsilons = [np.random.randn() for _ in range(N+3)]\n",
        "\n",
        "theta0, theta1, theta2 = 1.0, 0.2, 0.5\n",
        "X = [(epsilons[i],epsilons[i+1], epsilons[i+2]) for i in range(N)]\n",
        "y = [theta0 * _x[2] + theta1 * _x[1] + theta2 * _x[0] for _x in X]\n",
        "#len(y), y[:5]\n",
        "plt.figure(figsize=(12,3))\n",
        "plt.title('データ')\n",
        "plt.plot(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "789da913-4506-4635-95ab-82e3e5f1f97e",
      "metadata": {
        "id": "789da913-4506-4635-95ab-82e3e5f1f97e"
      },
      "outputs": [],
      "source": [
        "len(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "417200b9-064a-4784-826b-4590a805877b",
      "metadata": {
        "id": "417200b9-064a-4784-826b-4590a805877b"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "import statsmodels\n",
        "print(f'statsmodels.__version__:{statsmodels.__version__}')\n",
        "model = ARIMA(y, order=(0, 0, 2))\n",
        "result = model.fit()\n",
        "print(result.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87fa6355-fa9c-4e82-aae8-3ac1a52745d1",
      "metadata": {
        "id": "87fa6355-fa9c-4e82-aae8-3ac1a52745d1"
      },
      "outputs": [],
      "source": [
        "predct = result.predict()\n",
        "\n",
        "# 残差 plot\n",
        "plt.figure(figsize=(20,5))\n",
        "plt.plot(result.resid)\n",
        "plt.axhline(0, color='red', linestyle='--')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01c6e5c5-5abd-46a8-ba27-1281eccf9b97",
      "metadata": {
        "id": "01c6e5c5-5abd-46a8-ba27-1281eccf9b97"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.stattools import pacf, acf\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "#len(y), len(pacf(y,lags=1))\n",
        "plot_acf(y, lags=100)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bfcd06a-26a1-4315-8ad6-f1e37cf3e583",
      "metadata": {
        "id": "1bfcd06a-26a1-4315-8ad6-f1e37cf3e583"
      },
      "outputs": [],
      "source": [
        "y = X[0]\n",
        "\n",
        "model = ARIMA(y, order=(1, 0, 1))\n",
        "result = model.fit()\n",
        "print(result.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2baaab8-3819-4650-ac06-34d7ff38d4aa",
      "metadata": {
        "id": "c2baaab8-3819-4650-ac06-34d7ff38d4aa"
      },
      "outputs": [],
      "source": [
        "X.shape\n",
        "x = X[0]\n",
        "# x.shape, zs.shape\n",
        "# print(zs[:10])\n",
        "# plt.plot(zs)\n",
        "# plt.plot(estimates)\n",
        "# plt.show()\n",
        "\n",
        "fig, axes = plt.subplots(1,2,figsize=(4,2))\n",
        "axes[0].set_title('KF estimates')\n",
        "axes[0].imshow(np.array(estimates).reshape(64,64), cmap='gray')\n",
        "axes[0].axis(False)\n",
        "axes[1].imshow(x.reshape(64,64), cmap='gray')\n",
        "axes[1].axis(False)\n",
        "axes[1].set_title('Original')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45ce0e03-d9a2-45a8-980d-3dac07bd1a3f",
      "metadata": {
        "id": "45ce0e03-d9a2-45a8-980d-3dac07bd1a3f"
      },
      "outputs": [],
      "source": [
        "#from filterpy.stats import gaussian\n",
        "X.shape\n",
        "N = 70\n",
        "zs = X[N]\n",
        "\n",
        "from collections import namedtuple\n",
        "gaussian = namedtuple('Gaussian', ['mean', 'var'])\n",
        "gaussian.__repr__ = lambda s: '𝒩(μ={:.3f}, 𝜎²={:.3f})'.format(s[0], s[1])\n",
        "\n",
        "def update(likelihood, prior):\n",
        "    posterior = likelihood * prior\n",
        "    return normalize(posterior)\n",
        "\n",
        "def update(prior, measurement):\n",
        "    x, P = prior        # 事前分布の平均と分散\n",
        "    z, R = measurement  # 観測値の平均と分散\n",
        "\n",
        "    y = z - x        # 残差\n",
        "    K = P / (P + R)  # カルマンゲイン\n",
        "\n",
        "    x = x + K*y      # 事後分布の平均\n",
        "    P = (1 - K) * P  # 事後分布の分散\n",
        "    return gaussian(x, P)\n",
        "\n",
        "def predict(posterior, movement):\n",
        "    x, P = posterior # 事後分布の平均と分散\n",
        "    dx, Q = movement # 移動量の平均と分散\n",
        "    x = x + dx\n",
        "    P = P + Q\n",
        "    return gaussian(x, P)\n",
        "\n",
        "voltage_std = .13\n",
        "x = gaussian(.5, 1.) # 初期状態\n",
        "process_var = 0.05**2\n",
        "#process_var = 1.**2\n",
        "process_model = gaussian(0., process_var)\n",
        "\n",
        "N = 50\n",
        "# zs = [volt(actual_voltage, voltage_std) for i in range(N)]\n",
        "ps = []\n",
        "estimates = []\n",
        "\n",
        "for z in zs:\n",
        "    prior = predict(x, process_model)\n",
        "    x = update(prior, gaussian(z, voltage_std**2))\n",
        "\n",
        "    # グラフにするために記録する\n",
        "    estimates.append(x.mean)\n",
        "    ps.append(x.var)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(14,3))\n",
        "plt.plot(zs, label='zs')\n",
        "plt.plot(estimates, label='estimates')\n",
        "plt.legend()\n",
        "#plt.ylim(16, 17)\n",
        "plt.show()\n",
        "\n",
        "plt.plot(ps)\n",
        "plt.title('Variance')\n",
        "print('Variance converges to {:.3f}'.format(ps[-1]))\n",
        "\n",
        "fig, axes = plt.subplots(1,2,figsize=(3,2))\n",
        "axes[0].set_title('KF estimates')\n",
        "axes[0].imshow(np.array(estimates).reshape(64,64), cmap='gray')\n",
        "axes[0].axis(False)\n",
        "axes[1].imshow(zs.reshape(64,64), cmap='gray')\n",
        "axes[1].axis(False)\n",
        "axes[1].set_title('Original')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3adcf1f9-fe39-44a9-a9e6-d4b091e61d70",
      "metadata": {
        "id": "3adcf1f9-fe39-44a9-a9e6-d4b091e61d70"
      },
      "outputs": [],
      "source": [
        "zs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a10a932-ea1a-416a-89d3-30dece958de8",
      "metadata": {
        "id": "4a10a932-ea1a-416a-89d3-30dece958de8"
      },
      "source": [
        "# 機械学習手法による顔認識\n",
        "\n",
        "## データの分割，訓練データとテストデータ\n",
        "\n",
        "データを 2 分割して，訓練データセットとテストデータセットに分割します。\n",
        "分割した訓練データセットでモデルのパラメータを学習し，しかる後に，テストデータセットで，その汎化性能を評価します。\n",
        "このとき，テストデータセットでの性能が高いモデルが良いモデルということになります。\n",
        "\n",
        "オリベッティ顔データセットには， 各被験者の 10 枚の顔画像が含まれています。\n",
        "このうち，例えば 90% を訓練データとし，10% をテストデータとして使用することを考えます。\n",
        "各顔データの訓練画像とテスト画像の数が同じになるように stratify 機能を使用してます。\n",
        "したがって，各被験者には 9 枚の訓練用画像と 1 枚のテスト用画像が用意されることになります。\n",
        "訓練データとテストデータの割合は split_ratio 変更することができます。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QM9GNboxBo3i",
      "metadata": {
        "id": "QM9GNboxBo3i"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "\n",
        "#from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "#split_ratio = 0.3 としているので，訓練データ対テストデータが 7:3 となる\n",
        "split_ratio = 0.3\n",
        "X_train, X_test, y_train, y_test=train_test_split(X, y_sex, test_size=split_ratio, stratify=y, random_state=42)\n",
        "#X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=split_ratio, stratify=y, random_state=42)\n",
        "print(f'X_train 訓練画像のサイズ: {X_train.shape}')\n",
        "print(f'y_train 教師信号データのサイズ: {y_train.shape}')\n",
        "\n",
        "print(f'X_test 検証画像のサイズ: {X_test.shape}')\n",
        "print(f'y_test 教師信号データのサイズ: {y_test.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "keMwxtpHz94M",
      "metadata": {
        "id": "keMwxtpHz94M"
      },
      "source": [
        "## ロジスティック回帰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1a30yIeCGRP",
      "metadata": {
        "id": "e1a30yIeCGRP"
      },
      "outputs": [],
      "source": [
        "params = {'max_iter':10 ** 3,\n",
        "          'C':1e3,\n",
        "          #'penalty':'l2'\n",
        "         }\n",
        "\n",
        "model = LogisticRegression(**params)\n",
        "model.fit(X_train, y_train)    # 訓練データを用いて線形判別分析モデルを訓練\\n\",\n",
        "y_hat = model.predict(X_test)  # テストデータを使って予測を行い結果を y_hat に格納\\n\",\n",
        "print(f\"ロジスティック回帰を用いた分類精度: {metrics.accuracy_score(y_test, y_hat):.3f}\")\n",
        "print(f'分類報告:\\n{metrics.classification_report(y_test,y_hat)}')\n",
        "\n",
        "# 混同行列の表示\n",
        "print('混同行列:\\n', metrics.confusion_matrix(y_test,y_hat))\n",
        "# plt.figure(figsize=(8,6))\n",
        "# sns.heatmap(metrics.confusion_matrix(y_test, y_hat))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "X_OmJduo0NAE",
      "metadata": {
        "id": "X_OmJduo0NAE"
      },
      "source": [
        "## 線形判別分析\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "i1zDPV2ABuKl",
      "metadata": {
        "id": "i1zDPV2ABuKl"
      },
      "outputs": [],
      "source": [
        "params = {#'max_iter':10 ** 3,\n",
        "          #'C':1e3,\n",
        "          #'penalty':'l2'\n",
        "         }\n",
        "\n",
        "model = LinearDiscriminantAnalysis(**params)\n",
        "model.fit(X_train, y_train)    # 訓練データを用いて線形判別分析モデルを訓練\n",
        "y_hat = model.predict(X_test)  # テストデータを使って予測を行い結果を y_hat に格納\n",
        "print(f\"線形判別分析を用いた分類精度: {metrics.accuracy_score(y_test, y_hat):.3f}\")\n",
        "print(f'分類報告:\\n{metrics.classification_report(y_test,y_hat)}')\n",
        "\n",
        "# 混同行列の表示\n",
        "print('混同行列:\\n', metrics.confusion_matrix(y_test,y_hat))\n",
        "# plt.figure(figsize=(8,6))\n",
        "# sns.heatmap(metrics.confusion_matrix(y_test, y_hat))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tnBPgcEa0WG_",
      "metadata": {
        "id": "tnBPgcEa0WG_"
      },
      "source": [
        "## サポートベクターマシン\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xTig2ErwBxZU",
      "metadata": {
        "id": "xTig2ErwBxZU"
      },
      "outputs": [],
      "source": [
        "params = {'max_iter':10 ** 3,\n",
        "          'C':1e3,\n",
        "          #'penalty':'l2'\n",
        "         }\n",
        "\n",
        "model = SVC(**params)\n",
        "model.fit(X_train, y_train)    # 訓練データを用いて線形判別分析モデルを訓練\n",
        "y_hat = model.predict(X_test)  # テストデータを使って予測を行い結果を y_hat に格納\n",
        "print(f\"サポートベクターマシン用いた分類精度: {metrics.accuracy_score(y_test, y_hat):.3f}\")\n",
        "print(f'分類報告:\\n{metrics.classification_report(y_test,y_hat)}')\n",
        "# print(f'適合率 precision score:{metrics.precision_score(y_test, y_hat):.3f}')\n",
        "# print(f'再現率 recall  score  :{metrics.recall_score(y_test, y_hat):.3f}')\n",
        "# print(f'F1 値  F1 score       :{metrics.f1_score(y_test, y_hat):.3f}')\n",
        "\n",
        "# 混同行列の表示\n",
        "print('混同行列:\\n', metrics.confusion_matrix(y_test,y_hat))\n",
        "# plt.figure(figsize=(8,6))\n",
        "# sns.heatmap(metrics.confusion_matrix(y_test, y_hat))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gom1BG_v0f-J",
      "metadata": {
        "id": "gom1BG_v0f-J"
      },
      "source": [
        "## 3 手法比較\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CYVUL4ik0jcA",
      "metadata": {
        "id": "CYVUL4ik0jcA"
      },
      "outputs": [],
      "source": [
        "# 40 名の顔認識データをもちいて 3 手法を比較\n",
        "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=split_ratio, stratify=y, random_state=42)\n",
        "\n",
        "# 共通パラメータ\n",
        "params = {'max_iter':10 ** 4,\n",
        "          #'C':1e3,\n",
        "          #'penalty':'l2'\n",
        "         }\n",
        "\n",
        "# 3 つのモデルの定義\n",
        "svc_model = SVC(**params)\n",
        "logistic_model = LogisticRegression(**params)\n",
        "lda_model = LinearDiscriminantAnalysis()\n",
        "\n",
        "# 出力する図のサイズを定義\n",
        "fig, _axes = plt.subplots(ncols=3, nrows=1, figsize=(12,4), constrained_layout=True)\n",
        "\n",
        "# 3 つのモデルをそれぞれ実行して結果を描画\n",
        "for i, (model_name, model) in enumerate([('サポートベクタマシン',svc_model),\n",
        "                                         ('ロジスティック回帰',logistic_model),\n",
        "                                         ('線形判別分析',lda_model)]):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_hat = model.predict(X_test)\n",
        "    y_hat = model.predict(X_test)  # テストデータを使って予測を行い結果を y_hat に格納\n",
        "\n",
        "    _axes[i].imshow(metrics.confusion_matrix(y_test,y_hat), cmap='gray')\n",
        "    _axes[i].set_title(f'{model_name}:分類精度:{metrics.accuracy_score(y_test,y_hat):.2f}')\n",
        "    _axes[i].axis('off')\n",
        "    print(f'分類報告:\\n{metrics.classification_report(y_test,y_hat)}')\n",
        "    # print(f'適合率 precision score:{metrics.precision_score(y_test, y_hat, average='macro'):.3f}')\n",
        "    # print(f'再現率 recall  score  :{metrics.recall_score(y_test, y_hat, average='macro'):.3f}')\n",
        "    # print(f'F1 値  F1 score       :{metrics.f1_score(y_test, y_hat, average='macro'):.3f}')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1z4Bwuo9aTEO",
      "metadata": {
        "id": "1z4Bwuo9aTEO"
      },
      "source": [
        "## リーブ・ワン・アウト 交差検証\n",
        "\n",
        "オリベッティ顔データセットには，各被験者に対して 10 枚の顔画像が含まれています。\n",
        "これは， 機械学習モデルの学習やテストには少ない数です。\n",
        "\n",
        "クラスの例が少ない機械学習モデルをよりよく評価するために，採用される交差検証法にリーブ・ワン・アウト leave-one-out (LOO) 交差検証法があります。\n",
        "LOO 法では，あるクラスのサンプルのうち 1 つだけをテストに使用します。\n",
        "他のサンプルは訓練に使用します。 この手順を， 全サンプルを一度づつテストに使用して繰り返さします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b408wi0faU0V",
      "metadata": {
        "id": "b408wi0faU0V"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "loo_cv = LeaveOneOut()\n",
        "model = LogisticRegression(**params)\n",
        "cv_scores = cross_val_score(model, X_train, y_train, cv=loo_cv)\n",
        "\n",
        "print(f\"{model.__class__.__name__} リーブ・ワン・アウト交差検証法による平均得点:{cv_scores.mean():.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hNCGjJ6FHCft",
      "metadata": {
        "id": "hNCGjJ6FHCft"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# シグモイド関数の描画\n",
        "# logits = [_x/(1.-_x) for _x in x]\n",
        "# plt.plot(x, logits)\n",
        "# plt.show()\n",
        "\n",
        "# plt.plot(x, np.log(logits))\n",
        "# plt.show()\n",
        "\n",
        "# x = np.arange(-10, 10, 0.01)\n",
        "# sigmoids = [1./(1.+np.exp(-_x)) for _x in x]\n",
        "# plt.plot(x, sigmoids)\n",
        "# plt.show()\n",
        "\n",
        "# x = np.arange(-10, 10, 0.01)\n",
        "# sigmoids = [1./(1.+np.exp(-_x)) for _x in x]\n",
        "# plt.plot(x, sigmoids, label=\"sigmoid\", c='red')\n",
        "# plt.plot(x, np.tanh(x), label=\"tanh\", c='green')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "701b9057-1abd-478f-9e17-5a30b7b0ce20",
      "metadata": {
        "id": "701b9057-1abd-478f-9e17-5a30b7b0ce20"
      },
      "source": [
        "## 交差検証"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8e27bda-c885-4f53-a236-c444d77e2f44",
      "metadata": {
        "id": "d8e27bda-c885-4f53-a236-c444d77e2f44"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "name = 'ロジスティック回帰'\n",
        "model = LogisticRegression(**params)\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores = cross_val_score(model, X_train, y_train, cv=kfold)\n",
        "print(f\"{name} 平均交差検証得点: {cv_scores.mean():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca8819b8-db47-44db-b5e8-fc2fa3dd79e6",
      "metadata": {
        "id": "ca8819b8-db47-44db-b5e8-fc2fa3dd79e6"
      },
      "source": [
        "## ハイパーパラメータの調整: GridSearcCV\n",
        "\n",
        "モデルの汎化性能向上のために GridSearchCV を行います。\n",
        "ロジスティック回帰分類器のハイパーパラメータを調整してみます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6952b8de-87a5-4c4d-afac-2c411e7c6bf0",
      "metadata": {
        "id": "6952b8de-87a5-4c4d-afac-2c411e7c6bf0"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "params2={'penalty':['l1', 'l2'],\n",
        "        'C':np.logspace(0, 4, 10),\n",
        "        'max_iter': [10 ** 4],\n",
        "       }\n",
        "model = LogisticRegression()\n",
        "loo_cv = LeaveOneOut()\n",
        "gridSearchCV = GridSearchCV(model, params2, cv=loo_cv)\n",
        "gridSearchCV.fit(X_train, y_train)\n",
        "print(\"Grid search fitted..\")\n",
        "print(gridSearchCV.best_params_)\n",
        "print(gridSearchCV.best_score_)\n",
        "print(f\"グリッドサーチによる交差妥当性得点:{gridSearchCV.score(X_test, y_test):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_8TrzyS6IYqj",
      "metadata": {
        "id": "_8TrzyS6IYqj"
      },
      "source": [
        "# PCA 固有顔 Eigenfaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Z60qpsFHIdKT",
      "metadata": {
        "id": "Z60qpsFHIdKT"
      },
      "outputs": [],
      "source": [
        "# X を n 行 m 列の行列として，列方向 m x m の相関係数行列を求める\n",
        "# すなわち各画素ごとの相関係数行列を計算する\n",
        "# オリベッティ顔データの場合 64 x 64 = 4096 画素分のデータなので,相関係数行列は 4096 x 4096 の大きさとなる\n",
        "#np.set_printoptions(precision=3)\n",
        "np.set_printoptions(formatter={'float': '{:.2f}'.format})\n",
        "\n",
        "x_mean = np.mean(X, axis=0)   # 各列の平均値を計算\n",
        "_X = X - x_mean               # 各列の平均値を減じて平均偏差ベクトルとする\n",
        "Cov = _X.T @ _X / _X.shape[0] # 共分散行列\n",
        "_X_std = np.std(_X, axis=0)     # 各列の標準偏差\n",
        "R = Cov / np.outer(_X_std.T, _X_std) # 共分散行列の各列を対応する標準偏差の積で除して相関係数行列にする\n",
        "print(f'R.shape:{R.shape}')        # 確認用 相関係数行列のサイズ\n",
        "print(f'相関係数行列 R:\\n{R[8:15,8:15]}')           # 確認用 相関係数行列の最初の 3 行 3 列を表示する\n",
        "\n",
        "R2 = np.corrcoef(X.T)              # 上記を一行で行う numpy コマンド\n",
        "print(f'相関係数行列 R2:\\n{R2[8:15,8:15]}')         # 結果の表示"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QXLGyHa8IfjA",
      "metadata": {
        "id": "QXLGyHa8IfjA"
      },
      "outputs": [],
      "source": [
        "# 上セルとは異なりデータ行列 X (n 行 m 列) の行方向 n x n の相関係数行列を求める\n",
        "# この場合 400 画像 x 400 画像 (400 は 40 人分の画像で各人 10 枚の画像)\n",
        "import seaborn as sns  # ヒートマップ描画のために使用\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(np.corrcoef(X), center=0, vmin=-1., vmax=1., square=True, cmap='gnuplot2')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OTfzM0YmIhzc",
      "metadata": {
        "id": "OTfzM0YmIhzc"
      },
      "outputs": [],
      "source": [
        "# 平均画像を描画\n",
        "x_mean = np.mean(X, axis=0)   # 各列の平均値を計算\n",
        "print(f'x_mean.min():{x_mean.min():.2f}',\n",
        "      f'x_mean.max():{x_mean.max():.2f}')\n",
        "#print(X.min(), X.max())\n",
        "plt.figure(figsize=(2.5,2.5))\n",
        "plt.title(f'平均顔, 最小値:{x_mean.min():.2f}, 最大値:{x_mean.max():.2f}')\n",
        "plt.imshow(x_mean.reshape(64,64), cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8UjDln-yIj8d",
      "metadata": {
        "id": "8UjDln-yIj8d"
      },
      "outputs": [],
      "source": [
        "# いくつかの画像に対して，平均顔からの差分を画像化して表示してみる\n",
        "idxes = [0, 10, 20, 30, 40, 50, 60, 70, 80]\n",
        "fig, axes = plt.subplots(nrows=1, ncols=len(idxes), figsize=(len(idxes) * 1.2, 1.5))\n",
        "for i in range(0,len(idxes),1):\n",
        "    idx = idxes[i]\n",
        "    #print(f'idx:{idx}')\n",
        "    axes[i].imshow((X[idx] - x_mean).reshape(64,64), cmap='gray')\n",
        "    axes[i].set_title(f'idx:{idx}')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OWCmA5hSIo6k",
      "metadata": {
        "id": "OWCmA5hSIo6k"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "class PCA():\n",
        "    def __init__(self, X:np.array, n_dim:int=500):\n",
        "        self.X = X\n",
        "\n",
        "        N, M = X.shape\n",
        "        if N < M:\n",
        "            self.n_dim = N\n",
        "        else:\n",
        "            self.n_dim = M\n",
        "\n",
        "        if self.n_dim > n_dim:\n",
        "            self.n_dim = n_dim\n",
        "        self.mean = np.mean(X, axis=0)          # 行列 X の各列ごとの平均を求める\n",
        "        self._X = X - self.mean                 # 各列ごとの平均を引いた 平均偏差行列 _X\n",
        "        self.Corr = np.dot(self._X.T, self._X)  # 各列ごとの分散共分散行列 Corr\n",
        "        self.Eigenvalues, self.Eigenvectors = np.linalg.eig(self.Corr)  # 固有値問題を解く\n",
        "\n",
        "        self.Eigenvalues = self.Eigenvalues[0:self.n_dim].copy()\n",
        "        self.Eigenvectors = self.Eigenvectors[:,0:self.n_dim].copy()\n",
        "        self.projections = np.dot(self._X, self.Eigenvectors)\n",
        "\n",
        "    def _reconstruct(self, start:int=0, end:int=10):\n",
        "        return np.dot(self.projections[:,start:end], self.Eigenvectors[:,start:end].T) + self.mean\n",
        "\n",
        "\n",
        "_PCA = PCA(X=X)\n",
        "Eigenvalues, Eigenvectors, mean = _PCA.Eigenvalues, _PCA.Eigenvectors, _PCA.mean\n",
        "print(f'Eigenvalues.shape:{Eigenvalues.shape}',\n",
        "      f'\\nEigenvectors.shape:{Eigenvectors.shape}',\n",
        "      f'\\nmean.shape:{mean.shape}')\n",
        "\n",
        "plt.figure(figsize=(2,2))\n",
        "plt.title('平均顔')\n",
        "plt.imshow(mean.reshape(64,64), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tW6rgJ1AayMm",
      "metadata": {
        "id": "tW6rgJ1AayMm"
      },
      "outputs": [],
      "source": [
        "# いくつかの画像に対して，平均顔からの差分を画像化して表示してみる\n",
        "idxes = [0, 10, 20, 30, 40, 50, 60, 70, 80]\n",
        "n_idx = 12\n",
        "idxes = sorted(np.random.permutation(np.arange(X.shape[0]))[:n_idx])\n",
        "fig, axes = plt.subplots(nrows=1, ncols=len(idxes), figsize=(len(idxes) * 1.2, 1.5))\n",
        "for i in range(0,len(idxes),1):\n",
        "    idx = idxes[i]\n",
        "    #print(f'idx:{idx}')\n",
        "    axes[i].imshow((X[idx] - x_mean).reshape(64,64), cmap='gray')\n",
        "    axes[i].set_title(f'idx:{idx}', size=8)\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.suptitle('いくつかの画像に対して，平均顔からの差分を画像化', size=10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "v397odVca3Nh",
      "metadata": {
        "id": "v397odVca3Nh"
      },
      "source": [
        "## 固有値のプロット (降順)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Hy9T4qNka5Zs",
      "metadata": {
        "id": "Hy9T4qNka5Zs"
      },
      "outputs": [],
      "source": [
        "# 大きい方から上位 N 個の固有値をプロットしてみる\n",
        "N = 200\n",
        "plt.plot(Eigenvalues[:N])\n",
        "plt.title(f'固有値のプロット: max:{_PCA.n_dim}')\n",
        "\n",
        "\n",
        "N_pca = 10\n",
        "fix, axes = plt.subplots(nrows=1, ncols=N_pca, figsize=(N_pca * 1.4, 1.4))\n",
        "for i in range(N_pca):\n",
        "    axes[i].imshow(_PCA.Eigenvectors[:,i].reshape(64,64), cmap=\"gray\")\n",
        "    axes[i].set_title(f'第 {i+1} 固有値に対応\\nする固有ベクトル', size=7)\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "j5H07ld6bJ89",
      "metadata": {
        "id": "j5H07ld6bJ89"
      },
      "source": [
        "## 固有ベクトルの相関係数行列を可視化\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lPLgr3S5bMXd",
      "metadata": {
        "id": "lPLgr3S5bMXd"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(np.corrcoef(_PCA.Eigenvectors.T)[:400,:400], center=0, vmin=-1., vmax=1., square=True, cmap='gnuplot2')\n",
        "plt.title('固有ベクトルの相関係数行列を可視化')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "478fe75c-d353-4877-8c12-8776a5f0c3c7",
      "metadata": {
        "id": "478fe75c-d353-4877-8c12-8776a5f0c3c7"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(_PCA.Eigenvectors.T @ _PCA.Eigenvectors, center=0, vmin=-1., vmax=1., square=True, cmap='gnuplot2')\n",
        "plt.title('固有ベクトルの積を可視化')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2211703-9e22-42cb-8d37-1371b3f446c6",
      "metadata": {
        "id": "b2211703-9e22-42cb-8d37-1371b3f446c6"
      },
      "outputs": [],
      "source": [
        "print('固有値は各行ごとに正規化されている。かつ，各固有値は直交している。すなわち対角要素が 1 で非対角要素は 0 である')\n",
        "print((_PCA.Eigenvectors.T @ _PCA.Eigenvectors)[:5,:5])\n",
        "\n",
        "print('固有値は各列ごとではない。その証拠に列ごとに計算してみると以下のようになる')\n",
        "print((_PCA.Eigenvectors @ _PCA.Eigenvectors.T)[:5,:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_Soz_jNBbYq8",
      "metadata": {
        "id": "_Soz_jNBbYq8"
      },
      "source": [
        "## PCA による次元圧縮の結果を表示\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NdAvqkHJIrR-",
      "metadata": {
        "id": "NdAvqkHJIrR-"
      },
      "outputs": [],
      "source": [
        "# PCA による次元圧縮の結果を表示\n",
        "\n",
        "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(14,4))\n",
        "axes[0].scatter(_PCA.projections[:,0], _PCA.projections[:,1], s=1)\n",
        "axes[0].set_xlabel('第 1 主成分')\n",
        "axes[0].set_ylabel('第 2 主成分')\n",
        "for i in range(_PCA.projections.shape[0]):\n",
        "    axes[0].annotate(str(y[i]), (_PCA.projections[i,0], _PCA.projections[i,1]))\n",
        "\n",
        "axes[1].scatter(_PCA.projections[:,1], _PCA.projections[:,2], s=1)\n",
        "axes[1].set_xlabel('第 2 主成分')\n",
        "axes[1].set_ylabel('第 3 主成分')\n",
        "for i in range(_PCA.projections.shape[0]):\n",
        "    axes[1].annotate(str(y[i]), (_PCA.projections[i,1], _PCA.projections[i,2]))\n",
        "\n",
        "axes[2].scatter(_PCA.projections[:,0], _PCA.projections[:,3], s=1)\n",
        "axes[2].set_xlabel('第 1 主成分')\n",
        "axes[2].set_ylabel('第 4 主成分')\n",
        "for i in range(_PCA.projections.shape[0]):\n",
        "    axes[2].annotate(str(y[i]), (_PCA.projections[i,0], _PCA.projections[i,3]))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GC82DIa6be_A",
      "metadata": {
        "id": "GC82DIa6be_A"
      },
      "source": [
        "## PCA による固有顔の再構成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pM6gioH1bgfZ",
      "metadata": {
        "id": "pM6gioH1bgfZ"
      },
      "outputs": [],
      "source": [
        "# 表示する画像番号リストを idexes で宣言\n",
        "idxes = [0, 10, 20, 40, 60, 70]\n",
        "idxes = [70, 71, 72, 73, 74, 75]\n",
        "\n",
        "# 乱数を発生させて n_idx 個のデータ画像をランダムに選んで idxes に格納する\n",
        "n_idx = 10\n",
        "idxes = sorted(np.random.permutation(np.arange(X.shape[0]))[:n_idx])\n",
        "\n",
        "# PCA による画像の再構成時に何個の固有ベクトルを重ねるを指定するリスト ends\n",
        "ends = [1, 10, 20, 40, 80, 160, 320]\n",
        "ends = [1, 10, 20, 30, 40, 50, 100, 150, 200, 250, 300]\n",
        "\n",
        "# 表示する画像サイズの宣言 figsize の幅と高さを指定,単位は歴史的経緯からインチ\n",
        "fig, axes = plt.subplots(nrows=len(idxes), ncols=len(ends), figsize=(1.4 * len(ends), 1.6 * len(idxes)))\n",
        "for i, idx in enumerate(idxes):\n",
        "    for j, end in enumerate(ends):\n",
        "        axes[i][j].axis('off')\n",
        "        if j == 0:\n",
        "            axes[i][j].set_title(f'画像番号:{idx}')\n",
        "        else:\n",
        "            axes[i][j].set_title(f'{end} 次元まで')\n",
        "        axes[i][j].imshow((_PCA.projections[idx,0:end] @ _PCA.Eigenvectors[:,0:end].T + _PCA.mean).reshape(64,64), cmap='gray')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wsBJNZHPbj1v",
      "metadata": {
        "id": "wsBJNZHPbj1v"
      },
      "source": [
        "## 固有顔 (PCA) を用いた分類"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MYuE8TJWbkmQ",
      "metadata": {
        "id": "MYuE8TJWbkmQ"
      },
      "outputs": [],
      "source": [
        "# 固有顔 (PCA) を用いて 40 名の顔認識データをもちいて 3 手法を比較\n",
        "X_train, X_test, y_train, y_test=train_test_split(_PCA.projections, y, test_size=split_ratio, stratify=y, random_state=42)\n",
        "#X_train, X_test, y_train, y_test=train_test_split(_PCA.projections, y_sex, test_size=split_ratio, stratify=y, random_state=42)\n",
        "\n",
        "# 共通パラメータ\n",
        "params = {'max_iter':10 ** 4,\n",
        "          #'C':1e3,\n",
        "          #'penalty':'l2'\n",
        "         }\n",
        "\n",
        "# 3 つのモデルの定義\n",
        "svc_model = SVC(**params)\n",
        "logistic_model = LogisticRegression(**params)\n",
        "lda_model = LinearDiscriminantAnalysis()\n",
        "\n",
        "# 出力する図のサイズを定義\n",
        "fig, _axes = plt.subplots(ncols=3, nrows=1, figsize=(12,4), constrained_layout=True)\n",
        "\n",
        "# 3 つのモデルをそれぞれ実行して結果を描画\n",
        "for i, (model_name, model) in enumerate([('サポートベクタマシン',svc_model),\n",
        "                                         ('ロジスティック回帰',logistic_model),\n",
        "                                         ('線形判別分析',lda_model)]):\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_hat = model.predict(X_test)  # テストデータを使って予測を行い結果を y_hat に格納\n",
        "\n",
        "    _axes[i].imshow(metrics.confusion_matrix(y_test,y_hat), cmap='gray')\n",
        "    _axes[i].set_title(f'{model_name}:分類精度:{metrics.accuracy_score(y_test,y_hat):.2f}')\n",
        "    _axes[i].axis('off')\n",
        "\n",
        "    print(model_name, '\\n', metrics.confusion_matrix(y_test,y_hat))\n",
        "    print(model_name, '\\n', metrics.classification_report(y_test,y_hat))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wP9bW8YMbpeJ",
      "metadata": {
        "id": "wP9bW8YMbpeJ"
      },
      "source": [
        "## tSNE によるプロット"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "okTvz_DpbrFQ",
      "metadata": {
        "id": "okTvz_DpbrFQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "X_tsne = TSNE(n_components=2, learning_rate='auto',\n",
        "              init='random', perplexity=3).fit_transform(X)\n",
        "\n",
        "PCA_tsne = TSNE(n_components=2, learning_rate='auto',\n",
        "              init='random', perplexity=3).fit_transform(_PCA.projections)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "t45EfhY4byMB",
      "metadata": {
        "id": "t45EfhY4byMB"
      },
      "outputs": [],
      "source": [
        "#plt.figure(figsize=(12,6))\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,6))\n",
        "\n",
        "axes[0].scatter(X_tsne[:,0], X_tsne[:,1], s=1)\n",
        "for i in range(X_tsne.shape[0]):\n",
        "    axes[0].annotate(str(y[i]), (X_tsne[i,0], X_tsne[i,1]))\n",
        "axes[0].set_title('tSNE プロット')\n",
        "\n",
        "axes[1].scatter(PCA_tsne[:,0], PCA_tsne[:,1], s=1)\n",
        "for i in range(PCA_tsne.shape[0]):\n",
        "    axes[1].annotate(str(y[i]), (X_tsne[i,0], X_tsne[i,1]))\n",
        "axes[1].set_title('tSNE プロット')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RdAMVKdQb145",
      "metadata": {
        "id": "RdAMVKdQb145"
      },
      "source": [
        "# フィッシャー顔 Fisherfaces\n",
        "\n",
        "線形判別分析は、R.A.フィッシャー 卿によって発明された。\n",
        "フィッシャーは 1936 年の論文 \"The use of multiple measurements in classificationonomic problems\" の中で、アヤメの分類に用いることに成功した。\n",
        "<!-- しかし、主成分分析 (PCA) がこれほどうまくいったのに、なぜ別の次元削減法が必要なのだろうか？-->\n",
        "PCA はデータの全分散を最大化する特徴の線形結合を見つける。\n",
        "これは強力な方法だが、クラスを考慮しないため、成分を捨てるときに多くの識別情報が失われる可能性がある。\n",
        "分散が外部ソースによって生成される状況を想像してみよう。\n",
        "PCA によって同定された成分は、必ずしも識別情報を全く含まないので、投影されたサンプルは互いに混ざり合い、分類は不可能になる。\n",
        "クラス間を最もよく分離する特徴の組み合わせを見つけるために、線形判別分析はクラス間のばらつきとクラス内のばらつきの比率を最大化する。\n",
        "考え方は単純で、同じクラスは互いに密に集まり、異なるクラスはできるだけ離れるべきである。\n",
        "このことは Belhumeur_Hespanha_Kriegman も認識しており、彼らは [3] で顔認識に判別分析を適用した。\n",
        "<!-- The Linear Discriminant Analysis was invented by the great statistician Sir R. A. Fisher, who successfully used it for classifying owers in his 1936 paper The use of multiple measurements in taxonomic problems [8].\n",
        "But why do we need another dimensionality reduction method, if the Principal Component Analysis (PCA) did such a good job?\n",
        "The PCA  finds a linear combination of features that maximizes the total variance in data.\n",
        "While this is clearly a powerful way to represuccsent data, it doesn't consider any classes and so a lot of discriminative information may be lost when throwing components away.\n",
        "Imagine a situation where the variance is generated by an external source, let it be the light.\n",
        "The components identified by a PCA do not necessarily contain any discriminative information at all, so the projected samples are smeared together and a classification becomes impossible.\n",
        "In order to  nd the combination of features that separates best between classes the Linear Discriminant Analysis maximizes the ratio of between-classes to within-classes scatter.\n",
        "The idea is simple: same classes should cluster tightly together, while different classes are as far away as possible from each other.\n",
        "This was also recognized by Belhumeur, Hespanha and Kriegman and so they applied a Discriminant Analysis to face recognition in [3]. -->\n",
        "\n",
        "* [3] Belhumeur, P. N., Hespanha, J., and Kriegman, D. Eigenfaces vs. Fisherfaces: Recognition using class specific linear projection. IEEE Transactions on Pattern Analysis and Machine Intelligence 19, 7 (1997), 711-720.\n",
        "* [4] Brunelli, R., and Poggio, T. Face recognition through geometrical features. In European Conference on Computer Vision (ECCV) (1992), pp. 792-800.\n",
        "* [5] Cardinaux, F., Sanderson, C., and Bengio, S. User authentication via adapted statistical models of face images. IEEE Transactions on Signal Processing 54 (January 2006), 361-373.\n",
        "* [6] Chiara Turati, Viola Macchi Cassia, F. S., and Leo, I. Newborns face recognition: Role of inner and outer facial features. Child Development 77, 2 (2006), 297-311.\n",
        "* [7] Duda, R. O., Hart, P. E., and Stork, D. G. Pattern Classification (2nd Edition), 2 ed. November 2001.\n",
        "* [8] Fisher, R. A. The use of multiple measurements in taxonomic problems. Annals Eugen. 7 (1936), 179-188.\n",
        "\n",
        "### アルゴリズムの説明\n",
        "<!--2.3.1 Algorithmic Description-->\n",
        "\n",
        "$X$ を $c$ 個のクラスから抽出したランダムベクトルとする：\n",
        "<!--Let $X$ be a random vector with samples drawn from c classes: -->\n",
        "$$\\tag{8}\n",
        "X = \\left\\{X_1,X_2,\\ldots,X_{c}\\right\\}\n",
        "$$\n",
        "$$\\tag{9}\n",
        "X_i = \\left\\{x_1, x_2,\\ldots, x_{n}\\right\\}\n",
        "$$\n",
        "\n",
        "分散行列 $S_B$ (級間分散) と $S_W$ (級内分散) は次式のように定義される：\n",
        "<!-- The scatter matrices $S_B$ and $S_W$ are defined as: -->\n",
        "$$\\tag{10}\n",
        "S_B = \\sum_{i=1}^{c} N_i (\\mu_i - \\mu)(\\mu_i - \\mu)^{\\top},\n",
        "$$\n",
        "$$\\tag{11}\n",
        "S_W = \\sum_{i=1}^{c} \\sum_{x \\in X_i} (x - \\mu_i)(x - \\mu_i)^{\\top},\n",
        "$$\n",
        "ここで $\\mu$ は全平均:<!--where $\\mu$ is the total mean:-->\n",
        "$$\\tag{12}\n",
        "\\mu = \\frac{1}{N} \\sum_{i=1}^{N} x_i,\n",
        "$$\n",
        "さらに $\\mu_i$ は群内平均:<!--And $\\mu_i$ is the mean of class $i\\in\\left\\{1,\\ldots,C\\right\\}$:-->\n",
        "$$\\tag{13}\n",
        "\\mu_i = \\frac{1}{\\left|X_i\\right|} \\sum_{x_{j} \\in X_{i}} x_{j}.\n",
        "$$\n",
        "フィッシャーの古典的アルゴリズムは、クラス分離可能性基準を最大化する射影行列 $W$ を探す：\n",
        "<!-- Fisher's classic algorithm now looks for a projection matrix $W$, that maximizes the class separability criterion: -->\n",
        "$$\\tag{14}\n",
        "W_{opt}=\\arg\\max_{W} \\frac{\\left|W^{\\top} S_B W\\right|}{\\left|W^{\\top} S_W W\\right|},\n",
        "$$\n",
        "[3] に従って、この最適化問題の解は、一般固有値問題を解くことによって与えられる：\n",
        "<!-- Following[3], a solution for this optimization problem is given by solving the Genral Eigenvalue Problem: -->\n",
        "$$\\tag{15}\\begin{aligned}\n",
        "S_{B}\\nu_i &= \\lambda_i S_{W}\\nu_i,\\\\\n",
        "S_{W}^{-1} S_{B} \\nu_i &= \\lambda_i \\nu_i,\n",
        "\\end{aligned}$$\n",
        "\n",
        "解決すべき問題が 1 つ残っている：\n",
        "$S_W$ のランクは最大でも $(N-c)$ であり，$N$ 個のサンプルと $c$ 個のクラスが存在する。\n",
        "パターン認識問題では，サンプル数 $N$ は入力データの次元 (画素数) より小さいことがほとんどなので，分散行列 $S_W$ は特異行列になる ([2]を参照)。\n",
        "[3] では、データに対して主成分分析を実行し、サンプルを (N-c) 次元空間に射影することでこれを解決した。\n",
        "$S_W$ が特異でなくなったので、線形判別分析が縮小データに対して実行される。\n",
        "最適化問題は次のように書き換えられる:\n",
        "<!-- There's one problem left to solve:\n",
        "The rank of S_W is at most (N-c), with N samples and c classes.\n",
        "In pattern recognition problems the number of samples N is almost always smaller than the dimension of the input data (the number of pixels), so the scatter matrix SW becomes singular (see [2]).\n",
        "In [3] this was solved by performing a Principal Component Analysis on the data and projecting the samples int the (N-c)-dimensional space.\n",
        "A Linear Discriminant Analysis is then performed on the reduced data, because S_W is not singular anymore.\n",
        "The optimization problem is can be rewritten as: -->\n",
        "$$\\tag{16}\n",
        "W_{pca}=\\arg\\max_{W} \\left|W^{\\top} S_T W\\right|\n",
        "$$\n",
        "\n",
        "$$\\tag{17}\n",
        "W_{fld} = \\arg\\max_W \\frac{\\left|W^{\\top} W_{pca}^{\\top} S_B W_{pca}W\\right|}{\\left|W^{\\top} W_{pca}^{\\top}S_W W_{pca}W\\right|},\n",
        "$$\n",
        "サンプルを (c-1) 次元空間に投影する変換行列 $W$ は次のように与えられる：\n",
        "<!-- The transformation matrix $W$, that projects a sample into the (c-1)-dimensional space is then given by:-->\n",
        "$$\\tag{18}\n",
        "W = W_{fld}^{\\top}W_{pca}^{\\top}.\n",
        "$$\n",
        "\n",
        "最後に注意点：\n",
        "$S_W$ と $S_B$ とは対称行列であるが，対称行列同士の積は必ずしも対称ではないので，一般行列用の固有値ソルバを使う必要がある。\n",
        "OpenCV の `cv:eigen` は，現在のバージョンでは対称行列に対してのみ動作する。\n",
        "非対称行列に対しては，特異値の固有値は等価ではないので，特異値分解（SVD）ソルバーを利用することはできない．\n",
        "<!-- one final note:\n",
        "Although $S_W$ and $S_B$ are symmetric matrices, the product of two symmetric matrices is not necessarily symmetric; thus, so you have to use an eigenvalue solver for general matrices.\n",
        "OpenCV's `cv:eigen` only works for symmetric matrices in it scurrent version; since eigenvlues of singular values are not equivalent for non-symmetric matrices you can not use a Singular Value Decomposition (SVD) eigher. -->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44a8c08d-0222-45e7-ac36-ee675d0e306a",
      "metadata": {
        "id": "44a8c08d-0222-45e7-ac36-ee675d0e306a"
      },
      "source": [
        "\n",
        "## 固有顔 Eigenfaces\n",
        "\n",
        "与えられた画像表現の問題は、その高次元性である。\n",
        "2次元の $p\\times q$ の濃淡画像は $m=pq$ 次元のベクトル空間にまたがるので、$100\\times100$ 画素の画像はすでに 10,000 次元の画像空間にある。\n",
        "これはどんな計算をするにも多すぎるが、すべての次元が本当に我々にとって有用なのだろうか？\n",
        "我々はデータに分散がある場合にのみ判断を下すことができるので、我々が探しているのは情報の大部分を占める成分である。\n",
        "主成分分析 (PCA) は、カール・ピアソン(1901) とハロルド・ホテリング (1933) によって独自に提案されたもので，相関している可能性のある変数の集合を，より小さな相関していない変数の集合に変えるものである。\n",
        "このアイデアは、高次元のデータ集合は、しばしば相関のある変数によって記述され、したがって、いくつかの意味のある次元だけが情報の大部分を占めるというものである。\n",
        "PCA は、主成分と呼ばれるデータ中の最大の分散を持つ方向を見つける。\n",
        "<!-- The problem with the image representation we are given is its high dimensionality.\n",
        "Two-dimensional pxq grayscale images span a m=pq-dimensional vector space, so an image with 100x100 pixels lies in a 10,000-dimensional image space already.\n",
        "That's way too much for any computations, but are all dimensions really useful for us?\n",
        "We can only make a decision if there's any variance in data, so what we are looking for are the components that account for most of the information.\n",
        "The Principal Component Analysis (PCA) was independently proposed by Karl Pearson (1901) and Harold Hotelling (1933) to turn a set of possibly correlated variables into a smaller set of uncorrelated variables.\n",
        "The idea is that a high-dimensional dataset is often described by correlated variables and therefore only a few meaningful dimensions account for most of the information.\n",
        "The PCA method finds the directions with the greatest variance in the data, called principal components. -->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faf5815a",
      "metadata": {
        "id": "faf5815a"
      },
      "source": [
        "### アルゴリズム<!--Algorithmic Description-->\n",
        "\n",
        "$X=\\left\\{x_1,x_2,\\ldots,x_n\\right\\}$ は $x_i\\in\\mathbb{R}^{d}$ からの確率ベクトルとする:\n",
        "<!-- Let $X=\\left\\{x_1,x_2,\\ldots,x_n\\right\\}$ be a random vector with observation $x_i\\in\\mathbb{R}^{d}$. -->\n",
        "\n",
        "1. Compute the mean $\\mu$\n",
        "$$\\tag{1}\n",
        "\\mu=\\frac{1}{n}\\sum_{i=1}^{n}x_i.\n",
        "$$\n",
        "2. Compute the Covariance matrix $C$\n",
        "$$\\tag{2}\n",
        "C=\\frac{1}{n}\\sum_{i=1}^{n}(x_i-\\mu)(x_i-\\mu)^{\\top}.\n",
        "$$\n",
        "3. Compute the eigenvalues $\\lambda_i$ and eigenvectors $\\nu_i$ of $C$\n",
        "$$\\tag{3}\n",
        "C\\nu_i=\\lambda_i\\nu_i, \\text{\\hspace{1cm} $i=1,2,\\ldots,n$}\n",
        "$$\n",
        "4. Order the eigenvalues descending by their eigenvalue.\n",
        "The $k$ principla components are the eigenvectors corresponding to the $k$ largest eigenvalues.\n",
        "\n",
        "観測ベクトル $x$ の $k$ 個の主成分は次式で与えられる：<!-- The k principal components of the observed vector $x$ are then given by: -->\n",
        "\n",
        "$$\\tag{4}\n",
        "y = W^{\\top}(x-\\mu),\n",
        "$$\n",
        "\n",
        "ここで $W=\\left(v_1,v_2,\\ldots,v_k\\right)$.\n",
        "<!--where $W=left(v_1,v_2,\\ldots,v_k\\right)$.-->\n",
        "PCA 基底からの再構成は次式:<!--The reconstruction from the PCA basis is given by:-->\n",
        "$$\\tag{5}\n",
        "x= Wy + \\mu.\n",
        "$$\n",
        "そして固有顔法は、次のようにして顔認識を行う：<!-- The Eigenfaces method then performs face recognition by: -->\n",
        "1. すべての訓練サンプルを PCA の部分空間に射影する  (式 (4) )。\n",
        "2. クエリ画像を PCA 部分空間に射影する (リスト 5 を使用)。\n",
        "3. 投影された訓練サンプルと投影されたクエリ画像の間の最近傍を見つける。\n",
        "\n",
        "<!-- 1. Projecting all training samples into the PCA subspace (using Equation 4).\n",
        "2. Projecting the query image into the PCA subspace (using Listing 5).\n",
        "3. Finding the nearest neighbor between the projected training samples and the projected query image. -->\n",
        "\n",
        "まだ、解決しなければならない問題が 1 つ残っている。\n",
        "100x100 画素の画像が 400 枚与えられたとする。\n",
        "主成分分析（PCA）は共分散行列 $C=XX^{\\top}$ を解くが、この例では size(X)=$10000\\times400$ である。\n",
        "結局 10000x10000 の行列になり、ざっと 0.8GB になる。\n",
        "この問題を解くのは現実的ではないので、トリックを適用する必要がある。\n",
        "線形代数の授業で、$M>N$ の $M\\times N$ 行列は $N-1$ 個の非ゼロ固有値しか持てないことを知っているだろう。\n",
        "そこで、代わりにサイズ $N\\times N$ の固有値分解 $S=X^{\\top}X$ を取ることができる：\n",
        "<!-- Still there is one problem left to solve.\n",
        "Imagin we are given 400 images sized 100x100 pixels.\n",
        "The Principal Component Analysis (PCA) solves the covariance matrix $C=XX^{\\top}$, where size(X)=10000X400 in our example.\n",
        "You would end up with a 10000x10000 matrix, rougly 0.8GB.\n",
        "Solving this  problem is not feasible, so we will need to apply a trick.\n",
        "From your linear algebra lessons you know that a MxN matrix with M>N can only have N-1 non-zero eigenvalues.\n",
        "So it is possible to take the eigenvalue decompostion $S=X^{\\top}X$ of size NxN instead: -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qxf4e2iNb7Kp",
      "metadata": {
        "id": "qxf4e2iNb7Kp"
      },
      "outputs": [],
      "source": [
        "def LDA(X, y, num_comp=0):\n",
        "    \"\"\"線形判別分析 LDA: Linear Discriminant Analysis\n",
        "        X: データ行列\n",
        "        y: X の各行に対応する群ラベルを格納した numpy.array リスト\n",
        "    \"\"\"\n",
        "    #y = np.asarray(y)\n",
        "    [n,d] = X.shape         # データ行列の 行:n と 列:d を求める\n",
        "    n_class = np.unique(y)  # データに含まれる群の数\n",
        "    if (num_comp <= 0) or (num_comp > (len(n_class)-1)):\n",
        "        num_comp = (len(n_class)-1)\n",
        "\n",
        "    Total_mean = X.mean(axis=0)             # 全平均の計算\n",
        "    Sw = np.zeros((d,d), dtype=np.float32)  # 群内分散保存用\n",
        "    Sb = np.zeros((d,d), dtype=np.float32)  # 群間分散保存用\n",
        "    for i in n_class:                       # 各群について繰り返す\n",
        "        Xi = X[np.where(y==i)[0],:]\n",
        "        G_mean = Xi.mean(axis=0)                                             # 群平均\n",
        "        Sw = Sw + np.dot((Xi - G_mean).T, (Xi - G_mean))                     # 群内分散\n",
        "        Sb = Sb + n * np.dot((G_mean - Total_mean).T, (G_mean - Total_mean)) # 群間分散\n",
        "    Eigenvalues, Eigenvectors = np.linalg.eig(np.linalg.inv(Sw) * Sb)\n",
        "    idx = np.argsort(-Eigenvalues.real)\n",
        "    Eigenvalues, Eigenvectors = Eigenvalues[idx], Eigenvectors[:,idx]\n",
        "    Eigenvalues = np.array(Eigenvalues[0:num_comp].real, dtype=np.float32, copy=True)\n",
        "    Eigenvectors = np.array(Eigenvectors[0:,0:num_comp].real, dtype=np.float32, copy=True)\n",
        "    return Eigenvalues, Eigenvectors\n",
        "\n",
        "\n",
        "def Fisherfaces(X,y,num_comp=0):\n",
        "    #y = np.asarray(y)\n",
        "    [n,d] = X.shape\n",
        "    n_class = len(np.unique(y))\n",
        "    #[Eigenvalues_pca, Eigenvectors_pca, mu_pca] = pca(X, y, (n-n_class))\n",
        "    Eigenvalues_pca, Eigenvectors_pca, mu_pca = _PCA.Eigenvalues, _PCA.Eigenvectors, _PCA.mean\n",
        "    #[Eigenvalues_lda, Eigenvectors_lda] = LDA(project(Eigenvectors_pca, X, mu_pca), y, num_comp)\n",
        "    Eigenvalues_lda, Eigenvectors_lda = LDA(_PCA.projections, y, num_comp)\n",
        "    Eigenvectors = np.dot(Eigenvectors_pca, Eigenvectors_lda)\n",
        "    return Eigenvalues_lda, Eigenvectors #, mu_pca\n",
        "\n",
        "Fisher_Eignevalues, Fisher_Eigenvectors = Fisherfaces(X,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49KNaJr6b-Gu",
      "metadata": {
        "id": "49KNaJr6b-Gu"
      },
      "source": [
        "## フィッシャー顔固有ベクトルの視覚化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GbjuPPF2cAHS",
      "metadata": {
        "id": "GbjuPPF2cAHS"
      },
      "outputs": [],
      "source": [
        "# help(np.set_printoptions)\n",
        "N_pca = 10\n",
        "fix, axes = plt.subplots(nrows=1, ncols=N_pca, figsize=(N_pca * 1.4, 1.4))\n",
        "for i in range(N_pca):\n",
        "    axes[i].imshow(Fisher_Eigenvectors[:,i].reshape(64,64), cmap=\"gray\")\n",
        "    axes[i].set_title(f'第 {i+1} 固有値に対応\\nする固有ベクトル', size=7)\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xk4VsFCVcB8B",
      "metadata": {
        "id": "xk4VsFCVcB8B"
      },
      "outputs": [],
      "source": [
        "Fisher_projections = _PCA._X @ Fisher_Eigenvectors\n",
        "Fisher_reconstruct = Fisher_projections @ Fisher_Eigenvectors.T + _PCA.mean\n",
        "print(Fisher_reconstruct.shape, Fisher_projections.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b81111f-fed8-4adc-8a7f-7eac1ba632c3",
      "metadata": {
        "id": "0b81111f-fed8-4adc-8a7f-7eac1ba632c3"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(Fisher_Eigenvectors.T @ Fisher_Eigenvectors, center=0, vmin=-1., vmax=1., square=True, cmap='gnuplot2')\n",
        "plt.title('固有ベクトルの積を可視化')\n",
        "plt.show()\n",
        "\n",
        "print((Fisher_Eigenvectors.T @ Fisher_Eigenvectors)[:5,:5])\n",
        "print((Fisher_Eigenvectors.T @ Fisher_Eigenvectors)[-10:,-10:])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a4b574b-4006-41a9-b224-44461da86fd2",
      "metadata": {
        "id": "9a4b574b-4006-41a9-b224-44461da86fd2"
      },
      "outputs": [],
      "source": [
        "plt.plot(Fisher_Eignevalues[3:])\n",
        "plt.title('Fisher 顔の固有値プロット')\n",
        "plt.show()\n",
        "print(Fisher_Eignevalues[3:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BzdPZLZEcFA3",
      "metadata": {
        "id": "BzdPZLZEcFA3"
      },
      "outputs": [],
      "source": [
        "# 固有顔 (PCA) を用いて 40 名の顔認識データをもちいて 3 手法を比較\n",
        "X_train, X_test, y_train, y_test=train_test_split(Fisher_projections, y, test_size=split_ratio, stratify=y, random_state=42)\n",
        "#X_train, X_test, y_train, y_test=train_test_split(_PCA.projections, y_sex, test_size=split_ratio, stratify=y, random_state=42)\n",
        "\n",
        "# 共通パラメータ\n",
        "params = {'max_iter':10 ** 4,\n",
        "          #'C':1e3,\n",
        "          #'penalty':'l2'\n",
        "         }\n",
        "\n",
        "# 3 つのモデルの定義\n",
        "svc_model = SVC(**params)\n",
        "logistic_model = LogisticRegression(**params)\n",
        "lda_model = LinearDiscriminantAnalysis()\n",
        "\n",
        "# 出力する図のサイズを定義\n",
        "fig, _axes = plt.subplots(ncols=3, nrows=1, figsize=(12,4), constrained_layout=True)\n",
        "\n",
        "# 3 つのモデルをそれぞれ実行して結果を描画\n",
        "for i, (model_name, model) in enumerate([('サポートベクタマシン',svc_model),\n",
        "                                         ('ロジスティック回帰',logistic_model),\n",
        "                                         ('線形判別分析',lda_model)]):\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_hat = model.predict(X_test)  # テストデータを使って予測を行い結果を y_hat に格納\n",
        "\n",
        "    _axes[i].imshow(metrics.confusion_matrix(y_test,y_hat), cmap='gray')\n",
        "    _axes[i].set_title(f'{model_name}:分類精度:{metrics.accuracy_score(y_test,y_hat):.2f}')\n",
        "    _axes[i].axis('off')\n",
        "\n",
        "    # print(model_name, '\\n', metrics.confusion_matrix(y_test,y_hat))\n",
        "    # print(model_name, '\\n', metrics.classification_report(y_test,y_hat))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e03kLjQfcIcL",
      "metadata": {
        "id": "e03kLjQfcIcL"
      },
      "outputs": [],
      "source": [
        "Fisher_reconstruct.shape\n",
        "plt.figure(figsize=(2.5,2.5))\n",
        "plt.imshow(Fisher_reconstruct[-1].reshape(64,64), cmap='gray')\n",
        "plt.title(f'フィッシャー顔 再構成')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yJ8z9kxHcMOE",
      "metadata": {
        "id": "yJ8z9kxHcMOE"
      },
      "outputs": [],
      "source": [
        "# PCA による次元圧縮の結果を表示\n",
        "\n",
        "XX = Fisher_projections\n",
        "XX = Fisher_reconstruct\n",
        "\n",
        "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(14,4))\n",
        "axes[0].scatter(XX[:,0], XX[:,1], s=1)\n",
        "axes[0].set_xlabel('第 1 主成分')\n",
        "axes[0].set_ylabel('第 2 主成分')\n",
        "for i in range(XX.shape[0]):\n",
        "    axes[0].annotate(str(y[i]), (XX[i,0], XX[i,1]))\n",
        "\n",
        "axes[1].scatter(XX[:,1], XX[:,2], s=1)\n",
        "axes[1].set_xlabel('第 2 主成分')\n",
        "axes[1].set_ylabel('第 3 主成分')\n",
        "for i in range(XX.shape[0]):\n",
        "    axes[1].annotate(str(y[i]), (XX[i,1], XX[i,2]))\n",
        "\n",
        "axes[2].scatter(XX[:,0], XX[:,3], s=1)\n",
        "axes[2].set_xlabel('第 1 主成分')\n",
        "axes[2].set_ylabel('第 4 主成分')\n",
        "for i in range(XX.shape[0]):\n",
        "    axes[2].annotate(str(y[i]), (XX[i,0], XX[i,3]))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fe102e6-47b5-45b8-bfb9-d14c786ad49d",
      "metadata": {
        "id": "8fe102e6-47b5-45b8-bfb9-d14c786ad49d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d89812df-8736-4a5f-afc9-5d1c5dae4a76",
      "metadata": {
        "id": "d89812df-8736-4a5f-afc9-5d1c5dae4a76"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}