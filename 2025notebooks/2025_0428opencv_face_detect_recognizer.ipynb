{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2025notebooks/2025_0428opencv_face_detect_recognizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "065823a2-5085-4d5f-be8c-2d4f9a85b58e",
      "metadata": {
        "id": "065823a2-5085-4d5f-be8c-2d4f9a85b58e"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "isColab = 'google.colab' in str(IPython.get_ipython())\n",
        "\n",
        "if isColab:\n",
        "    !pip install opencv-python --upgrade\n",
        "\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import sys\n",
        "import urllib\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib\n",
        "\n",
        "try:\n",
        "    import japanize_matplotlib\n",
        "except ImportError:\n",
        "    !pip install japanize_matplotlib\n",
        "    import japanize_matplotlib\n",
        "\n",
        "face_detector_fname = 'face_detection_yunet_2023mar.onnx'\n",
        "face_detector_url = 'https://github.com/opencv/opencv_zoo/raw/refs/heads/main/models/face_detection_yunet/face_detection_yunet_2023mar.onnx'\n",
        "\n",
        "\n",
        "if os.path.exists(face_detector_fname):\n",
        "    print(f'{face_detector_fname} already exists.')\n",
        "else:\n",
        "    try:\n",
        "        urllib.request.urlretrieve(face_detector_url, face_detector_fname)\n",
        "        print(f\"Successfully downloaded {face_detector_fname}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "face_detector = cv.FaceDetectorYN.create(\n",
        "    model = face_detector_fname,\n",
        "    config = \"\",\n",
        "    input_size = (320,320),\n",
        "    score_threshold = 0.9,\n",
        "    nms_threshold = 0.3,\n",
        "    top_k = 5000)\n",
        "\n",
        "\n",
        "face_recognizer_fname = 'face_recognition_sface_2021dec.onnx'\n",
        "face_recognizer_url = 'https://github.com/opencv/opencv_zoo/raw/refs/heads/main/models/face_recognition_sface/face_recognition_sface_2021dec.onnx'\n",
        "\n",
        "if os.path.exists(face_recognizer_fname):\n",
        "    print(f'{face_recognizer_fname} already exists.')\n",
        "else:\n",
        "    try:\n",
        "        urllib.request.urlretrieve(face_recognizer_url, face_recognizer_fname)\n",
        "        print(f\"Successfully downloaded {face_recognizer_fname}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "face_recognizer = cv.FaceRecognizerSF.create(\n",
        "    model = face_recognizer_fname, config=\"\",\n",
        ")\n",
        "\n",
        "def visualize(img, faces, fps, thickness=24):\n",
        "    if faces[1] is not None:\n",
        "        for idx, face in enumerate(faces[1]):\n",
        "            print(f'Face {idx}',\n",
        "                  f'top-left coordinates: ({face[0]:.0f}',\n",
        "                  f'{face[1]:.0f})',\n",
        "                  f'box width: {face[2]:.0f}',\n",
        "                  f'box height {face[3]:.0f}',\n",
        "                  f'score: {face[-1]:.2f}')\n",
        "\n",
        "            coords = face[:-1].astype(np.int32)\n",
        "            cv.rectangle(img, (coords[0], coords[1]), (coords[0]+coords[2], coords[1]+coords[3]), (0, 255, 0), thickness)\n",
        "            cv.circle(img, (coords[4], coords[5]), 2, (255, 0, 0), thickness)  # 右目を 青 で描画\n",
        "            cv.circle(img, (coords[6], coords[7]), 2, (0, 0, 255), thickness)  # 左目を 赤 で描画\n",
        "            cv.circle(img, (coords[8], coords[9]), 2, (0, 255, 0), thickness) # 鼻を 緑 で描画\n",
        "            cv.circle(img, (coords[10], coords[11]), 2, (255, 0, 255), thickness) # 右唇 を ピンクで描画\n",
        "            cv.circle(img, (coords[12], coords[13]), 2, (0, 255, 255), thickness) # 左唇を 黄色で描画\n",
        "    cv.putText(img, f'FPS: {fps:.2f}', (1, 16), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "    #cv.putText(input, 'FPS: {:.2f}'.format(fps), (1, 16), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Web 上にある任意の画像を持ってきて試してみる\n",
        "# たとえば https://prtimes.jp/main/html/rd/p/000000006.000024843.html から一枚の画像を持ってくる。\n",
        "# 手順は以下のとおり:\n",
        "# 1. 任意の URL を閲覧し，そのページ内に表示されている画像をマウス右クリック，あるいは右クリックに相当する操作を行う。\n",
        "# 2. 現れたウィンドウ内にあるメニューから画像の URL を選んで情報をコピーする。\n",
        "# 3. コピーした画像の URL を以下の欄に貼り付ける\n",
        "!wget https://prtimes.jp/i/24843/6/resize/d24843-6-786069-2.jpg -O test_faces.jpg\n",
        "\n",
        "img = cv.imread('test_faces.jpg')\n",
        "plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bo4QlNl55IHY"
      },
      "id": "bo4QlNl55IHY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 顔検出の実例\n",
        "imgHeight = int(img.shape[0])\n",
        "imgWidth = int(img.shape[1])\n",
        "\n",
        "face_detector.setInputSize((imgWidth, imgHeight))\n",
        "faces = face_detector.detect(img)\n",
        "\n",
        "tm = cv.TickMeter()\n",
        "tm.reset(); tm.start()\n",
        "visualize(img, faces, tm.getFPS(), thickness=2)\n",
        "plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ExhLWjXmD865"
      },
      "id": "ExhLWjXmD865",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7f53f79-a4c1-4478-9d5c-6df6a786a480",
      "metadata": {
        "id": "d7f53f79-a4c1-4478-9d5c-6df6a786a480"
      },
      "outputs": [],
      "source": [
        "# 顔を含む画像をアップロードする\n",
        "if isColab:\n",
        "    from google.colab import files\n",
        "    files.upload()\n",
        "\n",
        "# ここでは 2 枚の画像を自身の PC からアップロードすることを想定している\n",
        "# アップロードした画像のファイル名に合わせて適宜下の 2 行のファイル名を変更する必要がある\n",
        "img1_fname = 'IMG_0328.jpg'\n",
        "img2_fname = 'IMG_0330.jpg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e089c41-ac7e-400c-a538-168f0d48e796",
      "metadata": {
        "id": "1e089c41-ac7e-400c-a538-168f0d48e796"
      },
      "outputs": [],
      "source": [
        "# アップロードした画像を表示\n",
        "img1 = cv.imread(img1_fname)\n",
        "img2 = cv.imread(img2_fname)\n",
        "\n",
        "img1Width = int(img1.shape[1])\n",
        "img1Height = int(img1.shape[0])\n",
        "\n",
        "face_detector.setInputSize((img1Width, img1Height))\n",
        "#print(type(img1), img1.min(), img1.max())\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, nrows=1, figsize=(12, 5))\n",
        "axes[0].imshow(cv.cvtColor(img1, cv.COLOR_BGR2RGB))\n",
        "axes[1].imshow(cv.cvtColor(img2, cv.COLOR_BGR2RGB))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8db4360-b3cb-45aa-ab21-e3c7488bd82b",
      "metadata": {
        "id": "c8db4360-b3cb-45aa-ab21-e3c7488bd82b"
      },
      "outputs": [],
      "source": [
        "# 顔検出の実際\n",
        "faces1 = face_detector.detect(img1)\n",
        "faces2 = face_detector.detect(img2)\n",
        "\n",
        "tm = cv.TickMeter()\n",
        "\n",
        "tm.reset()\n",
        "tm.start()\n",
        "visualize(img1, faces1, tm.getFPS())\n",
        "tm.stop()\n",
        "\n",
        "tm.reset()\n",
        "tm.start()\n",
        "visualize(img2, faces2, tm.getFPS())\n",
        "tm.stop()\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, nrows=1, figsize=(12, 5))\n",
        "axes[0].imshow(cv.cvtColor(img1, cv.COLOR_BGR2RGB))\n",
        "axes[1].imshow(cv.cvtColor(img2, cv.COLOR_BGR2RGB))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7dcfbea-dfcf-42e0-9ed9-a01fe854de0b",
      "metadata": {
        "id": "a7dcfbea-dfcf-42e0-9ed9-a01fe854de0b"
      },
      "outputs": [],
      "source": [
        "face1_align = face_recognizer.alignCrop(img1, faces1[1][0])\n",
        "face2_align = face_recognizer.alignCrop(img2, faces2[1][0])\n",
        "\n",
        "# face1_align = face_recognizer.alignCrop(img1, faces1[1][1])\n",
        "# face2_align = face_recognizer.alignCrop(img2, faces2[1][1])\n",
        "\n",
        "# Extract features\n",
        "face1_feature = face_recognizer.feature(face1_align)\n",
        "face2_feature = face_recognizer.feature(face2_align)\n",
        "\n",
        "cosine_similarity_threshold = 0.363\n",
        "l2_similarity_threshold = 1.128\n",
        "\n",
        "cosine_score = face_recognizer.match(face1_feature, face2_feature, cv.FaceRecognizerSF_FR_COSINE)\n",
        "l2_score = face_recognizer.match(face1_feature, face2_feature, cv.FaceRecognizerSF_FR_NORM_L2)\n",
        "\n",
        "msg = 'different identities'\n",
        "if cosine_score >= cosine_similarity_threshold:\n",
        "    msg = 'the same identity'\n",
        "print(f'They have {msg}.',\n",
        "      f'Cosine Similarity: {cosine_score:.3f}',\n",
        "      f'threshold: {cosine_similarity_threshold:.3f}',\n",
        "      '(higher value means higher similarity, max 1.0).')\n",
        "\n",
        "msg = 'different identities'\n",
        "if l2_score <= l2_similarity_threshold:\n",
        "    msg = 'the same identity'\n",
        "print(f'They have {msg}.',\n",
        "      f'NormL2 Distance: {l2_score:.3f}',\n",
        "      f'fthreshold: {l2_similarity_threshold:.3f}',\n",
        "      '(lower value means higher similarity, min 0.0).')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae73ef87-cff5-4378-8cb1-c92ff1cfa82c",
      "metadata": {
        "id": "ae73ef87-cff5-4378-8cb1-c92ff1cfa82c"
      },
      "outputs": [],
      "source": [
        "print(type(face1_align), face1_align.shape)\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(4,3))\n",
        "axes[0].imshow(cv.cvtColor(face1_align, cv.COLOR_BGRA2RGB))\n",
        "axes[1].imshow(cv.cvtColor(face2_align, cv.COLOR_BGRA2RGB))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}